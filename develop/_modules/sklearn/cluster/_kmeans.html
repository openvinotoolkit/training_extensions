
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>sklearn.cluster._kmeans &#8212; OpenVINOâ„¢ Training Extensions 1.6.0dev documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=796348d33e8b1d947c94" rel="stylesheet">
<link href="../../../_static/styles/bootstrap.css?digest=796348d33e8b1d947c94" rel="stylesheet">
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=796348d33e8b1d947c94" rel="stylesheet">

  
  <link href="../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=796348d33e8b1d947c94" rel="stylesheet">
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2">
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2">
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/custom.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94">
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/sphinx_highlight.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/sklearn/cluster/_kmeans';</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="docsearch:language" content="en">
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>

  
  <input type="checkbox" class="sidebar-toggle" name="__primary" id="__primary">
  <label class="overlay overlay-primary" for="__primary"></label>

  
  <input type="checkbox" class="sidebar-toggle" name="__secondary" id="__secondary">
  <label class="overlay overlay-secondary" for="__secondary"></label>

  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
      
<form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
  </div>

  
  <nav class="bd-header navbar navbar-expand-lg bd-navbar" id="navbar-main"><div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
      <span class="fa-solid fa-bars"></span>
  </label>
  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../../../index.html">

  
  
  
  
  
  
  

  
    <img src="../../../_static/logos/otx-logo.png" class="logo__image only-light" alt="Logo image">
    <img src="../../../_static/logos/otx-logo.png" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    
  </div>

  
  <div class="col-lg-9 navbar-header-items">
    <div id="navbar-center" class="mr-auto">
      
    </div>

    <div id="navbar-end">
      
        <div class="navbar-end-item navbar-persistent--container">
          
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
        </div>
      
      
      <div class="navbar-end-item">
        <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          <a href="https://github.com/openvinotoolkit/training_extensions" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-toggle="tooltip"><img src="../../../_static/logos/github_icon.png" class="icon-link-image" alt="GitHub"/></a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>


  
  
    <div class="navbar-persistent--mobile">
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
    </div>
  

  
  <label class="sidebar-toggle secondary-toggle" for="__secondary">
      <span class="fa-solid fa-outdent"></span>
  </label>
  

</div>
  </nav>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar hide-on-wide">
        
  
  <div class="sidebar-header-items sidebar-primary__section">
    
    

    
    
    <div class="sidebar-header-items__end">
      
      <div class="navbar-end-item">
        <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          <a href="https://github.com/openvinotoolkit/training_extensions" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-toggle="tooltip"><img src="../../../_static/logos/github_icon.png" class="icon-link-image" alt="GitHub"/></a>
        </li>
      </ul>
      </div>
      
    </div>
    
  </div>

  

  
  <div class="sidebar-end-items sidebar-primary__section">
    <div class="sidebar-end-items__item">
    </div>
  </div>

  
  <div id="rtd-footer-container"></div>

      </div>
      <main id="main-content" class="bd-main">
        
        
        <div class="bd-content">
          <div class="bd-article-container">
            
            <div class="bd-header-article">
                
            </div>
            
            
            <article class="bd-article" role="main">
              
  <h1>Source code for sklearn.cluster._kmeans</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;K-means clustering.&quot;&quot;&quot;</span>

<span class="c1"># Authors: Gael Varoquaux &lt;gael.varoquaux@normalesup.org&gt;</span>
<span class="c1">#          Thomas Rueckstiess &lt;ruecksti@in.tum.de&gt;</span>
<span class="c1">#          James Bergstra &lt;james.bergstra@umontreal.ca&gt;</span>
<span class="c1">#          Jan Schlueter &lt;scikit-learn@jan-schlueter.de&gt;</span>
<span class="c1">#          Nelle Varoquaux</span>
<span class="c1">#          Peter Prettenhofer &lt;peter.prettenhofer@gmail.com&gt;</span>
<span class="c1">#          Olivier Grisel &lt;olivier.grisel@ensta.org&gt;</span>
<span class="c1">#          Mathieu Blondel &lt;mathieu@mblondel.org&gt;</span>
<span class="c1">#          Robert Layton &lt;robertlayton@gmail.com&gt;</span>
<span class="c1"># License: BSD 3 clause</span>

<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">from</span> <span class="nn">numbers</span> <span class="kn">import</span> <span class="n">Integral</span><span class="p">,</span> <span class="n">Real</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy.sparse</span> <span class="k">as</span> <span class="nn">sp</span>

<span class="kn">from</span> <span class="nn">..base</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">BaseEstimator</span><span class="p">,</span>
    <span class="n">ClassNamePrefixFeaturesOutMixin</span><span class="p">,</span>
    <span class="n">ClusterMixin</span><span class="p">,</span>
    <span class="n">TransformerMixin</span><span class="p">,</span>
    <span class="n">_fit_context</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">..exceptions</span> <span class="kn">import</span> <span class="n">ConvergenceWarning</span>
<span class="kn">from</span> <span class="nn">..metrics.pairwise</span> <span class="kn">import</span> <span class="n">_euclidean_distances</span><span class="p">,</span> <span class="n">euclidean_distances</span>
<span class="kn">from</span> <span class="nn">..utils</span> <span class="kn">import</span> <span class="n">check_array</span><span class="p">,</span> <span class="n">check_random_state</span>
<span class="kn">from</span> <span class="nn">..utils._openmp_helpers</span> <span class="kn">import</span> <span class="n">_openmp_effective_n_threads</span>
<span class="kn">from</span> <span class="nn">..utils._param_validation</span> <span class="kn">import</span> <span class="n">Hidden</span><span class="p">,</span> <span class="n">Interval</span><span class="p">,</span> <span class="n">StrOptions</span><span class="p">,</span> <span class="n">validate_params</span>
<span class="kn">from</span> <span class="nn">..utils.extmath</span> <span class="kn">import</span> <span class="n">row_norms</span><span class="p">,</span> <span class="n">stable_cumsum</span>
<span class="kn">from</span> <span class="nn">..utils.fixes</span> <span class="kn">import</span> <span class="n">threadpool_info</span><span class="p">,</span> <span class="n">threadpool_limits</span>
<span class="kn">from</span> <span class="nn">..utils.sparsefuncs</span> <span class="kn">import</span> <span class="n">mean_variance_axis</span>
<span class="kn">from</span> <span class="nn">..utils.sparsefuncs_fast</span> <span class="kn">import</span> <span class="n">assign_rows_csr</span>
<span class="kn">from</span> <span class="nn">..utils.validation</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_check_sample_weight</span><span class="p">,</span>
    <span class="n">_is_arraylike_not_scalar</span><span class="p">,</span>
    <span class="n">check_is_fitted</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">._k_means_common</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">CHUNK_SIZE</span><span class="p">,</span>
    <span class="n">_inertia_dense</span><span class="p">,</span>
    <span class="n">_inertia_sparse</span><span class="p">,</span>
    <span class="n">_is_same_clustering</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">._k_means_elkan</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">elkan_iter_chunked_dense</span><span class="p">,</span>
    <span class="n">elkan_iter_chunked_sparse</span><span class="p">,</span>
    <span class="n">init_bounds_dense</span><span class="p">,</span>
    <span class="n">init_bounds_sparse</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">._k_means_lloyd</span> <span class="kn">import</span> <span class="n">lloyd_iter_chunked_dense</span><span class="p">,</span> <span class="n">lloyd_iter_chunked_sparse</span>
<span class="kn">from</span> <span class="nn">._k_means_minibatch</span> <span class="kn">import</span> <span class="n">_minibatch_update_dense</span><span class="p">,</span> <span class="n">_minibatch_update_sparse</span>

<span class="c1">###############################################################################</span>
<span class="c1"># Initialization heuristic</span>


<span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;X&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse matrix&quot;</span><span class="p">],</span>
        <span class="s2">&quot;n_clusters&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Interval</span><span class="p">(</span><span class="n">Integral</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">closed</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">)],</span>
        <span class="s2">&quot;sample_weight&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;x_squared_norms&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;random_state&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;random_state&quot;</span><span class="p">],</span>
        <span class="s2">&quot;n_local_trials&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Interval</span><span class="p">(</span><span class="n">Integral</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">closed</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">),</span> <span class="kc">None</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">kmeans_plusplus</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span>
    <span class="n">n_clusters</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">x_squared_norms</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">n_local_trials</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Init n_clusters seeds according to k-means++.</span>

<span class="sd">    .. versionadded:: 0.24</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : {array-like, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">        The data to pick seeds from.</span>

<span class="sd">    n_clusters : int</span>
<span class="sd">        The number of centroids to initialize.</span>

<span class="sd">    sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">        The weights for each observation in `X`. If `None`, all observations</span>
<span class="sd">        are assigned equal weight. `sample_weight` is ignored if `init`</span>
<span class="sd">        is a callable or a user provided array.</span>

<span class="sd">        .. versionadded:: 1.3</span>

<span class="sd">    x_squared_norms : array-like of shape (n_samples,), default=None</span>
<span class="sd">        Squared Euclidean norm of each data point.</span>

<span class="sd">    random_state : int or RandomState instance, default=None</span>
<span class="sd">        Determines random number generation for centroid initialization. Pass</span>
<span class="sd">        an int for reproducible output across multiple function calls.</span>
<span class="sd">        See :term:`Glossary &lt;random_state&gt;`.</span>

<span class="sd">    n_local_trials : int, default=None</span>
<span class="sd">        The number of seeding trials for each center (except the first),</span>
<span class="sd">        of which the one reducing inertia the most is greedily chosen.</span>
<span class="sd">        Set to None to make the number of trials depend logarithmically</span>
<span class="sd">        on the number of seeds (2+log(k)) which is the recommended setting.</span>
<span class="sd">        Setting to 1 disables the greedy cluster selection and recovers the</span>
<span class="sd">        vanilla k-means++ algorithm which was empirically shown to work less</span>
<span class="sd">        well than its greedy variant.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    centers : ndarray of shape (n_clusters, n_features)</span>
<span class="sd">        The initial centers for k-means.</span>

<span class="sd">    indices : ndarray of shape (n_clusters,)</span>
<span class="sd">        The index location of the chosen centers in the data array X. For a</span>
<span class="sd">        given index and center, X[index] = center.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Selects initial cluster centers for k-mean clustering in a smart way</span>
<span class="sd">    to speed up convergence. see: Arthur, D. and Vassilvitskii, S.</span>
<span class="sd">    &quot;k-means++: the advantages of careful seeding&quot;. ACM-SIAM symposium</span>
<span class="sd">    on Discrete algorithms. 2007</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    &gt;&gt;&gt; from sklearn.cluster import kmeans_plusplus</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [1, 4], [1, 0],</span>
<span class="sd">    ...               [10, 2], [10, 4], [10, 0]])</span>
<span class="sd">    &gt;&gt;&gt; centers, indices = kmeans_plusplus(X, n_clusters=2, random_state=0)</span>
<span class="sd">    &gt;&gt;&gt; centers</span>
<span class="sd">    array([[10,  2],</span>
<span class="sd">           [ 1,  0]])</span>
<span class="sd">    &gt;&gt;&gt; indices</span>
<span class="sd">    array([3, 2])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Check data</span>
    <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="s2">&quot;csr&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">])</span>
    <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">_check_sample_weight</span><span class="p">(</span><span class="n">sample_weight</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">n_clusters</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;n_samples=</span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> should be &gt;= n_clusters=</span><span class="si">{</span><span class="n">n_clusters</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>

    <span class="c1"># Check parameters</span>
    <span class="k">if</span> <span class="n">x_squared_norms</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">x_squared_norms</span> <span class="o">=</span> <span class="n">row_norms</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">squared</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">x_squared_norms</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">x_squared_norms</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">x_squared_norms</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;The length of x_squared_norms </span><span class="si">{</span><span class="n">x_squared_norms</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> should &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;be equal to the length of n_samples </span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>

    <span class="n">random_state</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>

    <span class="c1"># Call private k-means++</span>
    <span class="n">centers</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">_kmeans_plusplus</span><span class="p">(</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">n_clusters</span><span class="p">,</span> <span class="n">x_squared_norms</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">,</span> <span class="n">random_state</span><span class="p">,</span> <span class="n">n_local_trials</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">centers</span><span class="p">,</span> <span class="n">indices</span>


<span class="k">def</span> <span class="nf">_kmeans_plusplus</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">n_clusters</span><span class="p">,</span> <span class="n">x_squared_norms</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">,</span> <span class="n">random_state</span><span class="p">,</span> <span class="n">n_local_trials</span><span class="o">=</span><span class="kc">None</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Computational component for initialization of n_clusters by</span>
<span class="sd">    k-means++. Prior validation of data is assumed.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : {ndarray, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">        The data to pick seeds for.</span>

<span class="sd">    n_clusters : int</span>
<span class="sd">        The number of seeds to choose.</span>

<span class="sd">    sample_weight : ndarray of shape (n_samples,)</span>
<span class="sd">        The weights for each observation in `X`.</span>

<span class="sd">    x_squared_norms : ndarray of shape (n_samples,)</span>
<span class="sd">        Squared Euclidean norm of each data point.</span>

<span class="sd">    random_state : RandomState instance</span>
<span class="sd">        The generator used to initialize the centers.</span>
<span class="sd">        See :term:`Glossary &lt;random_state&gt;`.</span>

<span class="sd">    n_local_trials : int, default=None</span>
<span class="sd">        The number of seeding trials for each center (except the first),</span>
<span class="sd">        of which the one reducing inertia the most is greedily chosen.</span>
<span class="sd">        Set to None to make the number of trials depend logarithmically</span>
<span class="sd">        on the number of seeds (2+log(k)); this is the default.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    centers : ndarray of shape (n_clusters, n_features)</span>
<span class="sd">        The initial centers for k-means.</span>

<span class="sd">    indices : ndarray of shape (n_clusters,)</span>
<span class="sd">        The index location of the chosen centers in the data array X. For a</span>
<span class="sd">        given index and center, X[index] = center.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>

    <span class="n">centers</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">n_features</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

    <span class="c1"># Set the number of local seeding trials if none is given</span>
    <span class="k">if</span> <span class="n">n_local_trials</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># This is what Arthur/Vassilvitskii tried, but did not report</span>
        <span class="c1"># specific results for other than mentioning in the conclusion</span>
        <span class="c1"># that it helped.</span>
        <span class="n">n_local_trials</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">+</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">))</span>

    <span class="c1"># Pick first center randomly and track index of point</span>
    <span class="n">center_id</span> <span class="o">=</span> <span class="n">random_state</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">sample_weight</span> <span class="o">/</span> <span class="n">sample_weight</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">sp</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
        <span class="n">centers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">center_id</span><span class="p">]</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">centers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">center_id</span><span class="p">]</span>
    <span class="n">indices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">center_id</span>

    <span class="c1"># Initialize list of closest distances and calculate current potential</span>
    <span class="n">closest_dist_sq</span> <span class="o">=</span> <span class="n">_euclidean_distances</span><span class="p">(</span>
        <span class="n">centers</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y_norm_squared</span><span class="o">=</span><span class="n">x_squared_norms</span><span class="p">,</span> <span class="n">squared</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>
    <span class="n">current_pot</span> <span class="o">=</span> <span class="n">closest_dist_sq</span> <span class="o">@</span> <span class="n">sample_weight</span>

    <span class="c1"># Pick the remaining n_clusters-1 points</span>
    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_clusters</span><span class="p">):</span>
        <span class="c1"># Choose center candidates by sampling with probability proportional</span>
        <span class="c1"># to the squared distance to the closest existing center</span>
        <span class="n">rand_vals</span> <span class="o">=</span> <span class="n">random_state</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">n_local_trials</span><span class="p">)</span> <span class="o">*</span> <span class="n">current_pot</span>
        <span class="n">candidate_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">(</span>
            <span class="n">stable_cumsum</span><span class="p">(</span><span class="n">sample_weight</span> <span class="o">*</span> <span class="n">closest_dist_sq</span><span class="p">),</span> <span class="n">rand_vals</span>
        <span class="p">)</span>
        <span class="c1"># XXX: numerical imprecision can result in a candidate_id out of range</span>
        <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">candidate_ids</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">closest_dist_sq</span><span class="o">.</span><span class="n">size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">candidate_ids</span><span class="p">)</span>

        <span class="c1"># Compute distances to center candidates</span>
        <span class="n">distance_to_candidates</span> <span class="o">=</span> <span class="n">_euclidean_distances</span><span class="p">(</span>
            <span class="n">X</span><span class="p">[</span><span class="n">candidate_ids</span><span class="p">],</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y_norm_squared</span><span class="o">=</span><span class="n">x_squared_norms</span><span class="p">,</span> <span class="n">squared</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>

        <span class="c1"># update closest distances squared and potential for each candidate</span>
        <span class="n">np</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">closest_dist_sq</span><span class="p">,</span> <span class="n">distance_to_candidates</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">distance_to_candidates</span><span class="p">)</span>
        <span class="n">candidates_pot</span> <span class="o">=</span> <span class="n">distance_to_candidates</span> <span class="o">@</span> <span class="n">sample_weight</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Decide which candidate is the best</span>
        <span class="n">best_candidate</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">candidates_pot</span><span class="p">)</span>
        <span class="n">current_pot</span> <span class="o">=</span> <span class="n">candidates_pot</span><span class="p">[</span><span class="n">best_candidate</span><span class="p">]</span>
        <span class="n">closest_dist_sq</span> <span class="o">=</span> <span class="n">distance_to_candidates</span><span class="p">[</span><span class="n">best_candidate</span><span class="p">]</span>
        <span class="n">best_candidate</span> <span class="o">=</span> <span class="n">candidate_ids</span><span class="p">[</span><span class="n">best_candidate</span><span class="p">]</span>

        <span class="c1"># Permanently add best center candidate found in local tries</span>
        <span class="k">if</span> <span class="n">sp</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
            <span class="n">centers</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">best_candidate</span><span class="p">]</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">centers</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">best_candidate</span><span class="p">]</span>
        <span class="n">indices</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_candidate</span>

    <span class="k">return</span> <span class="n">centers</span><span class="p">,</span> <span class="n">indices</span>


<span class="c1">###############################################################################</span>
<span class="c1"># K-means batch estimation by EM (expectation maximization)</span>


<span class="k">def</span> <span class="nf">_tolerance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">tol</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Return a tolerance which is dependent on the dataset.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">tol</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">sp</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
        <span class="n">variances</span> <span class="o">=</span> <span class="n">mean_variance_axis</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">variances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">variances</span><span class="p">)</span> <span class="o">*</span> <span class="n">tol</span>


<span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;X&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse matrix&quot;</span><span class="p">],</span>
        <span class="s2">&quot;sample_weight&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;return_n_iter&quot;</span><span class="p">:</span> <span class="p">[</span><span class="nb">bool</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">k_means</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span>
    <span class="n">n_clusters</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">init</span><span class="o">=</span><span class="s2">&quot;k-means++&quot;</span><span class="p">,</span>
    <span class="n">n_init</span><span class="o">=</span><span class="s2">&quot;warn&quot;</span><span class="p">,</span>
    <span class="n">max_iter</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">tol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">copy_x</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;lloyd&quot;</span><span class="p">,</span>
    <span class="n">return_n_iter</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Perform K-means clustering algorithm.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;k_means&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : {array-like, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">        The observations to cluster. It must be noted that the data</span>
<span class="sd">        will be converted to C ordering, which will cause a memory copy</span>
<span class="sd">        if the given data is not C-contiguous.</span>

<span class="sd">    n_clusters : int</span>
<span class="sd">        The number of clusters to form as well as the number of</span>
<span class="sd">        centroids to generate.</span>

<span class="sd">    sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">        The weights for each observation in `X`. If `None`, all observations</span>
<span class="sd">        are assigned equal weight. `sample_weight` is not used during</span>
<span class="sd">        initialization if `init` is a callable or a user provided array.</span>

<span class="sd">    init : {&#39;k-means++&#39;, &#39;random&#39;}, callable or array-like of shape \</span>
<span class="sd">            (n_clusters, n_features), default=&#39;k-means++&#39;</span>
<span class="sd">        Method for initialization:</span>

<span class="sd">        - `&#39;k-means++&#39;` : selects initial cluster centers for k-mean</span>
<span class="sd">          clustering in a smart way to speed up convergence. See section</span>
<span class="sd">          Notes in k_init for more details.</span>
<span class="sd">        - `&#39;random&#39;`: choose `n_clusters` observations (rows) at random from data</span>
<span class="sd">          for the initial centroids.</span>
<span class="sd">        - If an array is passed, it should be of shape `(n_clusters, n_features)`</span>
<span class="sd">          and gives the initial centers.</span>
<span class="sd">        - If a callable is passed, it should take arguments `X`, `n_clusters` and a</span>
<span class="sd">          random state and return an initialization.</span>

<span class="sd">    n_init : &#39;auto&#39; or int, default=10</span>
<span class="sd">        Number of time the k-means algorithm will be run with different</span>
<span class="sd">        centroid seeds. The final results will be the best output of</span>
<span class="sd">        n_init consecutive runs in terms of inertia.</span>

<span class="sd">        When `n_init=&#39;auto&#39;`, the number of runs depends on the value of init:</span>
<span class="sd">        10 if using `init=&#39;random&#39;` or `init` is a callable;</span>
<span class="sd">        1 if using `init=&#39;k-means++&#39;` or `init` is an array-like.</span>

<span class="sd">        .. versionadded:: 1.2</span>
<span class="sd">           Added &#39;auto&#39; option for `n_init`.</span>

<span class="sd">        .. versionchanged:: 1.4</span>
<span class="sd">           Default value for `n_init` will change from 10 to `&#39;auto&#39;` in version 1.4.</span>

<span class="sd">    max_iter : int, default=300</span>
<span class="sd">        Maximum number of iterations of the k-means algorithm to run.</span>

<span class="sd">    verbose : bool, default=False</span>
<span class="sd">        Verbosity mode.</span>

<span class="sd">    tol : float, default=1e-4</span>
<span class="sd">        Relative tolerance with regards to Frobenius norm of the difference</span>
<span class="sd">        in the cluster centers of two consecutive iterations to declare</span>
<span class="sd">        convergence.</span>

<span class="sd">    random_state : int, RandomState instance or None, default=None</span>
<span class="sd">        Determines random number generation for centroid initialization. Use</span>
<span class="sd">        an int to make the randomness deterministic.</span>
<span class="sd">        See :term:`Glossary &lt;random_state&gt;`.</span>

<span class="sd">    copy_x : bool, default=True</span>
<span class="sd">        When pre-computing distances it is more numerically accurate to center</span>
<span class="sd">        the data first. If `copy_x` is True (default), then the original data is</span>
<span class="sd">        not modified. If False, the original data is modified, and put back</span>
<span class="sd">        before the function returns, but small numerical differences may be</span>
<span class="sd">        introduced by subtracting and then adding the data mean. Note that if</span>
<span class="sd">        the original data is not C-contiguous, a copy will be made even if</span>
<span class="sd">        `copy_x` is False. If the original data is sparse, but not in CSR format,</span>
<span class="sd">        a copy will be made even if `copy_x` is False.</span>

<span class="sd">    algorithm : {&quot;lloyd&quot;, &quot;elkan&quot;, &quot;auto&quot;, &quot;full&quot;}, default=&quot;lloyd&quot;</span>
<span class="sd">        K-means algorithm to use. The classical EM-style algorithm is `&quot;lloyd&quot;`.</span>
<span class="sd">        The `&quot;elkan&quot;` variation can be more efficient on some datasets with</span>
<span class="sd">        well-defined clusters, by using the triangle inequality. However it&#39;s</span>
<span class="sd">        more memory intensive due to the allocation of an extra array of shape</span>
<span class="sd">        `(n_samples, n_clusters)`.</span>

<span class="sd">        `&quot;auto&quot;` and `&quot;full&quot;` are deprecated and they will be removed in</span>
<span class="sd">        Scikit-Learn 1.3. They are both aliases for `&quot;lloyd&quot;`.</span>

<span class="sd">        .. versionchanged:: 0.18</span>
<span class="sd">            Added Elkan algorithm</span>

<span class="sd">        .. versionchanged:: 1.1</span>
<span class="sd">            Renamed &quot;full&quot; to &quot;lloyd&quot;, and deprecated &quot;auto&quot; and &quot;full&quot;.</span>
<span class="sd">            Changed &quot;auto&quot; to use &quot;lloyd&quot; instead of &quot;elkan&quot;.</span>

<span class="sd">    return_n_iter : bool, default=False</span>
<span class="sd">        Whether or not to return the number of iterations.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    centroid : ndarray of shape (n_clusters, n_features)</span>
<span class="sd">        Centroids found at the last iteration of k-means.</span>

<span class="sd">    label : ndarray of shape (n_samples,)</span>
<span class="sd">        The `label[i]` is the code or index of the centroid the</span>
<span class="sd">        i&#39;th observation is closest to.</span>

<span class="sd">    inertia : float</span>
<span class="sd">        The final value of the inertia criterion (sum of squared distances to</span>
<span class="sd">        the closest centroid for all observations in the training set).</span>

<span class="sd">    best_n_iter : int</span>
<span class="sd">        Number of iterations corresponding to the best results.</span>
<span class="sd">        Returned only if `return_n_iter` is set to True.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">est</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span>
        <span class="n">n_clusters</span><span class="o">=</span><span class="n">n_clusters</span><span class="p">,</span>
        <span class="n">init</span><span class="o">=</span><span class="n">init</span><span class="p">,</span>
        <span class="n">n_init</span><span class="o">=</span><span class="n">n_init</span><span class="p">,</span>
        <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
        <span class="n">tol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
        <span class="n">copy_x</span><span class="o">=</span><span class="n">copy_x</span><span class="p">,</span>
        <span class="n">algorithm</span><span class="o">=</span><span class="n">algorithm</span><span class="p">,</span>
    <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">return_n_iter</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">est</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">,</span> <span class="n">est</span><span class="o">.</span><span class="n">labels_</span><span class="p">,</span> <span class="n">est</span><span class="o">.</span><span class="n">inertia_</span><span class="p">,</span> <span class="n">est</span><span class="o">.</span><span class="n">n_iter_</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">est</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">,</span> <span class="n">est</span><span class="o">.</span><span class="n">labels_</span><span class="p">,</span> <span class="n">est</span><span class="o">.</span><span class="n">inertia_</span>


<span class="k">def</span> <span class="nf">_kmeans_single_elkan</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="p">,</span>
    <span class="n">centers_init</span><span class="p">,</span>
    <span class="n">max_iter</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">tol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
    <span class="n">n_threads</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A single run of k-means elkan, assumes preparation completed prior.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : {ndarray, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">        The observations to cluster. If sparse matrix, must be in CSR format.</span>

<span class="sd">    sample_weight : array-like of shape (n_samples,)</span>
<span class="sd">        The weights for each observation in X.</span>

<span class="sd">    centers_init : ndarray of shape (n_clusters, n_features)</span>
<span class="sd">        The initial centers.</span>

<span class="sd">    max_iter : int, default=300</span>
<span class="sd">        Maximum number of iterations of the k-means algorithm to run.</span>

<span class="sd">    verbose : bool, default=False</span>
<span class="sd">        Verbosity mode.</span>

<span class="sd">    tol : float, default=1e-4</span>
<span class="sd">        Relative tolerance with regards to Frobenius norm of the difference</span>
<span class="sd">        in the cluster centers of two consecutive iterations to declare</span>
<span class="sd">        convergence.</span>
<span class="sd">        It&#39;s not advised to set `tol=0` since convergence might never be</span>
<span class="sd">        declared due to rounding errors. Use a very small number instead.</span>

<span class="sd">    n_threads : int, default=1</span>
<span class="sd">        The number of OpenMP threads to use for the computation. Parallelism is</span>
<span class="sd">        sample-wise on the main cython loop which assigns each sample to its</span>
<span class="sd">        closest center.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    centroid : ndarray of shape (n_clusters, n_features)</span>
<span class="sd">        Centroids found at the last iteration of k-means.</span>

<span class="sd">    label : ndarray of shape (n_samples,)</span>
<span class="sd">        label[i] is the code or index of the centroid the</span>
<span class="sd">        i&#39;th observation is closest to.</span>

<span class="sd">    inertia : float</span>
<span class="sd">        The final value of the inertia criterion (sum of squared distances to</span>
<span class="sd">        the closest centroid for all observations in the training set).</span>

<span class="sd">    n_iter : int</span>
<span class="sd">        Number of iterations run.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">n_clusters</span> <span class="o">=</span> <span class="n">centers_init</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># Buffers to avoid new allocations at each iteration.</span>
    <span class="n">centers</span> <span class="o">=</span> <span class="n">centers_init</span>
    <span class="n">centers_new</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">centers</span><span class="p">)</span>
    <span class="n">weight_in_clusters</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">labels_old</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">center_half_distances</span> <span class="o">=</span> <span class="n">euclidean_distances</span><span class="p">(</span><span class="n">centers</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
    <span class="n">distance_next_center</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">partition</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">center_half_distances</span><span class="p">),</span> <span class="n">kth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span>
    <span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">upper_bounds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">lower_bounds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_clusters</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">center_shift</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">sp</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
        <span class="n">init_bounds</span> <span class="o">=</span> <span class="n">init_bounds_sparse</span>
        <span class="n">elkan_iter</span> <span class="o">=</span> <span class="n">elkan_iter_chunked_sparse</span>
        <span class="n">_inertia</span> <span class="o">=</span> <span class="n">_inertia_sparse</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">init_bounds</span> <span class="o">=</span> <span class="n">init_bounds_dense</span>
        <span class="n">elkan_iter</span> <span class="o">=</span> <span class="n">elkan_iter_chunked_dense</span>
        <span class="n">_inertia</span> <span class="o">=</span> <span class="n">_inertia_dense</span>

    <span class="n">init_bounds</span><span class="p">(</span>
        <span class="n">X</span><span class="p">,</span>
        <span class="n">centers</span><span class="p">,</span>
        <span class="n">center_half_distances</span><span class="p">,</span>
        <span class="n">labels</span><span class="p">,</span>
        <span class="n">upper_bounds</span><span class="p">,</span>
        <span class="n">lower_bounds</span><span class="p">,</span>
        <span class="n">n_threads</span><span class="o">=</span><span class="n">n_threads</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">strict_convergence</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
        <span class="n">elkan_iter</span><span class="p">(</span>
            <span class="n">X</span><span class="p">,</span>
            <span class="n">sample_weight</span><span class="p">,</span>
            <span class="n">centers</span><span class="p">,</span>
            <span class="n">centers_new</span><span class="p">,</span>
            <span class="n">weight_in_clusters</span><span class="p">,</span>
            <span class="n">center_half_distances</span><span class="p">,</span>
            <span class="n">distance_next_center</span><span class="p">,</span>
            <span class="n">upper_bounds</span><span class="p">,</span>
            <span class="n">lower_bounds</span><span class="p">,</span>
            <span class="n">labels</span><span class="p">,</span>
            <span class="n">center_shift</span><span class="p">,</span>
            <span class="n">n_threads</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># compute new pairwise distances between centers and closest other</span>
        <span class="c1"># center of each center for next iterations</span>
        <span class="n">center_half_distances</span> <span class="o">=</span> <span class="n">euclidean_distances</span><span class="p">(</span><span class="n">centers_new</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
        <span class="n">distance_next_center</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">partition</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">center_half_distances</span><span class="p">),</span> <span class="n">kth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span>
        <span class="p">)[</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="n">inertia</span> <span class="o">=</span> <span class="n">_inertia</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">,</span> <span class="n">centers</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">n_threads</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Iteration </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">, inertia </span><span class="si">{</span><span class="n">inertia</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">centers</span><span class="p">,</span> <span class="n">centers_new</span> <span class="o">=</span> <span class="n">centers_new</span><span class="p">,</span> <span class="n">centers</span>

        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">labels_old</span><span class="p">):</span>
            <span class="c1"># First check the labels for strict convergence.</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Converged at iteration </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: strict convergence.&quot;</span><span class="p">)</span>
            <span class="n">strict_convergence</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">break</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># No strict convergence, check for tol based convergence.</span>
            <span class="n">center_shift_tot</span> <span class="o">=</span> <span class="p">(</span><span class="n">center_shift</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">center_shift_tot</span> <span class="o">&lt;=</span> <span class="n">tol</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Converged at iteration </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: center shift &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">center_shift_tot</span><span class="si">}</span><span class="s2"> within tolerance </span><span class="si">{</span><span class="n">tol</span><span class="si">}</span><span class="s2">.&quot;</span>
                    <span class="p">)</span>
                <span class="k">break</span>

        <span class="n">labels_old</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">labels</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">strict_convergence</span><span class="p">:</span>
        <span class="c1"># rerun E-step so that predicted labels match cluster centers</span>
        <span class="n">elkan_iter</span><span class="p">(</span>
            <span class="n">X</span><span class="p">,</span>
            <span class="n">sample_weight</span><span class="p">,</span>
            <span class="n">centers</span><span class="p">,</span>
            <span class="n">centers</span><span class="p">,</span>
            <span class="n">weight_in_clusters</span><span class="p">,</span>
            <span class="n">center_half_distances</span><span class="p">,</span>
            <span class="n">distance_next_center</span><span class="p">,</span>
            <span class="n">upper_bounds</span><span class="p">,</span>
            <span class="n">lower_bounds</span><span class="p">,</span>
            <span class="n">labels</span><span class="p">,</span>
            <span class="n">center_shift</span><span class="p">,</span>
            <span class="n">n_threads</span><span class="p">,</span>
            <span class="n">update_centers</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="n">inertia</span> <span class="o">=</span> <span class="n">_inertia</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">,</span> <span class="n">centers</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">n_threads</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">labels</span><span class="p">,</span> <span class="n">inertia</span><span class="p">,</span> <span class="n">centers</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>


<span class="k">def</span> <span class="nf">_kmeans_single_lloyd</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="p">,</span>
    <span class="n">centers_init</span><span class="p">,</span>
    <span class="n">max_iter</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">tol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
    <span class="n">n_threads</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A single run of k-means lloyd, assumes preparation completed prior.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : {ndarray, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">        The observations to cluster. If sparse matrix, must be in CSR format.</span>

<span class="sd">    sample_weight : ndarray of shape (n_samples,)</span>
<span class="sd">        The weights for each observation in X.</span>

<span class="sd">    centers_init : ndarray of shape (n_clusters, n_features)</span>
<span class="sd">        The initial centers.</span>

<span class="sd">    max_iter : int, default=300</span>
<span class="sd">        Maximum number of iterations of the k-means algorithm to run.</span>

<span class="sd">    verbose : bool, default=False</span>
<span class="sd">        Verbosity mode</span>

<span class="sd">    tol : float, default=1e-4</span>
<span class="sd">        Relative tolerance with regards to Frobenius norm of the difference</span>
<span class="sd">        in the cluster centers of two consecutive iterations to declare</span>
<span class="sd">        convergence.</span>
<span class="sd">        It&#39;s not advised to set `tol=0` since convergence might never be</span>
<span class="sd">        declared due to rounding errors. Use a very small number instead.</span>

<span class="sd">    n_threads : int, default=1</span>
<span class="sd">        The number of OpenMP threads to use for the computation. Parallelism is</span>
<span class="sd">        sample-wise on the main cython loop which assigns each sample to its</span>
<span class="sd">        closest center.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    centroid : ndarray of shape (n_clusters, n_features)</span>
<span class="sd">        Centroids found at the last iteration of k-means.</span>

<span class="sd">    label : ndarray of shape (n_samples,)</span>
<span class="sd">        label[i] is the code or index of the centroid the</span>
<span class="sd">        i&#39;th observation is closest to.</span>

<span class="sd">    inertia : float</span>
<span class="sd">        The final value of the inertia criterion (sum of squared distances to</span>
<span class="sd">        the closest centroid for all observations in the training set).</span>

<span class="sd">    n_iter : int</span>
<span class="sd">        Number of iterations run.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_clusters</span> <span class="o">=</span> <span class="n">centers_init</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># Buffers to avoid new allocations at each iteration.</span>
    <span class="n">centers</span> <span class="o">=</span> <span class="n">centers_init</span>
    <span class="n">centers_new</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">centers</span><span class="p">)</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">labels_old</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">weight_in_clusters</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">center_shift</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">sp</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
        <span class="n">lloyd_iter</span> <span class="o">=</span> <span class="n">lloyd_iter_chunked_sparse</span>
        <span class="n">_inertia</span> <span class="o">=</span> <span class="n">_inertia_sparse</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">lloyd_iter</span> <span class="o">=</span> <span class="n">lloyd_iter_chunked_dense</span>
        <span class="n">_inertia</span> <span class="o">=</span> <span class="n">_inertia_dense</span>

    <span class="n">strict_convergence</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># Threadpoolctl context to limit the number of threads in second level of</span>
    <span class="c1"># nested parallelism (i.e. BLAS) to avoid oversubscription.</span>
    <span class="k">with</span> <span class="n">threadpool_limits</span><span class="p">(</span><span class="n">limits</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">user_api</span><span class="o">=</span><span class="s2">&quot;blas&quot;</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
            <span class="n">lloyd_iter</span><span class="p">(</span>
                <span class="n">X</span><span class="p">,</span>
                <span class="n">sample_weight</span><span class="p">,</span>
                <span class="n">centers</span><span class="p">,</span>
                <span class="n">centers_new</span><span class="p">,</span>
                <span class="n">weight_in_clusters</span><span class="p">,</span>
                <span class="n">labels</span><span class="p">,</span>
                <span class="n">center_shift</span><span class="p">,</span>
                <span class="n">n_threads</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="n">inertia</span> <span class="o">=</span> <span class="n">_inertia</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">,</span> <span class="n">centers</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">n_threads</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Iteration </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">, inertia </span><span class="si">{</span><span class="n">inertia</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

            <span class="n">centers</span><span class="p">,</span> <span class="n">centers_new</span> <span class="o">=</span> <span class="n">centers_new</span><span class="p">,</span> <span class="n">centers</span>

            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">labels_old</span><span class="p">):</span>
                <span class="c1"># First check the labels for strict convergence.</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Converged at iteration </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: strict convergence.&quot;</span><span class="p">)</span>
                <span class="n">strict_convergence</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">break</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># No strict convergence, check for tol based convergence.</span>
                <span class="n">center_shift_tot</span> <span class="o">=</span> <span class="p">(</span><span class="n">center_shift</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">center_shift_tot</span> <span class="o">&lt;=</span> <span class="n">tol</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Converged at iteration </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: center shift &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">center_shift_tot</span><span class="si">}</span><span class="s2"> within tolerance </span><span class="si">{</span><span class="n">tol</span><span class="si">}</span><span class="s2">.&quot;</span>
                        <span class="p">)</span>
                    <span class="k">break</span>

            <span class="n">labels_old</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">labels</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">strict_convergence</span><span class="p">:</span>
            <span class="c1"># rerun E-step so that predicted labels match cluster centers</span>
            <span class="n">lloyd_iter</span><span class="p">(</span>
                <span class="n">X</span><span class="p">,</span>
                <span class="n">sample_weight</span><span class="p">,</span>
                <span class="n">centers</span><span class="p">,</span>
                <span class="n">centers</span><span class="p">,</span>
                <span class="n">weight_in_clusters</span><span class="p">,</span>
                <span class="n">labels</span><span class="p">,</span>
                <span class="n">center_shift</span><span class="p">,</span>
                <span class="n">n_threads</span><span class="p">,</span>
                <span class="n">update_centers</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="n">inertia</span> <span class="o">=</span> <span class="n">_inertia</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">,</span> <span class="n">centers</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">n_threads</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">labels</span><span class="p">,</span> <span class="n">inertia</span><span class="p">,</span> <span class="n">centers</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>


<span class="k">def</span> <span class="nf">_labels_inertia</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">,</span> <span class="n">centers</span><span class="p">,</span> <span class="n">n_threads</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_inertia</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;E step of the K-means EM algorithm.</span>

<span class="sd">    Compute the labels and the inertia of the given samples and centers.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : {ndarray, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">        The input samples to assign to the labels. If sparse matrix, must</span>
<span class="sd">        be in CSR format.</span>

<span class="sd">    sample_weight : ndarray of shape (n_samples,)</span>
<span class="sd">        The weights for each observation in X.</span>

<span class="sd">    x_squared_norms : ndarray of shape (n_samples,)</span>
<span class="sd">        Precomputed squared euclidean norm of each data point, to speed up</span>
<span class="sd">        computations.</span>

<span class="sd">    centers : ndarray of shape (n_clusters, n_features)</span>
<span class="sd">        The cluster centers.</span>

<span class="sd">    n_threads : int, default=1</span>
<span class="sd">        The number of OpenMP threads to use for the computation. Parallelism is</span>
<span class="sd">        sample-wise on the main cython loop which assigns each sample to its</span>
<span class="sd">        closest center.</span>

<span class="sd">    return_inertia : bool, default=True</span>
<span class="sd">        Whether to compute and return the inertia.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    labels : ndarray of shape (n_samples,)</span>
<span class="sd">        The resulting assignment.</span>

<span class="sd">    inertia : float</span>
<span class="sd">        Sum of squared distances of samples to their closest cluster center.</span>
<span class="sd">        Inertia is only returned if return_inertia is True.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">n_clusters</span> <span class="o">=</span> <span class="n">centers</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">center_shift</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">centers</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">sp</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
        <span class="n">_labels</span> <span class="o">=</span> <span class="n">lloyd_iter_chunked_sparse</span>
        <span class="n">_inertia</span> <span class="o">=</span> <span class="n">_inertia_sparse</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">_labels</span> <span class="o">=</span> <span class="n">lloyd_iter_chunked_dense</span>
        <span class="n">_inertia</span> <span class="o">=</span> <span class="n">_inertia_dense</span>

    <span class="n">_labels</span><span class="p">(</span>
        <span class="n">X</span><span class="p">,</span>
        <span class="n">sample_weight</span><span class="p">,</span>
        <span class="n">centers</span><span class="p">,</span>
        <span class="n">centers_new</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">weight_in_clusters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
        <span class="n">center_shift</span><span class="o">=</span><span class="n">center_shift</span><span class="p">,</span>
        <span class="n">n_threads</span><span class="o">=</span><span class="n">n_threads</span><span class="p">,</span>
        <span class="n">update_centers</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">return_inertia</span><span class="p">:</span>
        <span class="n">inertia</span> <span class="o">=</span> <span class="n">_inertia</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">,</span> <span class="n">centers</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">n_threads</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">labels</span><span class="p">,</span> <span class="n">inertia</span>

    <span class="k">return</span> <span class="n">labels</span>


<span class="k">def</span> <span class="nf">_labels_inertia_threadpool_limit</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">,</span> <span class="n">centers</span><span class="p">,</span> <span class="n">n_threads</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_inertia</span><span class="o">=</span><span class="kc">True</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Same as _labels_inertia but in a threadpool_limits context.&quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">threadpool_limits</span><span class="p">(</span><span class="n">limits</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">user_api</span><span class="o">=</span><span class="s2">&quot;blas&quot;</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_labels_inertia</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">,</span> <span class="n">centers</span><span class="p">,</span> <span class="n">n_threads</span><span class="p">,</span> <span class="n">return_inertia</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">result</span>


<span class="k">class</span> <span class="nc">_BaseKMeans</span><span class="p">(</span>
    <span class="n">ClassNamePrefixFeaturesOutMixin</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">,</span> <span class="n">ClusterMixin</span><span class="p">,</span> <span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">ABC</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Base class for KMeans and MiniBatchKMeans&quot;&quot;&quot;</span>

    <span class="n">_parameter_constraints</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;n_clusters&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Interval</span><span class="p">(</span><span class="n">Integral</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">closed</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">)],</span>
        <span class="s2">&quot;init&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">StrOptions</span><span class="p">({</span><span class="s2">&quot;k-means++&quot;</span><span class="p">,</span> <span class="s2">&quot;random&quot;</span><span class="p">}),</span> <span class="nb">callable</span><span class="p">,</span> <span class="s2">&quot;array-like&quot;</span><span class="p">],</span>
        <span class="s2">&quot;n_init&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="n">StrOptions</span><span class="p">({</span><span class="s2">&quot;auto&quot;</span><span class="p">}),</span>
            <span class="n">Hidden</span><span class="p">(</span><span class="n">StrOptions</span><span class="p">({</span><span class="s2">&quot;warn&quot;</span><span class="p">})),</span>
            <span class="n">Interval</span><span class="p">(</span><span class="n">Integral</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">closed</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">),</span>
        <span class="p">],</span>
        <span class="s2">&quot;max_iter&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Interval</span><span class="p">(</span><span class="n">Integral</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">closed</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">)],</span>
        <span class="s2">&quot;tol&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Interval</span><span class="p">(</span><span class="n">Real</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">closed</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">)],</span>
        <span class="s2">&quot;verbose&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;verbose&quot;</span><span class="p">],</span>
        <span class="s2">&quot;random_state&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;random_state&quot;</span><span class="p">],</span>
    <span class="p">}</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">n_clusters</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">init</span><span class="p">,</span>
        <span class="n">n_init</span><span class="p">,</span>
        <span class="n">max_iter</span><span class="p">,</span>
        <span class="n">tol</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">,</span>
        <span class="n">random_state</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="n">n_clusters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init</span> <span class="o">=</span> <span class="n">init</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tol</span> <span class="o">=</span> <span class="n">tol</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_init</span> <span class="o">=</span> <span class="n">n_init</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>

    <span class="k">def</span> <span class="nf">_check_params_vs_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">default_n_init</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># n_clusters</span>
        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;n_samples=</span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> should be &gt;= n_clusters=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># tol</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tol</span> <span class="o">=</span> <span class="n">_tolerance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">)</span>

        <span class="c1"># n-init</span>
        <span class="c1"># TODO(1.4): Remove</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_n_init</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_init</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_init</span> <span class="o">==</span> <span class="s2">&quot;warn&quot;</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="p">(</span>
                    <span class="s2">&quot;The default value of `n_init` will change from &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">default_n_init</span><span class="si">}</span><span class="s2"> to &#39;auto&#39; in 1.4. Set the value of `n_init`&quot;</span>
                    <span class="s2">&quot; explicitly to suppress the warning&quot;</span>
                <span class="p">),</span>
                <span class="ne">FutureWarning</span><span class="p">,</span>
                <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_n_init</span> <span class="o">=</span> <span class="n">default_n_init</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_init</span> <span class="o">==</span> <span class="s2">&quot;auto&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">init</span> <span class="o">==</span> <span class="s2">&quot;k-means++&quot;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_n_init</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">init</span> <span class="o">==</span> <span class="s2">&quot;random&quot;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_n_init</span> <span class="o">=</span> <span class="n">default_n_init</span>
            <span class="k">elif</span> <span class="nb">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_n_init</span> <span class="o">=</span> <span class="n">default_n_init</span>
            <span class="k">else</span><span class="p">:</span>  <span class="c1"># array-like</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_n_init</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="n">_is_arraylike_not_scalar</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_init</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="p">(</span>
                    <span class="s2">&quot;Explicit initial center position passed: performing only&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot; one init in </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> instead of &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;n_init=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_init</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">),</span>
                <span class="ne">RuntimeWarning</span><span class="p">,</span>
                <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_n_init</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">_warn_mkl_vcomp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_active_threads</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Issue an estimator specific warning when vcomp and mkl are both present</span>

<span class="sd">        This method is called by `_check_mkl_vcomp`.</span>
<span class="sd">        &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">_check_mkl_vcomp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Check when vcomp and mkl are both present&quot;&quot;&quot;</span>
        <span class="c1"># The BLAS call inside a prange in lloyd_iter_chunked_dense is known to</span>
        <span class="c1"># cause a small memory leak when there are less chunks than the number</span>
        <span class="c1"># of available threads. It only happens when the OpenMP library is</span>
        <span class="c1"># vcomp (microsoft OpenMP) and the BLAS library is MKL. see #18653</span>
        <span class="k">if</span> <span class="n">sp</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
            <span class="k">return</span>

        <span class="n">n_active_threads</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">n_samples</span> <span class="o">/</span> <span class="n">CHUNK_SIZE</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">n_active_threads</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_threads</span><span class="p">:</span>
            <span class="n">modules</span> <span class="o">=</span> <span class="n">threadpool_info</span><span class="p">()</span>
            <span class="n">has_vcomp</span> <span class="o">=</span> <span class="s2">&quot;vcomp&quot;</span> <span class="ow">in</span> <span class="p">[</span><span class="n">module</span><span class="p">[</span><span class="s2">&quot;prefix&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">modules</span><span class="p">]</span>
            <span class="n">has_mkl</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;mkl&quot;</span><span class="p">,</span> <span class="s2">&quot;intel&quot;</span><span class="p">)</span> <span class="ow">in</span> <span class="p">[</span>
                <span class="p">(</span><span class="n">module</span><span class="p">[</span><span class="s2">&quot;internal_api&quot;</span><span class="p">],</span> <span class="n">module</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;threading_layer&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>
                <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">modules</span>
            <span class="p">]</span>
            <span class="k">if</span> <span class="n">has_vcomp</span> <span class="ow">and</span> <span class="n">has_mkl</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_warn_mkl_vcomp</span><span class="p">(</span><span class="n">n_active_threads</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_validate_center_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">centers</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Check if centers is compatible with X and n_clusters.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">centers</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The shape of the initial centers </span><span class="si">{</span><span class="n">centers</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> does not &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;match the number of clusters </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">centers</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The shape of the initial centers </span><span class="si">{</span><span class="n">centers</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> does not &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;match the number of features of the data </span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_check_test_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_data</span><span class="p">(</span>
            <span class="n">X</span><span class="p">,</span>
            <span class="n">accept_sparse</span><span class="o">=</span><span class="s2">&quot;csr&quot;</span><span class="p">,</span>
            <span class="n">reset</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">],</span>
            <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">,</span>
            <span class="n">accept_large_sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">X</span>

    <span class="k">def</span> <span class="nf">_init_centroids</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X</span><span class="p">,</span>
        <span class="n">x_squared_norms</span><span class="p">,</span>
        <span class="n">init</span><span class="p">,</span>
        <span class="n">random_state</span><span class="p">,</span>
        <span class="n">sample_weight</span><span class="p">,</span>
        <span class="n">init_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">n_centroids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute the initial centroids.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : {ndarray, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">            The input samples.</span>

<span class="sd">        x_squared_norms : ndarray of shape (n_samples,)</span>
<span class="sd">            Squared euclidean norm of each data point. Pass it if you have it</span>
<span class="sd">            at hands already to avoid it being recomputed here.</span>

<span class="sd">        init : {&#39;k-means++&#39;, &#39;random&#39;}, callable or ndarray of shape \</span>
<span class="sd">                (n_clusters, n_features)</span>
<span class="sd">            Method for initialization.</span>

<span class="sd">        random_state : RandomState instance</span>
<span class="sd">            Determines random number generation for centroid initialization.</span>
<span class="sd">            See :term:`Glossary &lt;random_state&gt;`.</span>

<span class="sd">        sample_weight : ndarray of shape (n_samples,)</span>
<span class="sd">            The weights for each observation in X. `sample_weight` is not used</span>
<span class="sd">            during initialization if `init` is a callable or a user provided</span>
<span class="sd">            array.</span>

<span class="sd">        init_size : int, default=None</span>
<span class="sd">            Number of samples to randomly sample for speeding up the</span>
<span class="sd">            initialization (sometimes at the expense of accuracy).</span>

<span class="sd">        n_centroids : int, default=None</span>
<span class="sd">            Number of centroids to initialize.</span>
<span class="sd">            If left to &#39;None&#39; the number of centroids will be equal to</span>
<span class="sd">            number of clusters to form (self.n_clusters).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        centers : ndarray of shape (n_clusters, n_features)</span>
<span class="sd">            Initial centroids of clusters.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">n_clusters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="k">if</span> <span class="n">n_centroids</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">n_centroids</span>

        <span class="k">if</span> <span class="n">init_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">init_size</span> <span class="o">&lt;</span> <span class="n">n_samples</span><span class="p">:</span>
            <span class="n">init_indices</span> <span class="o">=</span> <span class="n">random_state</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">init_size</span><span class="p">)</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">init_indices</span><span class="p">]</span>
            <span class="n">x_squared_norms</span> <span class="o">=</span> <span class="n">x_squared_norms</span><span class="p">[</span><span class="n">init_indices</span><span class="p">]</span>
            <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">sample_weight</span><span class="p">[</span><span class="n">init_indices</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">init</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">init</span> <span class="o">==</span> <span class="s2">&quot;k-means++&quot;</span><span class="p">:</span>
            <span class="n">centers</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">_kmeans_plusplus</span><span class="p">(</span>
                <span class="n">X</span><span class="p">,</span>
                <span class="n">n_clusters</span><span class="p">,</span>
                <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
                <span class="n">x_squared_norms</span><span class="o">=</span><span class="n">x_squared_norms</span><span class="p">,</span>
                <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">init</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">init</span> <span class="o">==</span> <span class="s2">&quot;random&quot;</span><span class="p">:</span>
            <span class="n">seeds</span> <span class="o">=</span> <span class="n">random_state</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span>
                <span class="n">n_samples</span><span class="p">,</span>
                <span class="n">size</span><span class="o">=</span><span class="n">n_clusters</span><span class="p">,</span>
                <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">p</span><span class="o">=</span><span class="n">sample_weight</span> <span class="o">/</span> <span class="n">sample_weight</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span>
            <span class="p">)</span>
            <span class="n">centers</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">seeds</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">_is_arraylike_not_scalar</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init</span><span class="p">):</span>
            <span class="n">centers</span> <span class="o">=</span> <span class="n">init</span>
        <span class="k">elif</span> <span class="nb">callable</span><span class="p">(</span><span class="n">init</span><span class="p">):</span>
            <span class="n">centers</span> <span class="o">=</span> <span class="n">init</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">n_clusters</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>
            <span class="n">centers</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">centers</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_validate_center_shape</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">centers</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">sp</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">centers</span><span class="p">):</span>
            <span class="n">centers</span> <span class="o">=</span> <span class="n">centers</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">centers</span>

    <span class="k">def</span> <span class="nf">fit_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute cluster centers and predict cluster index for each sample.</span>

<span class="sd">        Convenience method; equivalent to calling fit(X) followed by</span>
<span class="sd">        predict(X).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : {array-like, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">            New data to transform.</span>

<span class="sd">        y : Ignored</span>
<span class="sd">            Not used, present here for API consistency by convention.</span>

<span class="sd">        sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">            The weights for each observation in X. If None, all observations</span>
<span class="sd">            are assigned equal weight.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        labels : ndarray of shape (n_samples,)</span>
<span class="sd">            Index of the cluster each sample belongs to.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span><span class="o">.</span><span class="n">labels_</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="s2">&quot;deprecated&quot;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict the closest cluster each sample in X belongs to.</span>

<span class="sd">        In the vector quantization literature, `cluster_centers_` is called</span>
<span class="sd">        the code book and each value returned by `predict` is the index of</span>
<span class="sd">        the closest code in the code book.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : {array-like, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">            New data to predict.</span>

<span class="sd">        sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">            The weights for each observation in X. If None, all observations</span>
<span class="sd">            are assigned equal weight.</span>

<span class="sd">            .. deprecated:: 1.3</span>
<span class="sd">               The parameter `sample_weight` is deprecated in version 1.3</span>
<span class="sd">               and will be removed in 1.5.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        labels : ndarray of shape (n_samples,)</span>
<span class="sd">            Index of the cluster each sample belongs to.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_test_data</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">sample_weight</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">sample_weight</span> <span class="o">==</span> <span class="s2">&quot;deprecated&quot;</span><span class="p">):</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="p">(</span>
                    <span class="s2">&quot;&#39;sample_weight&#39; was deprecated in version 1.3 and &quot;</span>
                    <span class="s2">&quot;will be removed in 1.5.&quot;</span>
                <span class="p">),</span>
                <span class="ne">FutureWarning</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">_check_sample_weight</span><span class="p">(</span><span class="n">sample_weight</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">_check_sample_weight</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

        <span class="n">labels</span> <span class="o">=</span> <span class="n">_labels_inertia_threadpool_limit</span><span class="p">(</span>
            <span class="n">X</span><span class="p">,</span>
            <span class="n">sample_weight</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">,</span>
            <span class="n">n_threads</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_threads</span><span class="p">,</span>
            <span class="n">return_inertia</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">labels</span>

    <span class="k">def</span> <span class="nf">fit_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute clustering and transform X to cluster-distance space.</span>

<span class="sd">        Equivalent to fit(X).transform(X), but more efficiently implemented.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : {array-like, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">            New data to transform.</span>

<span class="sd">        y : Ignored</span>
<span class="sd">            Not used, present here for API consistency by convention.</span>

<span class="sd">        sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">            The weights for each observation in X. If None, all observations</span>
<span class="sd">            are assigned equal weight.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        X_new : ndarray of shape (n_samples, n_clusters)</span>
<span class="sd">            X transformed in the new space.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span><span class="o">.</span><span class="n">_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transform X to a cluster-distance space.</span>

<span class="sd">        In the new space, each dimension is the distance to the cluster</span>
<span class="sd">        centers. Note that even if X is sparse, the array returned by</span>
<span class="sd">        `transform` will typically be dense.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : {array-like, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">            New data to transform.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        X_new : ndarray of shape (n_samples, n_clusters)</span>
<span class="sd">            X transformed in the new space.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_test_data</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Guts of transform method; no input validation.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">euclidean_distances</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Opposite of the value of X on the K-means objective.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : {array-like, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">            New data.</span>

<span class="sd">        y : Ignored</span>
<span class="sd">            Not used, present here for API consistency by convention.</span>

<span class="sd">        sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">            The weights for each observation in X. If None, all observations</span>
<span class="sd">            are assigned equal weight.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score : float</span>
<span class="sd">            Opposite of the value of X on the K-means objective.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_test_data</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">_check_sample_weight</span><span class="p">(</span><span class="n">sample_weight</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

        <span class="n">_</span><span class="p">,</span> <span class="n">scores</span> <span class="o">=</span> <span class="n">_labels_inertia_threadpool_limit</span><span class="p">(</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_threads</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">scores</span>

    <span class="k">def</span> <span class="nf">_more_tags</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;_xfail_checks&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;check_sample_weights_invariance&quot;</span><span class="p">:</span> <span class="p">(</span>
                    <span class="s2">&quot;zero sample_weight is not equivalent to removing samples&quot;</span>
                <span class="p">),</span>
            <span class="p">},</span>
        <span class="p">}</span>


<div class="viewcode-block" id="KMeans"><a class="viewcode-back" href="../../../guide/reference/_autosummary/otx.algorithms.detection.adapters.mmdet.utils.config_utils.html#otx.algorithms.detection.adapters.mmdet.utils.config_utils.KMeans">[docs]</a><span class="k">class</span> <span class="nc">KMeans</span><span class="p">(</span><span class="n">_BaseKMeans</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;K-Means clustering.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;k_means&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    n_clusters : int, default=8</span>
<span class="sd">        The number of clusters to form as well as the number of</span>
<span class="sd">        centroids to generate.</span>

<span class="sd">    init : {&#39;k-means++&#39;, &#39;random&#39;}, callable or array-like of shape \</span>
<span class="sd">            (n_clusters, n_features), default=&#39;k-means++&#39;</span>
<span class="sd">        Method for initialization:</span>

<span class="sd">        * &#39;k-means++&#39; : selects initial cluster centroids using sampling \</span>
<span class="sd">            based on an empirical probability distribution of the points&#39; \</span>
<span class="sd">            contribution to the overall inertia. This technique speeds up \</span>
<span class="sd">            convergence. The algorithm implemented is &quot;greedy k-means++&quot;. It \</span>
<span class="sd">            differs from the vanilla k-means++ by making several trials at \</span>
<span class="sd">            each sampling step and choosing the best centroid among them.</span>

<span class="sd">        * &#39;random&#39;: choose `n_clusters` observations (rows) at random from \</span>
<span class="sd">        data for the initial centroids.</span>

<span class="sd">        * If an array is passed, it should be of shape (n_clusters, n_features)\</span>
<span class="sd">        and gives the initial centers.</span>

<span class="sd">        * If a callable is passed, it should take arguments X, n_clusters and a\</span>
<span class="sd">        random state and return an initialization.</span>

<span class="sd">        For an example of how to use the different `init` strategy, see the example</span>
<span class="sd">        entitled :ref:`sphx_glr_auto_examples_cluster_plot_kmeans_digits.py`.</span>

<span class="sd">    n_init : &#39;auto&#39; or int, default=10</span>
<span class="sd">        Number of times the k-means algorithm is run with different centroid</span>
<span class="sd">        seeds. The final results is the best output of `n_init` consecutive runs</span>
<span class="sd">        in terms of inertia. Several runs are recommended for sparse</span>
<span class="sd">        high-dimensional problems (see :ref:`kmeans_sparse_high_dim`).</span>

<span class="sd">        When `n_init=&#39;auto&#39;`, the number of runs depends on the value of init:</span>
<span class="sd">        10 if using `init=&#39;random&#39;` or `init` is a callable;</span>
<span class="sd">        1 if using `init=&#39;k-means++&#39;` or `init` is an array-like.</span>

<span class="sd">        .. versionadded:: 1.2</span>
<span class="sd">           Added &#39;auto&#39; option for `n_init`.</span>

<span class="sd">        .. versionchanged:: 1.4</span>
<span class="sd">           Default value for `n_init` will change from 10 to `&#39;auto&#39;` in version 1.4.</span>

<span class="sd">    max_iter : int, default=300</span>
<span class="sd">        Maximum number of iterations of the k-means algorithm for a</span>
<span class="sd">        single run.</span>

<span class="sd">    tol : float, default=1e-4</span>
<span class="sd">        Relative tolerance with regards to Frobenius norm of the difference</span>
<span class="sd">        in the cluster centers of two consecutive iterations to declare</span>
<span class="sd">        convergence.</span>

<span class="sd">    verbose : int, default=0</span>
<span class="sd">        Verbosity mode.</span>

<span class="sd">    random_state : int, RandomState instance or None, default=None</span>
<span class="sd">        Determines random number generation for centroid initialization. Use</span>
<span class="sd">        an int to make the randomness deterministic.</span>
<span class="sd">        See :term:`Glossary &lt;random_state&gt;`.</span>

<span class="sd">    copy_x : bool, default=True</span>
<span class="sd">        When pre-computing distances it is more numerically accurate to center</span>
<span class="sd">        the data first. If copy_x is True (default), then the original data is</span>
<span class="sd">        not modified. If False, the original data is modified, and put back</span>
<span class="sd">        before the function returns, but small numerical differences may be</span>
<span class="sd">        introduced by subtracting and then adding the data mean. Note that if</span>
<span class="sd">        the original data is not C-contiguous, a copy will be made even if</span>
<span class="sd">        copy_x is False. If the original data is sparse, but not in CSR format,</span>
<span class="sd">        a copy will be made even if copy_x is False.</span>

<span class="sd">    algorithm : {&quot;lloyd&quot;, &quot;elkan&quot;, &quot;auto&quot;, &quot;full&quot;}, default=&quot;lloyd&quot;</span>
<span class="sd">        K-means algorithm to use. The classical EM-style algorithm is `&quot;lloyd&quot;`.</span>
<span class="sd">        The `&quot;elkan&quot;` variation can be more efficient on some datasets with</span>
<span class="sd">        well-defined clusters, by using the triangle inequality. However it&#39;s</span>
<span class="sd">        more memory intensive due to the allocation of an extra array of shape</span>
<span class="sd">        `(n_samples, n_clusters)`.</span>

<span class="sd">        `&quot;auto&quot;` and `&quot;full&quot;` are deprecated and they will be removed in</span>
<span class="sd">        Scikit-Learn 1.3. They are both aliases for `&quot;lloyd&quot;`.</span>

<span class="sd">        .. versionchanged:: 0.18</span>
<span class="sd">            Added Elkan algorithm</span>

<span class="sd">        .. versionchanged:: 1.1</span>
<span class="sd">            Renamed &quot;full&quot; to &quot;lloyd&quot;, and deprecated &quot;auto&quot; and &quot;full&quot;.</span>
<span class="sd">            Changed &quot;auto&quot; to use &quot;lloyd&quot; instead of &quot;elkan&quot;.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    cluster_centers_ : ndarray of shape (n_clusters, n_features)</span>
<span class="sd">        Coordinates of cluster centers. If the algorithm stops before fully</span>
<span class="sd">        converging (see ``tol`` and ``max_iter``), these will not be</span>
<span class="sd">        consistent with ``labels_``.</span>

<span class="sd">    labels_ : ndarray of shape (n_samples,)</span>
<span class="sd">        Labels of each point</span>

<span class="sd">    inertia_ : float</span>
<span class="sd">        Sum of squared distances of samples to their closest cluster center,</span>
<span class="sd">        weighted by the sample weights if provided.</span>

<span class="sd">    n_iter_ : int</span>
<span class="sd">        Number of iterations run.</span>

<span class="sd">    n_features_in_ : int</span>
<span class="sd">        Number of features seen during :term:`fit`.</span>

<span class="sd">        .. versionadded:: 0.24</span>

<span class="sd">    feature_names_in_ : ndarray of shape (`n_features_in_`,)</span>
<span class="sd">        Names of features seen during :term:`fit`. Defined only when `X`</span>
<span class="sd">        has feature names that are all strings.</span>

<span class="sd">        .. versionadded:: 1.0</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    MiniBatchKMeans : Alternative online implementation that does incremental</span>
<span class="sd">        updates of the centers positions using mini-batches.</span>
<span class="sd">        For large scale learning (say n_samples &gt; 10k) MiniBatchKMeans is</span>
<span class="sd">        probably much faster than the default batch implementation.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The k-means problem is solved using either Lloyd&#39;s or Elkan&#39;s algorithm.</span>

<span class="sd">    The average complexity is given by O(k n T), where n is the number of</span>
<span class="sd">    samples and T is the number of iteration.</span>

<span class="sd">    The worst case complexity is given by O(n^(k+2/p)) with</span>
<span class="sd">    n = n_samples, p = n_features.</span>
<span class="sd">    Refer to :doi:`&quot;How slow is the k-means method?&quot; D. Arthur and S. Vassilvitskii -</span>
<span class="sd">    SoCG2006.&lt;10.1145/1137856.1137880&gt;` for more details.</span>

<span class="sd">    In practice, the k-means algorithm is very fast (one of the fastest</span>
<span class="sd">    clustering algorithms available), but it falls in local minima. That&#39;s why</span>
<span class="sd">    it can be useful to restart it several times.</span>

<span class="sd">    If the algorithm stops before fully converging (because of ``tol`` or</span>
<span class="sd">    ``max_iter``), ``labels_`` and ``cluster_centers_`` will not be consistent,</span>
<span class="sd">    i.e. the ``cluster_centers_`` will not be the means of the points in each</span>
<span class="sd">    cluster. Also, the estimator will reassign ``labels_`` after the last</span>
<span class="sd">    iteration to make ``labels_`` consistent with ``predict`` on the training</span>
<span class="sd">    set.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    &gt;&gt;&gt; from sklearn.cluster import KMeans</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [1, 4], [1, 0],</span>
<span class="sd">    ...               [10, 2], [10, 4], [10, 0]])</span>
<span class="sd">    &gt;&gt;&gt; kmeans = KMeans(n_clusters=2, random_state=0, n_init=&quot;auto&quot;).fit(X)</span>
<span class="sd">    &gt;&gt;&gt; kmeans.labels_</span>
<span class="sd">    array([1, 1, 1, 0, 0, 0], dtype=int32)</span>
<span class="sd">    &gt;&gt;&gt; kmeans.predict([[0, 0], [12, 3]])</span>
<span class="sd">    array([1, 0], dtype=int32)</span>
<span class="sd">    &gt;&gt;&gt; kmeans.cluster_centers_</span>
<span class="sd">    array([[10.,  2.],</span>
<span class="sd">           [ 1.,  2.]])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_parameter_constraints</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{</span>
        <span class="o">**</span><span class="n">_BaseKMeans</span><span class="o">.</span><span class="n">_parameter_constraints</span><span class="p">,</span>
        <span class="s2">&quot;copy_x&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;boolean&quot;</span><span class="p">],</span>
        <span class="s2">&quot;algorithm&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="n">StrOptions</span><span class="p">({</span><span class="s2">&quot;lloyd&quot;</span><span class="p">,</span> <span class="s2">&quot;elkan&quot;</span><span class="p">,</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="s2">&quot;full&quot;</span><span class="p">},</span> <span class="n">deprecated</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="s2">&quot;full&quot;</span><span class="p">})</span>
        <span class="p">],</span>
    <span class="p">}</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">n_clusters</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">init</span><span class="o">=</span><span class="s2">&quot;k-means++&quot;</span><span class="p">,</span>
        <span class="n">n_init</span><span class="o">=</span><span class="s2">&quot;warn&quot;</span><span class="p">,</span>
        <span class="n">max_iter</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
        <span class="n">tol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">copy_x</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;lloyd&quot;</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">n_clusters</span><span class="o">=</span><span class="n">n_clusters</span><span class="p">,</span>
            <span class="n">init</span><span class="o">=</span><span class="n">init</span><span class="p">,</span>
            <span class="n">n_init</span><span class="o">=</span><span class="n">n_init</span><span class="p">,</span>
            <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter</span><span class="p">,</span>
            <span class="n">tol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">copy_x</span> <span class="o">=</span> <span class="n">copy_x</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">algorithm</span> <span class="o">=</span> <span class="n">algorithm</span>

    <span class="k">def</span> <span class="nf">_check_params_vs_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_check_params_vs_input</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">default_n_init</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_algorithm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">algorithm</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_algorithm</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="s2">&quot;full&quot;</span><span class="p">):</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;algorithm=&#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_algorithm</span><span class="si">}</span><span class="s2">&#39; is deprecated, it will be &quot;</span>
                    <span class="s2">&quot;removed in 1.3. Using &#39;lloyd&#39; instead.&quot;</span>
                <span class="p">),</span>
                <span class="ne">FutureWarning</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_algorithm</span> <span class="o">=</span> <span class="s2">&quot;lloyd&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_algorithm</span> <span class="o">==</span> <span class="s2">&quot;elkan&quot;</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="p">(</span>
                    <span class="s2">&quot;algorithm=&#39;elkan&#39; doesn&#39;t make sense for a single &quot;</span>
                    <span class="s2">&quot;cluster. Using &#39;lloyd&#39; instead.&quot;</span>
                <span class="p">),</span>
                <span class="ne">RuntimeWarning</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_algorithm</span> <span class="o">=</span> <span class="s2">&quot;lloyd&quot;</span>

    <span class="k">def</span> <span class="nf">_warn_mkl_vcomp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_active_threads</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Warn when vcomp and mkl are both present&quot;&quot;&quot;</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="s2">&quot;KMeans is known to have a memory leak on Windows &quot;</span>
            <span class="s2">&quot;with MKL, when there are less chunks than available &quot;</span>
            <span class="s2">&quot;threads. You can avoid it by setting the environment&quot;</span>
            <span class="sa">f</span><span class="s2">&quot; variable OMP_NUM_THREADS=</span><span class="si">{</span><span class="n">n_active_threads</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>

<div class="viewcode-block" id="KMeans.fit"><a class="viewcode-back" href="../../../guide/reference/_autosummary/otx.algorithms.detection.adapters.mmdet.utils.config_utils.html#otx.algorithms.detection.adapters.mmdet.utils.config_utils.KMeans.fit">[docs]</a>    <span class="nd">@_fit_context</span><span class="p">(</span><span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute k-means clustering.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : {array-like, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">            Training instances to cluster. It must be noted that the data</span>
<span class="sd">            will be converted to C ordering, which will cause a memory</span>
<span class="sd">            copy if the given data is not C-contiguous.</span>
<span class="sd">            If a sparse matrix is passed, a copy will be made if it&#39;s not in</span>
<span class="sd">            CSR format.</span>

<span class="sd">        y : Ignored</span>
<span class="sd">            Not used, present here for API consistency by convention.</span>

<span class="sd">        sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">            The weights for each observation in X. If None, all observations</span>
<span class="sd">            are assigned equal weight. `sample_weight` is not used during</span>
<span class="sd">            initialization if `init` is a callable or a user provided array.</span>

<span class="sd">            .. versionadded:: 0.20</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">            Fitted estimator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_data</span><span class="p">(</span>
            <span class="n">X</span><span class="p">,</span>
            <span class="n">accept_sparse</span><span class="o">=</span><span class="s2">&quot;csr&quot;</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">],</span>
            <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">,</span>
            <span class="n">copy</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">copy_x</span><span class="p">,</span>
            <span class="n">accept_large_sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_check_params_vs_input</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="n">random_state</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
        <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">_check_sample_weight</span><span class="p">(</span><span class="n">sample_weight</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_n_threads</span> <span class="o">=</span> <span class="n">_openmp_effective_n_threads</span><span class="p">()</span>

        <span class="c1"># Validate init array</span>
        <span class="n">init</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">init</span>
        <span class="n">init_is_array_like</span> <span class="o">=</span> <span class="n">_is_arraylike_not_scalar</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">init_is_array_like</span><span class="p">:</span>
            <span class="n">init</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">init</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_validate_center_shape</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">init</span><span class="p">)</span>

        <span class="c1"># subtract of mean of x for more accurate distance computations</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">sp</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
            <span class="n">X_mean</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="c1"># The copy was already done above</span>
            <span class="n">X</span> <span class="o">-=</span> <span class="n">X_mean</span>

            <span class="k">if</span> <span class="n">init_is_array_like</span><span class="p">:</span>
                <span class="n">init</span> <span class="o">-=</span> <span class="n">X_mean</span>

        <span class="c1"># precompute squared norms of data points</span>
        <span class="n">x_squared_norms</span> <span class="o">=</span> <span class="n">row_norms</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">squared</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_algorithm</span> <span class="o">==</span> <span class="s2">&quot;elkan&quot;</span><span class="p">:</span>
            <span class="n">kmeans_single</span> <span class="o">=</span> <span class="n">_kmeans_single_elkan</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">kmeans_single</span> <span class="o">=</span> <span class="n">_kmeans_single_lloyd</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_check_mkl_vcomp</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="n">best_inertia</span><span class="p">,</span> <span class="n">best_labels</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_init</span><span class="p">):</span>
            <span class="c1"># Initialize centers</span>
            <span class="n">centers_init</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init_centroids</span><span class="p">(</span>
                <span class="n">X</span><span class="p">,</span>
                <span class="n">x_squared_norms</span><span class="o">=</span><span class="n">x_squared_norms</span><span class="p">,</span>
                <span class="n">init</span><span class="o">=</span><span class="n">init</span><span class="p">,</span>
                <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
                <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Initialization complete&quot;</span><span class="p">)</span>

            <span class="c1"># run a k-means once</span>
            <span class="n">labels</span><span class="p">,</span> <span class="n">inertia</span><span class="p">,</span> <span class="n">centers</span><span class="p">,</span> <span class="n">n_iter_</span> <span class="o">=</span> <span class="n">kmeans_single</span><span class="p">(</span>
                <span class="n">X</span><span class="p">,</span>
                <span class="n">sample_weight</span><span class="p">,</span>
                <span class="n">centers_init</span><span class="p">,</span>
                <span class="n">max_iter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
                <span class="n">tol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_tol</span><span class="p">,</span>
                <span class="n">n_threads</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_threads</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># determine if these results are the best so far</span>
            <span class="c1"># we chose a new run if it has a better inertia and the clustering is</span>
            <span class="c1"># different from the best so far (it&#39;s possible that the inertia is</span>
            <span class="c1"># slightly better even if the clustering is the same with potentially</span>
            <span class="c1"># permuted labels, due to rounding errors)</span>
            <span class="k">if</span> <span class="n">best_inertia</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="p">(</span>
                <span class="n">inertia</span> <span class="o">&lt;</span> <span class="n">best_inertia</span>
                <span class="ow">and</span> <span class="ow">not</span> <span class="n">_is_same_clustering</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">best_labels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">)</span>
            <span class="p">):</span>
                <span class="n">best_labels</span> <span class="o">=</span> <span class="n">labels</span>
                <span class="n">best_centers</span> <span class="o">=</span> <span class="n">centers</span>
                <span class="n">best_inertia</span> <span class="o">=</span> <span class="n">inertia</span>
                <span class="n">best_n_iter</span> <span class="o">=</span> <span class="n">n_iter_</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">sp</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">copy_x</span><span class="p">:</span>
                <span class="n">X</span> <span class="o">+=</span> <span class="n">X_mean</span>
            <span class="n">best_centers</span> <span class="o">+=</span> <span class="n">X_mean</span>

        <span class="n">distinct_clusters</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">best_labels</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">distinct_clusters</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;Number of distinct clusters (</span><span class="si">{}</span><span class="s2">) found smaller than &quot;</span>
                <span class="s2">&quot;n_clusters (</span><span class="si">{}</span><span class="s2">). Possibly due to duplicate points &quot;</span>
                <span class="s2">&quot;in X.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">distinct_clusters</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">),</span>
                <span class="n">ConvergenceWarning</span><span class="p">,</span>
                <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">cluster_centers_</span> <span class="o">=</span> <span class="n">best_centers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_n_features_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels_</span> <span class="o">=</span> <span class="n">best_labels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inertia_</span> <span class="o">=</span> <span class="n">best_inertia</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span> <span class="o">=</span> <span class="n">best_n_iter</span>
        <span class="k">return</span> <span class="bp">self</span></div></div>


<span class="k">def</span> <span class="nf">_mini_batch_step</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="p">,</span>
    <span class="n">centers</span><span class="p">,</span>
    <span class="n">centers_new</span><span class="p">,</span>
    <span class="n">weight_sums</span><span class="p">,</span>
    <span class="n">random_state</span><span class="p">,</span>
    <span class="n">random_reassign</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">reassignment_ratio</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">n_threads</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Incremental update of the centers for the Minibatch K-Means algorithm.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    X : {ndarray, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">        The original data array. If sparse, must be in CSR format.</span>

<span class="sd">    x_squared_norms : ndarray of shape (n_samples,)</span>
<span class="sd">        Squared euclidean norm of each data point.</span>

<span class="sd">    sample_weight : ndarray of shape (n_samples,)</span>
<span class="sd">        The weights for each observation in `X`.</span>

<span class="sd">    centers : ndarray of shape (n_clusters, n_features)</span>
<span class="sd">        The cluster centers before the current iteration</span>

<span class="sd">    centers_new : ndarray of shape (n_clusters, n_features)</span>
<span class="sd">        The cluster centers after the current iteration. Modified in-place.</span>

<span class="sd">    weight_sums : ndarray of shape (n_clusters,)</span>
<span class="sd">        The vector in which we keep track of the numbers of points in a</span>
<span class="sd">        cluster. This array is modified in place.</span>

<span class="sd">    random_state : RandomState instance</span>
<span class="sd">        Determines random number generation for low count centers reassignment.</span>
<span class="sd">        See :term:`Glossary &lt;random_state&gt;`.</span>

<span class="sd">    random_reassign : boolean, default=False</span>
<span class="sd">        If True, centers with very low counts are randomly reassigned</span>
<span class="sd">        to observations.</span>

<span class="sd">    reassignment_ratio : float, default=0.01</span>
<span class="sd">        Control the fraction of the maximum number of counts for a</span>
<span class="sd">        center to be reassigned. A higher value means that low count</span>
<span class="sd">        centers are more likely to be reassigned, which means that the</span>
<span class="sd">        model will take longer to converge, but should converge in a</span>
<span class="sd">        better clustering.</span>

<span class="sd">    verbose : bool, default=False</span>
<span class="sd">        Controls the verbosity.</span>

<span class="sd">    n_threads : int, default=1</span>
<span class="sd">        The number of OpenMP threads to use for the computation.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    inertia : float</span>
<span class="sd">        Sum of squared distances of samples to their closest cluster center.</span>
<span class="sd">        The inertia is computed after finding the labels and before updating</span>
<span class="sd">        the centers.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Perform label assignment to nearest centers</span>
    <span class="c1"># For better efficiency, it&#39;s better to run _mini_batch_step in a</span>
    <span class="c1"># threadpool_limit context than using _labels_inertia_threadpool_limit here</span>
    <span class="n">labels</span><span class="p">,</span> <span class="n">inertia</span> <span class="o">=</span> <span class="n">_labels_inertia</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">,</span> <span class="n">centers</span><span class="p">,</span> <span class="n">n_threads</span><span class="o">=</span><span class="n">n_threads</span><span class="p">)</span>

    <span class="c1"># Update centers according to the labels</span>
    <span class="k">if</span> <span class="n">sp</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
        <span class="n">_minibatch_update_sparse</span><span class="p">(</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">,</span> <span class="n">centers</span><span class="p">,</span> <span class="n">centers_new</span><span class="p">,</span> <span class="n">weight_sums</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">n_threads</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">_minibatch_update_dense</span><span class="p">(</span>
            <span class="n">X</span><span class="p">,</span>
            <span class="n">sample_weight</span><span class="p">,</span>
            <span class="n">centers</span><span class="p">,</span>
            <span class="n">centers_new</span><span class="p">,</span>
            <span class="n">weight_sums</span><span class="p">,</span>
            <span class="n">labels</span><span class="p">,</span>
            <span class="n">n_threads</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="c1"># Reassign clusters that have very low weight</span>
    <span class="k">if</span> <span class="n">random_reassign</span> <span class="ow">and</span> <span class="n">reassignment_ratio</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">to_reassign</span> <span class="o">=</span> <span class="n">weight_sums</span> <span class="o">&lt;</span> <span class="n">reassignment_ratio</span> <span class="o">*</span> <span class="n">weight_sums</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>

        <span class="c1"># pick at most .5 * batch_size samples as new centers</span>
        <span class="k">if</span> <span class="n">to_reassign</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="n">indices_dont_reassign</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">weight_sums</span><span class="p">)[</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="p">:]</span>
            <span class="n">to_reassign</span><span class="p">[</span><span class="n">indices_dont_reassign</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">n_reassigns</span> <span class="o">=</span> <span class="n">to_reassign</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">n_reassigns</span><span class="p">:</span>
            <span class="c1"># Pick new clusters amongst observations with uniform probability</span>
            <span class="n">new_centers</span> <span class="o">=</span> <span class="n">random_state</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span>
                <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_reassigns</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[MiniBatchKMeans] Reassigning </span><span class="si">{</span><span class="n">n_reassigns</span><span class="si">}</span><span class="s2"> cluster centers.&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">sp</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
                <span class="n">assign_rows_csr</span><span class="p">(</span>
                    <span class="n">X</span><span class="p">,</span>
                    <span class="n">new_centers</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">intp</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">to_reassign</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">intp</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
                    <span class="n">centers_new</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">centers_new</span><span class="p">[</span><span class="n">to_reassign</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">new_centers</span><span class="p">]</span>

        <span class="c1"># reset counts of reassigned centers, but don&#39;t reset them too small</span>
        <span class="c1"># to avoid instant reassignment. This is a pretty dirty hack as it</span>
        <span class="c1"># also modifies the learning rates.</span>
        <span class="n">weight_sums</span><span class="p">[</span><span class="n">to_reassign</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">weight_sums</span><span class="p">[</span><span class="o">~</span><span class="n">to_reassign</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">inertia</span>


<span class="k">class</span> <span class="nc">MiniBatchKMeans</span><span class="p">(</span><span class="n">_BaseKMeans</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Mini-Batch K-Means clustering.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;mini_batch_kmeans&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    n_clusters : int, default=8</span>
<span class="sd">        The number of clusters to form as well as the number of</span>
<span class="sd">        centroids to generate.</span>

<span class="sd">    init : {&#39;k-means++&#39;, &#39;random&#39;}, callable or array-like of shape \</span>
<span class="sd">            (n_clusters, n_features), default=&#39;k-means++&#39;</span>
<span class="sd">        Method for initialization:</span>

<span class="sd">        &#39;k-means++&#39; : selects initial cluster centroids using sampling based on</span>
<span class="sd">        an empirical probability distribution of the points&#39; contribution to the</span>
<span class="sd">        overall inertia. This technique speeds up convergence. The algorithm</span>
<span class="sd">        implemented is &quot;greedy k-means++&quot;. It differs from the vanilla k-means++</span>
<span class="sd">        by making several trials at each sampling step and choosing the best centroid</span>
<span class="sd">        among them.</span>

<span class="sd">        &#39;random&#39;: choose `n_clusters` observations (rows) at random from data</span>
<span class="sd">        for the initial centroids.</span>

<span class="sd">        If an array is passed, it should be of shape (n_clusters, n_features)</span>
<span class="sd">        and gives the initial centers.</span>

<span class="sd">        If a callable is passed, it should take arguments X, n_clusters and a</span>
<span class="sd">        random state and return an initialization.</span>

<span class="sd">    max_iter : int, default=100</span>
<span class="sd">        Maximum number of iterations over the complete dataset before</span>
<span class="sd">        stopping independently of any early stopping criterion heuristics.</span>

<span class="sd">    batch_size : int, default=1024</span>
<span class="sd">        Size of the mini batches.</span>
<span class="sd">        For faster computations, you can set the ``batch_size`` greater than</span>
<span class="sd">        256 * number of cores to enable parallelism on all cores.</span>

<span class="sd">        .. versionchanged:: 1.0</span>
<span class="sd">           `batch_size` default changed from 100 to 1024.</span>

<span class="sd">    verbose : int, default=0</span>
<span class="sd">        Verbosity mode.</span>

<span class="sd">    compute_labels : bool, default=True</span>
<span class="sd">        Compute label assignment and inertia for the complete dataset</span>
<span class="sd">        once the minibatch optimization has converged in fit.</span>

<span class="sd">    random_state : int, RandomState instance or None, default=None</span>
<span class="sd">        Determines random number generation for centroid initialization and</span>
<span class="sd">        random reassignment. Use an int to make the randomness deterministic.</span>
<span class="sd">        See :term:`Glossary &lt;random_state&gt;`.</span>

<span class="sd">    tol : float, default=0.0</span>
<span class="sd">        Control early stopping based on the relative center changes as</span>
<span class="sd">        measured by a smoothed, variance-normalized of the mean center</span>
<span class="sd">        squared position changes. This early stopping heuristics is</span>
<span class="sd">        closer to the one used for the batch variant of the algorithms</span>
<span class="sd">        but induces a slight computational and memory overhead over the</span>
<span class="sd">        inertia heuristic.</span>

<span class="sd">        To disable convergence detection based on normalized center</span>
<span class="sd">        change, set tol to 0.0 (default).</span>

<span class="sd">    max_no_improvement : int, default=10</span>
<span class="sd">        Control early stopping based on the consecutive number of mini</span>
<span class="sd">        batches that does not yield an improvement on the smoothed inertia.</span>

<span class="sd">        To disable convergence detection based on inertia, set</span>
<span class="sd">        max_no_improvement to None.</span>

<span class="sd">    init_size : int, default=None</span>
<span class="sd">        Number of samples to randomly sample for speeding up the</span>
<span class="sd">        initialization (sometimes at the expense of accuracy): the</span>
<span class="sd">        only algorithm is initialized by running a batch KMeans on a</span>
<span class="sd">        random subset of the data. This needs to be larger than n_clusters.</span>

<span class="sd">        If `None`, the heuristic is `init_size = 3 * batch_size` if</span>
<span class="sd">        `3 * batch_size &lt; n_clusters`, else `init_size = 3 * n_clusters`.</span>

<span class="sd">    n_init : &#39;auto&#39; or int, default=3</span>
<span class="sd">        Number of random initializations that are tried.</span>
<span class="sd">        In contrast to KMeans, the algorithm is only run once, using the best of</span>
<span class="sd">        the `n_init` initializations as measured by inertia. Several runs are</span>
<span class="sd">        recommended for sparse high-dimensional problems (see</span>
<span class="sd">        :ref:`kmeans_sparse_high_dim`).</span>

<span class="sd">        When `n_init=&#39;auto&#39;`, the number of runs depends on the value of init:</span>
<span class="sd">        3 if using `init=&#39;random&#39;` or `init` is a callable;</span>
<span class="sd">        1 if using `init=&#39;k-means++&#39;` or `init` is an array-like.</span>

<span class="sd">        .. versionadded:: 1.2</span>
<span class="sd">           Added &#39;auto&#39; option for `n_init`.</span>

<span class="sd">        .. versionchanged:: 1.4</span>
<span class="sd">           Default value for `n_init` will change from 3 to `&#39;auto&#39;` in version 1.4.</span>

<span class="sd">    reassignment_ratio : float, default=0.01</span>
<span class="sd">        Control the fraction of the maximum number of counts for a center to</span>
<span class="sd">        be reassigned. A higher value means that low count centers are more</span>
<span class="sd">        easily reassigned, which means that the model will take longer to</span>
<span class="sd">        converge, but should converge in a better clustering. However, too high</span>
<span class="sd">        a value may cause convergence issues, especially with a small batch</span>
<span class="sd">        size.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>

<span class="sd">    cluster_centers_ : ndarray of shape (n_clusters, n_features)</span>
<span class="sd">        Coordinates of cluster centers.</span>

<span class="sd">    labels_ : ndarray of shape (n_samples,)</span>
<span class="sd">        Labels of each point (if compute_labels is set to True).</span>

<span class="sd">    inertia_ : float</span>
<span class="sd">        The value of the inertia criterion associated with the chosen</span>
<span class="sd">        partition if compute_labels is set to True. If compute_labels is set to</span>
<span class="sd">        False, it&#39;s an approximation of the inertia based on an exponentially</span>
<span class="sd">        weighted average of the batch inertiae.</span>
<span class="sd">        The inertia is defined as the sum of square distances of samples to</span>
<span class="sd">        their cluster center, weighted by the sample weights if provided.</span>

<span class="sd">    n_iter_ : int</span>
<span class="sd">        Number of iterations over the full dataset.</span>

<span class="sd">    n_steps_ : int</span>
<span class="sd">        Number of minibatches processed.</span>

<span class="sd">        .. versionadded:: 1.0</span>

<span class="sd">    n_features_in_ : int</span>
<span class="sd">        Number of features seen during :term:`fit`.</span>

<span class="sd">        .. versionadded:: 0.24</span>

<span class="sd">    feature_names_in_ : ndarray of shape (`n_features_in_`,)</span>
<span class="sd">        Names of features seen during :term:`fit`. Defined only when `X`</span>
<span class="sd">        has feature names that are all strings.</span>

<span class="sd">        .. versionadded:: 1.0</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    KMeans : The classic implementation of the clustering method based on the</span>
<span class="sd">        Lloyd&#39;s algorithm. It consumes the whole set of input data at each</span>
<span class="sd">        iteration.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    See https://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf</span>

<span class="sd">    When there are too few points in the dataset, some centers may be</span>
<span class="sd">    duplicated, which means that a proper clustering in terms of the number</span>
<span class="sd">    of requesting clusters and the number of returned clusters will not</span>
<span class="sd">    always match. One solution is to set `reassignment_ratio=0`, which</span>
<span class="sd">    prevents reassignments of clusters that are too small.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.cluster import MiniBatchKMeans</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [1, 4], [1, 0],</span>
<span class="sd">    ...               [4, 2], [4, 0], [4, 4],</span>
<span class="sd">    ...               [4, 5], [0, 1], [2, 2],</span>
<span class="sd">    ...               [3, 2], [5, 5], [1, -1]])</span>
<span class="sd">    &gt;&gt;&gt; # manually fit on batches</span>
<span class="sd">    &gt;&gt;&gt; kmeans = MiniBatchKMeans(n_clusters=2,</span>
<span class="sd">    ...                          random_state=0,</span>
<span class="sd">    ...                          batch_size=6,</span>
<span class="sd">    ...                          n_init=&quot;auto&quot;)</span>
<span class="sd">    &gt;&gt;&gt; kmeans = kmeans.partial_fit(X[0:6,:])</span>
<span class="sd">    &gt;&gt;&gt; kmeans = kmeans.partial_fit(X[6:12,:])</span>
<span class="sd">    &gt;&gt;&gt; kmeans.cluster_centers_</span>
<span class="sd">    array([[3.375, 3.  ],</span>
<span class="sd">           [0.75 , 0.5 ]])</span>
<span class="sd">    &gt;&gt;&gt; kmeans.predict([[0, 0], [4, 4]])</span>
<span class="sd">    array([1, 0], dtype=int32)</span>
<span class="sd">    &gt;&gt;&gt; # fit on the whole data</span>
<span class="sd">    &gt;&gt;&gt; kmeans = MiniBatchKMeans(n_clusters=2,</span>
<span class="sd">    ...                          random_state=0,</span>
<span class="sd">    ...                          batch_size=6,</span>
<span class="sd">    ...                          max_iter=10,</span>
<span class="sd">    ...                          n_init=&quot;auto&quot;).fit(X)</span>
<span class="sd">    &gt;&gt;&gt; kmeans.cluster_centers_</span>
<span class="sd">    array([[3.55102041, 2.48979592],</span>
<span class="sd">           [1.06896552, 1.        ]])</span>
<span class="sd">    &gt;&gt;&gt; kmeans.predict([[0, 0], [4, 4]])</span>
<span class="sd">    array([1, 0], dtype=int32)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_parameter_constraints</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{</span>
        <span class="o">**</span><span class="n">_BaseKMeans</span><span class="o">.</span><span class="n">_parameter_constraints</span><span class="p">,</span>
        <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Interval</span><span class="p">(</span><span class="n">Integral</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">closed</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">)],</span>
        <span class="s2">&quot;compute_labels&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;boolean&quot;</span><span class="p">],</span>
        <span class="s2">&quot;max_no_improvement&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Interval</span><span class="p">(</span><span class="n">Integral</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">closed</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">),</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;init_size&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Interval</span><span class="p">(</span><span class="n">Integral</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">closed</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">),</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;reassignment_ratio&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Interval</span><span class="p">(</span><span class="n">Real</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">closed</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">)],</span>
    <span class="p">}</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">n_clusters</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">init</span><span class="o">=</span><span class="s2">&quot;k-means++&quot;</span><span class="p">,</span>
        <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">compute_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">tol</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
        <span class="n">max_no_improvement</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">init_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">n_init</span><span class="o">=</span><span class="s2">&quot;warn&quot;</span><span class="p">,</span>
        <span class="n">reassignment_ratio</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">n_clusters</span><span class="o">=</span><span class="n">n_clusters</span><span class="p">,</span>
            <span class="n">init</span><span class="o">=</span><span class="n">init</span><span class="p">,</span>
            <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
            <span class="n">tol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span>
            <span class="n">n_init</span><span class="o">=</span><span class="n">n_init</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">max_no_improvement</span> <span class="o">=</span> <span class="n">max_no_improvement</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">compute_labels</span> <span class="o">=</span> <span class="n">compute_labels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_size</span> <span class="o">=</span> <span class="n">init_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reassignment_ratio</span> <span class="o">=</span> <span class="n">reassignment_ratio</span>

    <span class="k">def</span> <span class="nf">_check_params_vs_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_check_params_vs_input</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">default_n_init</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="c1"># init_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_init_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_size</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_init_size</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init_size</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_init_size</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init_size</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;init_size=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_init_size</span><span class="si">}</span><span class="s2"> should be larger than &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;n_clusters=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="si">}</span><span class="s2">. Setting it to &quot;</span>
                    <span class="s2">&quot;min(3*n_clusters, n_samples)&quot;</span>
                <span class="p">),</span>
                <span class="ne">RuntimeWarning</span><span class="p">,</span>
                <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_init_size</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_init_size</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_init_size</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="c1"># reassignment_ratio</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reassignment_ratio</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;reassignment_ratio should be &gt;= 0, got &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">reassignment_ratio</span><span class="si">}</span><span class="s2"> instead.&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_warn_mkl_vcomp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_active_threads</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Warn when vcomp and mkl are both present&quot;&quot;&quot;</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="s2">&quot;MiniBatchKMeans is known to have a memory leak on &quot;</span>
            <span class="s2">&quot;Windows with MKL, when there are less chunks than &quot;</span>
            <span class="s2">&quot;available threads. You can prevent it by setting &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;batch_size &gt;= </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_threads</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">CHUNK_SIZE</span><span class="si">}</span><span class="s2"> or by &quot;</span>
            <span class="s2">&quot;setting the environment variable &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;OMP_NUM_THREADS=</span><span class="si">{</span><span class="n">n_active_threads</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_mini_batch_convergence</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">centers_squared_diff</span><span class="p">,</span> <span class="n">batch_inertia</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Helper function to encapsulate the early stopping logic&quot;&quot;&quot;</span>
        <span class="c1"># Normalize inertia to be able to compare values when</span>
        <span class="c1"># batch_size changes</span>
        <span class="n">batch_inertia</span> <span class="o">/=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span>

        <span class="c1"># count steps starting from 1 for user friendly verbose mode.</span>
        <span class="n">step</span> <span class="o">=</span> <span class="n">step</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="c1"># Ignore first iteration because it&#39;s inertia from initialization.</span>
        <span class="k">if</span> <span class="n">step</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Minibatch step </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">n_steps</span><span class="si">}</span><span class="s2">: mean batch &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;inertia: </span><span class="si">{</span><span class="n">batch_inertia</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="c1"># Compute an Exponentially Weighted Average of the inertia to</span>
        <span class="c1"># monitor the convergence while discarding minibatch-local stochastic</span>
        <span class="c1"># variability: https://en.wikipedia.org/wiki/Moving_average</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ewa_inertia</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_ewa_inertia</span> <span class="o">=</span> <span class="n">batch_inertia</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">alpha</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="o">*</span> <span class="mf">2.0</span> <span class="o">/</span> <span class="p">(</span><span class="n">n_samples</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">alpha</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_ewa_inertia</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ewa_inertia</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">+</span> <span class="n">batch_inertia</span> <span class="o">*</span> <span class="n">alpha</span>

        <span class="c1"># Log progress to be able to monitor convergence</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Minibatch step </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">n_steps</span><span class="si">}</span><span class="s2">: mean batch inertia: &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">batch_inertia</span><span class="si">}</span><span class="s2">, ewa inertia: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_ewa_inertia</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Early stopping based on absolute tolerance on squared change of</span>
        <span class="c1"># centers position</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tol</span> <span class="o">&gt;</span> <span class="mf">0.0</span> <span class="ow">and</span> <span class="n">centers_squared_diff</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tol</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Converged (small centers change) at step </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">n_steps</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">True</span>

        <span class="c1"># Early stopping heuristic due to lack of improvement on smoothed</span>
        <span class="c1"># inertia</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ewa_inertia_min</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ewa_inertia</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ewa_inertia_min</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_no_improvement</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_ewa_inertia_min</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ewa_inertia</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_no_improvement</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">max_no_improvement</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_no_improvement</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_no_improvement</span>
        <span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span>
                    <span class="s2">&quot;Converged (lack of improvement in inertia) at step &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">n_steps</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="kc">True</span>

        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">_random_reassign</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Check if a random reassignment needs to be done.</span>

<span class="sd">        Do random reassignments each time 10 * n_clusters samples have been</span>
<span class="sd">        processed.</span>

<span class="sd">        If there are empty clusters we always want to reassign.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_n_since_last_reassign</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_counts</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">()</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_since_last_reassign</span> <span class="o">&gt;=</span> <span class="p">(</span>
            <span class="mi">10</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_n_since_last_reassign</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="nd">@_fit_context</span><span class="p">(</span><span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute the centroids on X by chunking it into mini-batches.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : {array-like, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">            Training instances to cluster. It must be noted that the data</span>
<span class="sd">            will be converted to C ordering, which will cause a memory copy</span>
<span class="sd">            if the given data is not C-contiguous.</span>
<span class="sd">            If a sparse matrix is passed, a copy will be made if it&#39;s not in</span>
<span class="sd">            CSR format.</span>

<span class="sd">        y : Ignored</span>
<span class="sd">            Not used, present here for API consistency by convention.</span>

<span class="sd">        sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">            The weights for each observation in X. If None, all observations</span>
<span class="sd">            are assigned equal weight. `sample_weight` is not used during</span>
<span class="sd">            initialization if `init` is a callable or a user provided array.</span>

<span class="sd">            .. versionadded:: 0.20</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">            Fitted estimator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_data</span><span class="p">(</span>
            <span class="n">X</span><span class="p">,</span>
            <span class="n">accept_sparse</span><span class="o">=</span><span class="s2">&quot;csr&quot;</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">],</span>
            <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">,</span>
            <span class="n">accept_large_sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_check_params_vs_input</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">random_state</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
        <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">_check_sample_weight</span><span class="p">(</span><span class="n">sample_weight</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_n_threads</span> <span class="o">=</span> <span class="n">_openmp_effective_n_threads</span><span class="p">()</span>
        <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>

        <span class="c1"># Validate init array</span>
        <span class="n">init</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">init</span>
        <span class="k">if</span> <span class="n">_is_arraylike_not_scalar</span><span class="p">(</span><span class="n">init</span><span class="p">):</span>
            <span class="n">init</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">init</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_validate_center_shape</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">init</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_check_mkl_vcomp</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span><span class="p">)</span>

        <span class="c1"># precompute squared norms of data points</span>
        <span class="n">x_squared_norms</span> <span class="o">=</span> <span class="n">row_norms</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">squared</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Validation set for the init</span>
        <span class="n">validation_indices</span> <span class="o">=</span> <span class="n">random_state</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init_size</span><span class="p">)</span>
        <span class="n">X_valid</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">validation_indices</span><span class="p">]</span>
        <span class="n">sample_weight_valid</span> <span class="o">=</span> <span class="n">sample_weight</span><span class="p">[</span><span class="n">validation_indices</span><span class="p">]</span>

        <span class="c1"># perform several inits with random subsets</span>
        <span class="n">best_inertia</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">for</span> <span class="n">init_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_init</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Init </span><span class="si">{</span><span class="n">init_idx</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_init</span><span class="si">}</span><span class="s2"> with method </span><span class="si">{</span><span class="n">init</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Initialize the centers using only a fraction of the data as we</span>
            <span class="c1"># expect n_samples to be very large when using MiniBatchKMeans.</span>
            <span class="n">cluster_centers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init_centroids</span><span class="p">(</span>
                <span class="n">X</span><span class="p">,</span>
                <span class="n">x_squared_norms</span><span class="o">=</span><span class="n">x_squared_norms</span><span class="p">,</span>
                <span class="n">init</span><span class="o">=</span><span class="n">init</span><span class="p">,</span>
                <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
                <span class="n">init_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_init_size</span><span class="p">,</span>
                <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># Compute inertia on a validation set.</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">inertia</span> <span class="o">=</span> <span class="n">_labels_inertia_threadpool_limit</span><span class="p">(</span>
                <span class="n">X_valid</span><span class="p">,</span>
                <span class="n">sample_weight_valid</span><span class="p">,</span>
                <span class="n">cluster_centers</span><span class="p">,</span>
                <span class="n">n_threads</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_threads</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Inertia for init </span><span class="si">{</span><span class="n">init_idx</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_init</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">inertia</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">best_inertia</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">inertia</span> <span class="o">&lt;</span> <span class="n">best_inertia</span><span class="p">:</span>
                <span class="n">init_centers</span> <span class="o">=</span> <span class="n">cluster_centers</span>
                <span class="n">best_inertia</span> <span class="o">=</span> <span class="n">inertia</span>

        <span class="n">centers</span> <span class="o">=</span> <span class="n">init_centers</span>
        <span class="n">centers_new</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">centers</span><span class="p">)</span>

        <span class="c1"># Initialize counts</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

        <span class="c1"># Attributes to monitor the convergence</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_ewa_inertia</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_ewa_inertia_min</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_no_improvement</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Initialize number of samples seen since last reassignment</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_n_since_last_reassign</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="n">n_steps</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">*</span> <span class="n">n_samples</span><span class="p">)</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span>

        <span class="k">with</span> <span class="n">threadpool_limits</span><span class="p">(</span><span class="n">limits</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">user_api</span><span class="o">=</span><span class="s2">&quot;blas&quot;</span><span class="p">):</span>
            <span class="c1"># Perform the iterative optimization until convergence</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_steps</span><span class="p">):</span>
                <span class="c1"># Sample a minibatch from the full dataset</span>
                <span class="n">minibatch_indices</span> <span class="o">=</span> <span class="n">random_state</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span><span class="p">)</span>

                <span class="c1"># Perform the actual update step on the minibatch data</span>
                <span class="n">batch_inertia</span> <span class="o">=</span> <span class="n">_mini_batch_step</span><span class="p">(</span>
                    <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">[</span><span class="n">minibatch_indices</span><span class="p">],</span>
                    <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">[</span><span class="n">minibatch_indices</span><span class="p">],</span>
                    <span class="n">centers</span><span class="o">=</span><span class="n">centers</span><span class="p">,</span>
                    <span class="n">centers_new</span><span class="o">=</span><span class="n">centers_new</span><span class="p">,</span>
                    <span class="n">weight_sums</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_counts</span><span class="p">,</span>
                    <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
                    <span class="n">random_reassign</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_random_reassign</span><span class="p">(),</span>
                    <span class="n">reassignment_ratio</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reassignment_ratio</span><span class="p">,</span>
                    <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
                    <span class="n">n_threads</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_threads</span><span class="p">,</span>
                <span class="p">)</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tol</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
                    <span class="n">centers_squared_diff</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">centers_new</span> <span class="o">-</span> <span class="n">centers</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">centers_squared_diff</span> <span class="o">=</span> <span class="mi">0</span>

                <span class="n">centers</span><span class="p">,</span> <span class="n">centers_new</span> <span class="o">=</span> <span class="n">centers_new</span><span class="p">,</span> <span class="n">centers</span>

                <span class="c1"># Monitor convergence and do early stopping if necessary</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mini_batch_convergence</span><span class="p">(</span>
                    <span class="n">i</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">centers_squared_diff</span><span class="p">,</span> <span class="n">batch_inertia</span>
                <span class="p">):</span>
                    <span class="k">break</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">cluster_centers_</span> <span class="o">=</span> <span class="n">centers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_n_features_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">n_steps_</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(((</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_samples</span><span class="p">))</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_labels</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">labels_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inertia_</span> <span class="o">=</span> <span class="n">_labels_inertia_threadpool_limit</span><span class="p">(</span>
                <span class="n">X</span><span class="p">,</span>
                <span class="n">sample_weight</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">,</span>
                <span class="n">n_threads</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_threads</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inertia_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ewa_inertia</span> <span class="o">*</span> <span class="n">n_samples</span>

        <span class="k">return</span> <span class="bp">self</span>

    <span class="nd">@_fit_context</span><span class="p">(</span><span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">partial_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Update k means estimate on a single mini-batch X.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : {array-like, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">            Training instances to cluster. It must be noted that the data</span>
<span class="sd">            will be converted to C ordering, which will cause a memory copy</span>
<span class="sd">            if the given data is not C-contiguous.</span>
<span class="sd">            If a sparse matrix is passed, a copy will be made if it&#39;s not in</span>
<span class="sd">            CSR format.</span>

<span class="sd">        y : Ignored</span>
<span class="sd">            Not used, present here for API consistency by convention.</span>

<span class="sd">        sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">            The weights for each observation in X. If None, all observations</span>
<span class="sd">            are assigned equal weight. `sample_weight` is not used during</span>
<span class="sd">            initialization if `init` is a callable or a user provided array.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">            Return updated estimator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">has_centers</span> <span class="o">=</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;cluster_centers_&quot;</span><span class="p">)</span>

        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_data</span><span class="p">(</span>
            <span class="n">X</span><span class="p">,</span>
            <span class="n">accept_sparse</span><span class="o">=</span><span class="s2">&quot;csr&quot;</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">],</span>
            <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">,</span>
            <span class="n">accept_large_sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">reset</span><span class="o">=</span><span class="ow">not</span> <span class="n">has_centers</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_random_state</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_random_state&quot;</span><span class="p">,</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">_check_sample_weight</span><span class="p">(</span><span class="n">sample_weight</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_steps_</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;n_steps_&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

        <span class="c1"># precompute squared norms of data points</span>
        <span class="n">x_squared_norms</span> <span class="o">=</span> <span class="n">row_norms</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">squared</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">has_centers</span><span class="p">:</span>
            <span class="c1"># this instance has not been fitted yet (fit or partial_fit)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_check_params_vs_input</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_n_threads</span> <span class="o">=</span> <span class="n">_openmp_effective_n_threads</span><span class="p">()</span>

            <span class="c1"># Validate init array</span>
            <span class="n">init</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">init</span>
            <span class="k">if</span> <span class="n">_is_arraylike_not_scalar</span><span class="p">(</span><span class="n">init</span><span class="p">):</span>
                <span class="n">init</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">init</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_validate_center_shape</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">init</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_check_mkl_vcomp</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

            <span class="c1"># initialize the cluster centers</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cluster_centers_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init_centroids</span><span class="p">(</span>
                <span class="n">X</span><span class="p">,</span>
                <span class="n">x_squared_norms</span><span class="o">=</span><span class="n">x_squared_norms</span><span class="p">,</span>
                <span class="n">init</span><span class="o">=</span><span class="n">init</span><span class="p">,</span>
                <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_random_state</span><span class="p">,</span>
                <span class="n">init_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_init_size</span><span class="p">,</span>
                <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># Initialize counts</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

            <span class="c1"># Initialize number of samples seen since last reassignment</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_n_since_last_reassign</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">with</span> <span class="n">threadpool_limits</span><span class="p">(</span><span class="n">limits</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">user_api</span><span class="o">=</span><span class="s2">&quot;blas&quot;</span><span class="p">):</span>
            <span class="n">_mini_batch_step</span><span class="p">(</span>
                <span class="n">X</span><span class="p">,</span>
                <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
                <span class="n">centers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">,</span>
                <span class="n">centers_new</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">,</span>
                <span class="n">weight_sums</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_counts</span><span class="p">,</span>
                <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_random_state</span><span class="p">,</span>
                <span class="n">random_reassign</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_random_reassign</span><span class="p">(),</span>
                <span class="n">reassignment_ratio</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reassignment_ratio</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
                <span class="n">n_threads</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_threads</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_labels</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">labels_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inertia_</span> <span class="o">=</span> <span class="n">_labels_inertia_threadpool_limit</span><span class="p">(</span>
                <span class="n">X</span><span class="p">,</span>
                <span class="n">sample_weight</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">,</span>
                <span class="n">n_threads</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_threads</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">n_steps_</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_n_features_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">return</span> <span class="bp">self</span>
</pre></div>

            </article>
            
            
            
            <footer class="bd-footer-article">
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            </footer>
            
          </div>
          
          
          
            <div class="bd-sidebar-secondary bd-toc">
              
<div class="toc-item">
  
<div id="searchbox"></div>
</div>

<div class="toc-item">
  
</div>

<div class="toc-item">
  
</div>

            </div>
          
          
        </div>
        <footer class="bd-footer-content">
          <div class="bd-footer-content__inner">
            
          </div>
        </footer>
        
      </main>
    </div>
  </div>

  
    
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94"></script>

  <footer class="bd-footer"><div class="bd-footer__inner container">
  
  <div class="footer-item">
    
<p class="copyright">

    &copy; Copyright 2023, OpenVINOâ„¢ Training Extensions Contributors.<br>

</p>

  </div>
  
  <div class="footer-item">
    <p class="theme-version">
    Built with the
    <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">
        PyData Sphinx Theme
    </a>
    0.12.0.
</p>
  </div>
  
  <div class="footer-item">
    
<p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 5.3.0.<br>
</p>

  </div>
  
</div>
  </footer>
  </body>
</html>