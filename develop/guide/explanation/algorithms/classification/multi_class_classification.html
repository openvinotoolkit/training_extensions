
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Multi-class Classification &#8212; OpenVINO™ Training Extensions 1.6.0dev documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../_static/styles/theme.css?digest=796348d33e8b1d947c94" rel="stylesheet">
<link href="../../../../_static/styles/bootstrap.css?digest=796348d33e8b1d947c94" rel="stylesheet">
<link href="../../../../_static/styles/pydata-sphinx-theme.css?digest=796348d33e8b1d947c94" rel="stylesheet">

  
  <link href="../../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=796348d33e8b1d947c94" rel="stylesheet">
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2">
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2">
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/css/custom.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94">
<link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94">

    <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/sphinx_highlight.js"></script>
    <script src="../../../../_static/clipboard.min.js"></script>
    <script src="../../../../_static/copybutton.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'guide/explanation/algorithms/classification/multi_class_classification';</script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <link rel="next" title="Multi-label Classification" href="multi_label_classification.html" />
    <link rel="prev" title="Classification" href="index.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="docsearch:language" content="en">
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>

  
  <input type="checkbox" class="sidebar-toggle" name="__primary" id="__primary">
  <label class="overlay overlay-primary" for="__primary"></label>

  
  <input type="checkbox" class="sidebar-toggle" name="__secondary" id="__secondary">
  <label class="overlay overlay-secondary" for="__secondary"></label>

  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
      
<form class="bd-search d-flex align-items-center" action="../../../../search.html" method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
  </div>

  
  <nav class="bd-header navbar navbar-expand-lg bd-navbar" id="navbar-main"><div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
      <span class="fa-solid fa-bars"></span>
  </label>
  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../../../../index.html">

  
  
  
  
  
  
  

  
    <img src="../../../../_static/logos/otx-logo.png" class="logo__image only-light" alt="Logo image">
    <img src="../../../../_static/logos/otx-logo.png" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    
  </div>

  
  <div class="col-lg-9 navbar-header-items">
    <div id="navbar-center" class="mr-auto">
      
    </div>

    <div id="navbar-end">
      
        <div class="navbar-end-item navbar-persistent--container">
          
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
        </div>
      
      
      <div class="navbar-end-item">
        <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          <a href="https://github.com/openvinotoolkit/training_extensions" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-toggle="tooltip"><img src="../../../../_static/logos/github_icon.png" class="icon-link-image" alt="GitHub"/></a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>


  
  
    <div class="navbar-persistent--mobile">
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
    </div>
  

  
  <label class="sidebar-toggle secondary-toggle" for="__secondary">
      <span class="fa-solid fa-outdent"></span>
  </label>
  

</div>
  </nav>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        
  
  <div class="sidebar-header-items sidebar-primary__section">
    
    

    
    
    <div class="sidebar-header-items__end">
      
      <div class="navbar-end-item">
        <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          <a href="https://github.com/openvinotoolkit/training_extensions" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-toggle="tooltip"><img src="../../../../_static/logos/github_icon.png" class="icon-link-image" alt="GitHub"/></a>
        </li>
      </ul>
      </div>
      
    </div>
    
  </div>

  
  <div class="sidebar-start-items sidebar-primary__section">
    <div class="sidebar-start-items__item"><nav class="bd-links" id="bd-docs-nav" aria-label="Section navigation">
  <p class="bd-links__title" role="heading" aria-level="1">
    Section Navigation
  </p>
  <div class="bd-toc-item navbar-nav">
    <p aria-level="2" class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../get_started/introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../get_started/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../get_started/cli_commands.html">OpenVINO™ Training Extensions CLI commands</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../tutorials/base/index.html">Base Tutorials</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../tutorials/base/how_to_train/index.html">How to train, validate, export and optimize the model</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/base/how_to_train/classification.html">Classification  model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/base/how_to_train/detection.html">Object Detection model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/base/how_to_train/instance_segmentation.html">Instance Segmentation model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/base/how_to_train/semantic_segmentation.html">Semantic Segmentation model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/base/how_to_train/anomaly_detection.html">Anomaly Detection Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/base/how_to_train/action_classification.html">Action Classification model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/base/how_to_train/action_detection.html">Action Detection model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/base/demo.html">How to run the demonstration mode with OpenVINO™ Training Extensions CLI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/base/deploy.html">How to deploy the model and use demo in exportable code</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/base/explain.html">How to explain the model behavior</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../tutorials/advanced/index.html">Advanced Tutorials</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/advanced/semi_sl.html">Use Semi-Supervised Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/advanced/self_sl.html">Use Self-Supervised Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/advanced/backbones.html">Backbone Replacement</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/advanced/api_tutorial.html">Utilize OpenVINO™ Training Extensions APIs in your project</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/advanced/hpo_tutorial.html">Simple HPO Tutorial</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Explanation</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../index.html">Algorithms</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2 current active has-children"><a class="reference internal" href="index.html">Classification</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l3 current active"><a class="current reference internal" href="#">Multi-class Classification</a></li>
<li class="toctree-l3"><a class="reference internal" href="multi_label_classification.html">Multi-label Classification</a></li>
<li class="toctree-l3"><a class="reference internal" href="hierarhical_classification.html">Hierarchical Classification</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../object_detection/index.html">Object Detection</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../object_detection/object_detection.html">Object Detection</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../segmentation/index.html">Segmentation</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../segmentation/semantic_segmentation.html">Semantic Segmentation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../segmentation/instance_segmentation.html">Instance Segmentation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../anomaly/index.html">Anomaly Detection</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../action/index.html">Action Recognition</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../action/action_classification.html">Action Classification</a></li>
<li class="toctree-l3"><a class="reference internal" href="../action/action_detection.html">Action Detection</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../visual_prompting/index.html">Visual Prompting</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../additional_features/index.html">Additional Features</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../additional_features/models_optimization.html">Models Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../additional_features/hpo.html">Hyperparameters Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../additional_features/auto_configuration.html">Auto-configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../additional_features/adaptive_training.html">Adaptive Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../additional_features/xai.html">Explainable AI (XAI)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../additional_features/noisy_label_detection.html">Noisy Label Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../additional_features/fast_data_loading.html">Fast Data Loading</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../additional_features/tiling.html">Improve Small Object Detection with Image Tiling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../additional_features/config_input_size.html">Configurable Input Size</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../reference/index.html">API reference</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../reference/_autosummary/otx.html">otx</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../reference/_autosummary/otx.algorithms.html">otx.algorithms</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../reference/_autosummary/otx.algorithms.action.html">otx.algorithms.action</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../reference/_autosummary/otx.algorithms.anomaly.html">otx.algorithms.anomaly</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../reference/_autosummary/otx.algorithms.classification.html">otx.algorithms.classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../reference/_autosummary/otx.algorithms.common.html">otx.algorithms.common</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../reference/_autosummary/otx.algorithms.detection.html">otx.algorithms.detection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../reference/_autosummary/otx.algorithms.segmentation.html">otx.algorithms.segmentation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../reference/_autosummary/otx.algorithms.visual_prompting.html">otx.algorithms.visual_prompting</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../reference/_autosummary/otx.api.html">otx.api</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../reference/_autosummary/otx.api.configuration.html">otx.api.configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../reference/_autosummary/otx.api.entities.html">otx.api.entities</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../reference/_autosummary/otx.api.serialization.html">otx.api.serialization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../reference/_autosummary/otx.api.usecases.html">otx.api.usecases</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../reference/_autosummary/otx.api.utils.html">otx.api.utils</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../reference/_autosummary/otx.cli.html">otx.cli</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../reference/_autosummary/otx.cli.builder.html">otx.cli.builder</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../reference/_autosummary/otx.cli.manager.html">otx.cli.manager</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../reference/_autosummary/otx.cli.registry.html">otx.cli.registry</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../reference/_autosummary/otx.cli.tools.html">otx.cli.tools</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../reference/_autosummary/otx.cli.utils.html">otx.cli.utils</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../reference/_autosummary/otx.core.html">otx.core</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../reference/_autosummary/otx.core.data.html">otx.core.data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../reference/_autosummary/otx.core.file.html">otx.core.file</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../reference/_autosummary/otx.core.ov.html">otx.core.ov</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../reference/_autosummary/otx.core.patcher.html">otx.core.patcher</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../reference/_autosummary/otx.hpo.html">otx.hpo</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../reference/_autosummary/otx.hpo.hpo_base.html">otx.hpo.hpo_base</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../reference/_autosummary/otx.hpo.hpo_runner.html">otx.hpo.hpo_runner</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../reference/_autosummary/otx.hpo.hyperband.html">otx.hpo.hyperband</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../reference/_autosummary/otx.hpo.resource_manager.html">otx.hpo.resource_manager</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../reference/_autosummary/otx.hpo.search_space.html">otx.hpo.search_space</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../reference/_autosummary/otx.hpo.utils.html">otx.hpo.utils</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../reference/_autosummary/otx.recipes.html">otx.recipes</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../reference/_autosummary/otx.recipes.stages.html">otx.recipes.stages</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../reference/_autosummary/otx.utils.html">otx.utils</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-18"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../reference/_autosummary/otx.utils.logger.html">otx.utils.logger</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Release Notes</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../release_notes/index.html">Releases</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-19"><i class="fa-solid fa-chevron-down"></i></label><ul class="simple">
</ul>
</li>
</ul>

  </div>
</nav>
    </div>
  </div>
  

  
  <div class="sidebar-end-items sidebar-primary__section">
    <div class="sidebar-end-items__item">
    </div>
  </div>

  
  <div id="rtd-footer-container"></div>

      </div>
      <main id="main-content" class="bd-main">
        
        
        <div class="bd-content">
          <div class="bd-article-container">
            
            <div class="bd-header-article">
                
            </div>
            
            
            <article class="bd-article" role="main">
              
  <section id="multi-class-classification">
<h1>Multi-class Classification<a class="headerlink" href="#multi-class-classification" title="Permalink to this heading">#</a></h1>
<p>Multi-class classification is the problem of classifying instances into one of two or more classes. We solve this problem in a common fashion, based on the feature extractor backbone and classifier head that predicts the distribution probability of the categories from the given corpus.
For the supervised training we use the following algorithms components:</p>
<ul id="mcl-cls-supervised-pipeline">
<li><p><code class="docutils literal notranslate"><span class="pre">Augmentations</span></code>: Besides basic augmentations like random flip and random rotate, we use <a class="reference external" href="https://arxiv.org/abs/1912.02781">Augmix</a>. This advanced type of augmentations helps to significantly expand the training distribution.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Optimizer</span></code>: <a class="reference external" href="https://arxiv.org/abs/2209.06585">Sharpness Aware Minimization (SAM)</a>. Wrapper upon the <a class="reference external" href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">SGD</a> optimizer that helps to achieve better generalization minimizing simultaneously loss value and loss sharpness.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Learning</span> <span class="pre">rate</span> <span class="pre">schedule</span></code>: <a class="reference external" href="https://arxiv.org/abs/1608.03983v5">Cosine Annealing</a>. It is a common learning rate scheduler that tends to work well on average for this task on a variety of different datasets.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Loss</span> <span class="pre">function</span></code>: We use standard <a class="reference external" href="https://en.wikipedia.org/wiki/Cross_entropy">Cross Entropy Loss</a>  to train a model. However, for the class-incremental scenario we use <a class="reference external" href="https://arxiv.org/abs/2110.02444">Influence-Balanced Loss</a>. IB loss is a solution for the class imbalance, which avoids overfitting to the majority classes re-weighting the influential samples.</p></li>
<li><dl>
<dt><code class="docutils literal notranslate"><span class="pre">Additional</span> <span class="pre">training</span> <span class="pre">techniques</span></code></dt><dd><ul>
<li><p><a class="reference external" href="https://arxiv.org/abs/1812.01187">No Bias Decay (NBD)</a>: To add adaptability to the training pipeline and prevent overfitting.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Early</span> <span class="pre">stopping</span></code>: To add adaptability to the training pipeline and prevent overfitting. You can use early stopping like the below command.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ otx train {TEMPLATE} ... \
    params \
    --learning_parameters.enable_early_stopping=True
</pre></div>
</div>
</li>
<li><p><a class="reference external" href="https://github.dev/openvinotoolkit/training_extensions/blob/develop/src/otx/mpa/modules/datasets/samplers/balanced_sampler.py#L11">Balanced Sampler</a>: To create an efficient batch that consists of balanced samples over classes, reducing the iteration size as well.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<section id="dataset-format">
<h2>Dataset Format<a class="headerlink" href="#dataset-format" title="Permalink to this heading">#</a></h2>
<p>We support a commonly used format for multi-class image classification task: <a class="reference external" href="https://www.image-net.org/">ImageNet</a> class folder format.
This format has the following structure:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>data
├── train
    ├── class 0
        ├── 0.png
        ├── 1.png
        ...
        └── N.png
    ├── class 1
        ├── 0.png
        ├── 1.png
        ...
        └── N.png
    ...
    └── class N
        ├── 0.png
        ├── 1.png
        ...
        └── N.png
└── val
    ...
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please, refer to our <a class="reference internal" href="../../../tutorials/base/how_to_train/classification.html"><span class="doc">dedicated tutorial</span></a> for more information how to train, validate and optimize classification models.</p>
</div>
</section>
<section id="models">
<h2>Models<a class="headerlink" href="#models" title="Permalink to this heading">#</a></h2>
<p id="classification-models">We support the following ready-to-use model templates:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Template ID</p></th>
<th class="head"><p>Name</p></th>
<th class="head"><p>Complexity (GFLOPs)</p></th>
<th class="head"><p>Model size (MB)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference external" href="https://github.com/openvinotoolkit/training_extensions/blob/develop/src/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/template.yaml">Custom_Image_Classification_MobileNet-V3-large-1x</a></p></td>
<td><p>MobileNet-V3-large-1x</p></td>
<td><p>0.44</p></td>
<td><p>4.29</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://github.com/openvinotoolkit/training_extensions/blob/develop/src/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/template.yaml">Custom_Image_Classification_EfficinetNet-B0</a></p></td>
<td><p>EfficientNet-B0</p></td>
<td><p>0.81</p></td>
<td><p>4.09</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://github.com/openvinotoolkit/training_extensions/blob/develop/src/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/template.yaml">Custom_Image_Classification_EfficientNet-V2-S</a></p></td>
<td><p>EfficientNet-V2-S</p></td>
<td><p>5.76</p></td>
<td><p>20.23</p></td>
</tr>
</tbody>
</table>
<p><a class="reference external" href="https://arxiv.org/abs/2104.00298">EfficientNet-V2-S</a> has more parameters and Flops and needs more time to train, meanwhile providing superior classification performance. <a class="reference external" href="https://arxiv.org/abs/1905.02244">MobileNet-V3-large-1x</a> is the best choice when training time and computational cost are in priority, nevertheless, this template provides competitive accuracy as well.
<a class="reference external" href="https://arxiv.org/abs/1905.11946">EfficientNet-B0</a> consumes more Flops compared to MobileNet, providing better performance on large datasets, but may be not so stable in case of a small amount of training data.</p>
<p>Besides this, we support public backbones from <a class="reference external" href="https://pytorch.org/vision/stable/index.html">torchvision</a>, <a class="reference external" href="https://github.com/osmr/imgclsmob">pytorchcv</a>, <a class="reference external" href="https://github.com/open-mmlab/mmclassification">mmcls</a> and <a class="reference external" href="https://github.com/openvinotoolkit/open_model_zoo">OpenVino Model Zoo</a>.
Please, refer to the <a class="reference internal" href="../../../tutorials/advanced/backbones.html"><span class="doc">tutorial</span></a> how to customize models and run public backbones.</p>
<p>To see which public backbones are available for the task, the following command can be executed:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ otx find --backbone {torchvision, pytorchcv, mmcls, omz.mmcls}
</pre></div>
</div>
<p>In the table below the top-1 accuracy on some academic datasets using our <a class="reference internal" href="#mcl-cls-supervised-pipeline"><span class="std std-ref">supervised pipeline</span></a> is presented. The results were obtained on our templates without any changes. We use 224x224 image resolution, for other hyperparameters, please, refer to the related template. We trained each model with single Nvidia GeForce RTX3090.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Model name</p></th>
<th class="head"><p>CIFAR10</p></th>
<th class="head"><p>CIFAR100</p></th>
<th class="head"><p>flowers*</p></th>
<th class="head"><p>cars*</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>MobileNet-V3-large-1x</p></td>
<td><p>93.36</p></td>
<td><p>83.01</p></td>
<td><p>96.45</p></td>
<td><p>83.24</p></td>
</tr>
<tr class="row-odd"><td><p>EfficientNet-B0</p></td>
<td><p>94.86</p></td>
<td><p>84.73</p></td>
<td><p>96.86</p></td>
<td><p>85.70</p></td>
</tr>
<tr class="row-even"><td><p>EfficientNet-V2-S</p></td>
<td><p>96.13</p></td>
<td><p>90.36</p></td>
<td><p>97.68</p></td>
<td><p>86.74</p></td>
</tr>
</tbody>
</table>
<p>* These datasets were splitted with auto-split (80% train, 20% test).</p>
</section>
<section id="semi-supervised-learning">
<h2>Semi-supervised Learning<a class="headerlink" href="#semi-supervised-learning" title="Permalink to this heading">#</a></h2>
<p>Semi-SL (Semi-supervised Learning) is a type of machine learning algorithm that uses both labeled and unlabeled data to improve the performance of the model. This is particularly useful when labeled data is limited, expensive or time-consuming to obtain.</p>
<p>We use <a class="reference external" href="https://arxiv.org/abs/2001.07685">FixMatch</a> as a core algorithm for Semi-SL task solving. It is a specific implementation of Semi-SL that has been shown to be effective in various applications. FixMatch introduces pseudo-labeling, which is the process of generating labels for the unlabeled data and treating them as if they were labeled data. Pseudo-labeling is based on the idea that the model’s prediction for the unlabeled data is likely to be correct, which can improve the model’s accuracy and reduce the need for labeled data.</p>
<p>In Semi-SL, the pseudo-labeling process is combined with a consistency loss that ensures that the predictions of the model are consistent across augmented versions of the same data. This helps to reduce the impact of noisy or incorrect labels that may arise from the pseudo-labeling process. Additionally, our algorithm uses a combination of strong data augmentations and a specific optimizer called Sharpness-Aware Minimization (SAM) to further improve the accuracy of the model.</p>
<p>Overall, OpenVINO™ Training Extensions utilizes powerful techniques for improving the performance of Semi-SL algorithm with limited labeled data. They can be particularly useful in domains where labeled data is expensive or difficult to obtain, and can help to reduce the time and cost associated with collecting labeled data.</p>
<ul class="simple" id="mcl-cls-semi-supervised-pipeline">
<li><p><code class="docutils literal notranslate"><span class="pre">Pseudo-labeling</span> <span class="pre">(FixMatch)</span></code>: A specific implementation of Semi-SL that combines the use of pseudo-labeling with a consistency loss, strong data augmentations, and a specific optimizer called Sharpness-Aware Minimization (SAM) to improve the performance of the model.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Adaptable</span> <span class="pre">Threshold</span></code>: A novel addition to our solution that calculates a class-wise threshold for pseudo-labeling, which can solve the issue of imbalanced data and produce high-quality pseudo-labels that improve the overall score.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Unlabeled</span> <span class="pre">Warm-Up</span> <span class="pre">Loss</span></code>: A technique for preventing the initial unstable learning of pseudo-labeling by increasing the coefficient of the unlabeled loss from 0 to 1.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Exponential</span> <span class="pre">Moving</span> <span class="pre">Average</span> <span class="pre">(EMA)</span></code>: A technique for maintaining a moving average of the model’s parameters, which can improve the generalization performance of the model.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Additional</span> <span class="pre">techniques</span></code>: Other than that, we use several solutions that apply to supervised learning (No bias Decay, Augmentations, Early-Stopping, etc.)</p></li>
</ul>
<p>Please, refer to the <a class="reference internal" href="../../../tutorials/advanced/semi_sl.html"><span class="doc">tutorial</span></a> on how to train semi-supervised learning.
Training time depends on the number of images and can be up to several times longer than conventional supervised learning.</p>
<p>In the table below the top-1 accuracy on some academic datasets using our pipeline is presented. Same as the supervised setting except for an image for unlabeled and additional batch size.</p>
<ul class="simple">
<li><p>4 labeled images per class including unlabeled dataset for Semi-SL</p></li>
</ul>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Dataset</p></th>
<th class="head"><p>CIFAR10</p></th>
<th class="head"></th>
<th class="head"><p>SVHN</p></th>
<th class="head"></th>
<th class="head"><p>FMNIST</p></th>
<th class="head"></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td></td>
<td><p>SL</p></td>
<td><p>Semi-SL</p></td>
<td><p>SL</p></td>
<td><p>Semi-SL</p></td>
<td><p>SL</p></td>
<td><p>Semi-SL</p></td>
</tr>
<tr class="row-odd"><td><p>MobileNet-V3-large-1x</p></td>
<td><p>40.75</p></td>
<td><p>43.13</p></td>
<td><p>23.32</p></td>
<td><p>27.85</p></td>
<td><p>68.2</p></td>
<td><p>71.84</p></td>
</tr>
<tr class="row-even"><td><p>EfficientNet-B0</p></td>
<td><p>42.24</p></td>
<td><p>44.23</p></td>
<td><p>28.09</p></td>
<td><p>32.96</p></td>
<td><p>68.58</p></td>
<td><p>70.79</p></td>
</tr>
<tr class="row-odd"><td><p>EfficientNet-V2-S</p></td>
<td><p>36.03</p></td>
<td><p>39.66</p></td>
<td><p>16.81</p></td>
<td><p>20.28</p></td>
<td><p>65.99</p></td>
<td><p>69.61</p></td>
</tr>
</tbody>
</table>
<ul class="simple">
<li><p>10 labeled images per class including unlabeled dataset for Semi-SL</p></li>
</ul>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Dataset</p></th>
<th class="head"><p>CIFAR10</p></th>
<th class="head"></th>
<th class="head"><p>SVHN</p></th>
<th class="head"></th>
<th class="head"><p>FMNIST</p></th>
<th class="head"></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td></td>
<td><p>SL</p></td>
<td><p>Semi-SL</p></td>
<td><p>SL</p></td>
<td><p>Semi-SL</p></td>
<td><p>SL</p></td>
<td><p>Semi-SL</p></td>
</tr>
<tr class="row-odd"><td><p>MobileNet-V3-large-1x</p></td>
<td><p>50.77</p></td>
<td><p>52.16</p></td>
<td><p>38.73</p></td>
<td><p>48.36</p></td>
<td><p>73.33</p></td>
<td><p>77.04</p></td>
</tr>
<tr class="row-even"><td><p>EfficientNet-B0</p></td>
<td><p>52.69</p></td>
<td><p>58.35</p></td>
<td><p>46.04</p></td>
<td><p>61.79</p></td>
<td><p>74.56</p></td>
<td><p>80.14</p></td>
</tr>
<tr class="row-odd"><td><p>EfficientNet-V2-S</p></td>
<td><p>48.84</p></td>
<td><p>55</p></td>
<td><p>26.16</p></td>
<td><p>47.99</p></td>
<td><p>74.6</p></td>
<td><p>80.92</p></td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This result can vary greatly depending on the image selected for each class. Also, since there are few labeled settings for the Semi-SL algorithm. Some models may require larger datasets for better results.</p>
</div>
</section>
<section id="self-supervised-learning">
<h2>Self-supervised Learning<a class="headerlink" href="#self-supervised-learning" title="Permalink to this heading">#</a></h2>
<p id="selfsl-multi-class-classification">Self-supervised learning can be one of the solutions if the user has a small data set, but label information is not yet available.
General self-supervised Learning in academia is commonly used to obtain well-pretrained weights from a source dataset without label information.
However, in real-world industries, it is difficult to apply because of small datasets, limited resources, or training in minutes.</p>
<p>For these cases, OpenVINO™ Training Extensions provides improved self-supervised learning recipes that can be applied to the above harsh environments.
We adapted <a class="reference external" href="https://arxiv.org/abs/2006.07733">BYOL</a> as our self-supervised method.
This algorithm will require some additional training time, meanwhile, improved performance is expected, especially in low-data regimes.
OpenVINO™ Training Extensions allows to perform a pre-training phase on any images to further use obtained weights on the target dataset.</p>
<p>Below is graphs of performance improvement for three baseline datasets: CIFAR10, CIFAR100, and Food-101.
The graphs below show how much performance improvement over baseline was achieved using our self-supervised learning recipes.
We created subset datasets by sampling images to check performance from small to large datasets.
In particular, the smaller the data, the greater the performance improvement can be expected.
To get the below performance, we had two steps:</p>
<ul class="simple">
<li><p>Train the models using only images without label information to get pretrained weights for a few epochs.</p></li>
<li><p>Fine-tune the models with pretrained weights using subset datasets and get performance.</p></li>
</ul>
<p>We additionally obtained baseline performance from supervised learning using subset datasets for comparison.
Each subset dataset has 500, 1000, 5000, 10000, and the whole images, respectively.</p>
<a class="reference internal image-reference" href="../../../../_images/multi_cls_selfsl_performance_CIFAR10.png"><img alt="../../../../_images/multi_cls_selfsl_performance_CIFAR10.png" src="../../../../_images/multi_cls_selfsl_performance_CIFAR10.png" style="width: 600px;" /></a>
<a class="reference internal image-reference" href="../../../../_images/multi_cls_selfsl_performance_CIFAR100.png"><img alt="../../../../_images/multi_cls_selfsl_performance_CIFAR100.png" src="../../../../_images/multi_cls_selfsl_performance_CIFAR100.png" style="width: 600px;" /></a>
<a class="reference internal image-reference" href="../../../../_images/multi_cls_selfsl_performance_Food-101.png"><img alt="../../../../_images/multi_cls_selfsl_performance_Food-101.png" src="../../../../_images/multi_cls_selfsl_performance_Food-101.png" style="width: 600px;" /></a>
<p>To enable self-supervised training, the command below can be executed. The folder with images for pre-training is needed to be passed in <code class="docutils literal notranslate"><span class="pre">--train-data-root</span></code> folder.
Unlike other tasks, <code class="docutils literal notranslate"><span class="pre">--val-data-root</span></code> is not needed.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ otx train EfficientNet-V2-S \
            --train-data-root path/to/folder/with/images
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It is also possible to pass a full imagenet dataset format to <code class="docutils literal notranslate"><span class="pre">--train-data-root</span></code> instead of just a folder with images.
However, it will be required to add <code class="docutils literal notranslate"><span class="pre">--train-type</span> <span class="pre">Selfsupervised</span></code> option into the command line. Otherwise, ordinary supervised training will be started with auto-split functionality.</p>
</div>
<p>After self-supervised training, pretrained weights can be use for supervised (incremental) learning like the below command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ otx train EfficientNet-V2-S \
            --train-data-roots path/to/train/subset \
            --val-data-roots path/to/val/subset \
            --load-weights={PATH/PRETRAINED/WEIGHTS}
</pre></div>
</div>
</section>
<section id="supervised-contrastive-learning">
<h2>Supervised Contrastive Learning<a class="headerlink" href="#supervised-contrastive-learning" title="Permalink to this heading">#</a></h2>
<p>To enhance the performance of the algorithm in the case when we have a small number of data, <a class="reference external" href="https://arxiv.org/abs/2004.11362">Supervised Contrastive Learning (SupCon)</a> can be used.
More specifically, we train a model with two heads: classification head with Influence-Balanced Loss and contrastive head with <a class="reference external" href="https://arxiv.org/abs/2103.03230">Barlow Twins loss</a>.
The below table shows how much performance SupCon improved compared with baseline performance on three baseline datasets with 10 samples per class: CIFAR10, Eurosat-10, and Food-101.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Model name</p></th>
<th class="head"><p>CIFAR10</p></th>
<th class="head"></th>
<th class="head"><p>Eurosat-10</p></th>
<th class="head"></th>
<th class="head"><p>Food-101</p></th>
<th class="head"></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td></td>
<td><p>SL</p></td>
<td><p>SupCon</p></td>
<td><p>SL</p></td>
<td><p>SupCon</p></td>
<td><p>SL</p></td>
<td><p>SupCon</p></td>
</tr>
<tr class="row-odd"><td><p>MobileNet-V3-large-1x</p></td>
<td><p>55.06</p></td>
<td><p>58.88</p></td>
<td><p>77.60</p></td>
<td><p>78.70</p></td>
<td><p>34.83</p></td>
<td><p>34.38</p></td>
</tr>
<tr class="row-even"><td><p>EfficientNet-B0</p></td>
<td><p>42.81</p></td>
<td><p>46.35</p></td>
<td><p>66.87</p></td>
<td><p>70.23</p></td>
<td><p>37.26</p></td>
<td><p>39.17</p></td>
</tr>
<tr class="row-odd"><td><p>EfficientNet-V2-S</p></td>
<td><p>59.78</p></td>
<td><p>63.13</p></td>
<td><p>81.84</p></td>
<td><p>83.12</p></td>
<td><p>51.32</p></td>
<td><p>54.84</p></td>
</tr>
</tbody>
</table>
<p>The SupCon training can be launched by adding additional option to template parameters like the below.
It can be launched only with supervised (incremental) training type.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ otx train src/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/template.yaml \
            --train-data-roots=tests/assets/imagenet_dataset_class_incremental \
            --val-data-roots=tests/assets/imagenet_dataset_class_incremental \
            params \
            --learning_parameters.enable_supcon=True
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>SL stands for Supervised Learning.</p>
</div>
</section>
</section>


            </article>
            
            
            
            <footer class="bd-footer-article">
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
  <a class='left-prev' id="prev-link" href="index.html" title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
          <p class="prev-next-subtitle">previous</p>
          <p class="prev-next-title">Classification</p>
      </div>
  </a>
  <a class='right-next' id="next-link" href="multi_label_classification.html" title="next page">
  <div class="prev-next-info">
      <p class="prev-next-subtitle">next</p>
      <p class="prev-next-title">Multi-label Classification</p>
  </div>
  <i class="fa-solid fa-angle-right"></i>
  </a>
</div>
            </footer>
            
          </div>
          
          
          
            <div class="bd-sidebar-secondary bd-toc">
              
<div class="toc-item">
  
<div class="tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
</div>
<nav id="bd-toc-nav" class="page-toc">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dataset-format">
   Dataset Format
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#models">
   Models
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#semi-supervised-learning">
   Semi-supervised Learning
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#self-supervised-learning">
   Self-supervised Learning
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#supervised-contrastive-learning">
   Supervised Contrastive Learning
  </a>
 </li>
</ul>

</nav>
</div>

<div class="toc-item">
  
<div id="searchbox"></div>
</div>

<div class="toc-item">
  
</div>

<div class="toc-item">
  
<div class="tocsection sourcelink">
    <a href="../../../../_sources/guide/explanation/algorithms/classification/multi_class_classification.rst.txt">
        <i class="fa-solid fa-file-lines"></i> Show Source
    </a>
</div>

</div>

            </div>
          
          
        </div>
        <footer class="bd-footer-content">
          <div class="bd-footer-content__inner">
            
          </div>
        </footer>
        
      </main>
    </div>
  </div>

  
    
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94"></script>
<script src="../../../../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94"></script>

  <footer class="bd-footer"><div class="bd-footer__inner container">
  
  <div class="footer-item">
    
<p class="copyright">

    &copy; Copyright 2023, OpenVINO™ Training Extensions Contributors.<br>

</p>

  </div>
  
  <div class="footer-item">
    <p class="theme-version">
    Built with the
    <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">
        PyData Sphinx Theme
    </a>
    0.12.0.
</p>
  </div>
  
  <div class="footer-item">
    
<p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 5.3.0.<br>
</p>

  </div>
  
</div>
  </footer>
  </body>
</html>