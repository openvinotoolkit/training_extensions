{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTX API DEMO (MMPretrain Example)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customization Training API\n",
    "\n",
    "Select a framework & import adapter modules.\n",
    "\n",
    "We'll choose MMpretrain here."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Environment:\n",
    "- mmpretrain-1.0.0rc8\n",
    "- mmcv-2.0.1\n",
    "- mmengine-0.7.4\n",
    "- mmdeploy-1.2.0\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset & DataLoader\n",
    "1. Prepare a dataset and enter path into Dataset\n",
    "\n",
    "    - Convert to OTX's DatasetEntity and Label Schema by leveraging Datumaro's features through paths (path -> Datumaro -> OTX DatasetEntity & LabelSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/repo/otx-fork-3/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/harimkan/workspace/repo/otx-fork-3/venv/lib/python3.9/site-packages/openvino/pyopenvino/__init__.py:10: FutureWarning: The module is private and following namespace `pyopenvino` will be removed in the future\n",
      "  warnings.warn(message=\"The module is private and following namespace \" \"`pyopenvino` will be removed in the future\", category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from otx.v2.adapters.torch.mmengine.mmpretrain import Dataset\n",
    "dataset = Dataset(\n",
    "    train_data_roots=\"/home/harimkan/workspace/repo/otx-fork-3/tests/assets/classification_dataset_class_incremental\",\n",
    "    val_data_roots=\"/home/harimkan/workspace/repo/otx-fork-3/tests/assets/classification_dataset_class_incremental\",\n",
    "    test_data_roots=\"/home/harimkan/workspace/repo/otx-fork-3/tests/assets/classification_dataset_class_incremental\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-1. Build Torch Dataset from MMCV config (filepath or dict) -> torch.utils.data.Dataset\n",
    "\n",
    "    - User can build a dataset from a config file or dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Detected dataset format: imagenet\n",
      "[*] Detected task type: CLASSIFICATION\n",
      "2023-07-31 14:45:40,208 | INFO : Try to create a 0 size memory pool.\n",
      "Dataset type: <class 'torch.utils.data.dataloader.DataLoader'>\n",
      "Length of DataLoader: 32\n",
      "Dataset size: 32\n",
      "Number of classes: 3\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = dataset.train_dataloader()\n",
    "print(f\"Dataset type: {type(train_dataloader)}\")\n",
    "print(f\"Length of DataLoader: {len(train_dataloader)}\")\n",
    "print(f\"Dataset size: {len(train_dataloader.dataset)}\")\n",
    "print(f\"Number of classes: {dataset.num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader type: <class 'torch.utils.data.dataloader.DataLoader'>\n",
      "Length of DataLoader: 8\n",
      "Dataset size: 32\n"
     ]
    }
   ],
   "source": [
    "# Customize batch_size\n",
    "train_dataloader = dataset.train_dataloader(batch_size=4)\n",
    "print(f\"DataLoader type: {type(train_dataloader)}\")\n",
    "print(f\"Length of DataLoader: {len(train_dataloader)}\")\n",
    "print(f\"Dataset size: {len(train_dataloader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader type: <class 'torch.utils.data.dataloader.DataLoader'>\n",
      "Length of DataLoader: 32\n",
      "Dataset size: 32\n"
     ]
    }
   ],
   "source": [
    "val_dataloader = dataset.val_dataloader()\n",
    "print(f\"DataLoader type: {type(val_dataloader)}\")\n",
    "print(f\"Length of DataLoader: {len(val_dataloader)}\")\n",
    "print(f\"Dataset size: {len(val_dataloader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader type: <class 'torch.utils.data.dataloader.DataLoader'>\n",
      "Length of DataLoader: 32\n",
      "Dataset size: 32\n"
     ]
    }
   ],
   "source": [
    "test_dataloader = dataset.test_dataloader()\n",
    "print(f\"DataLoader type: {type(test_dataloader)}\")\n",
    "print(f\"Length of DataLoader: {len(test_dataloader)}\")\n",
    "print(f\"Dataset size: {len(test_dataloader.dataset)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Model\n",
    "### Model provided by OTX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['resnet101-csra_1xb16_voc07-448px', 'resnet101_8xb16_cifar10', 'resnet101_8xb32_in1k', 'resnet152_8xb16_cifar10', 'resnet152_8xb32_in1k', 'resnet18_8xb16_cifar10', 'resnet18_8xb32_in1k', 'resnet34_8xb16_cifar10', 'resnet34_8xb32_in1k', 'resnet50-arcface_8xb32_inshop', 'resnet50_8xb16_cifar10', 'resnet50_8xb16_cifar100', 'resnet50_8xb256-rsb-a1-600e_in1k', 'resnet50_8xb256-rsb-a2-300e_in1k', 'resnet50_8xb256-rsb-a3-100e_in1k', 'resnet50_8xb32-fp16_in1k', 'resnet50_8xb32_in1k', 'resnet50_8xb8_cub', 'resnet50_barlowtwins-pre_8xb32-linear-coslr-100e_in1k', 'resnet50_byol-pre_8xb512-linear-coslr-90e_in1k', 'resnet50_densecl-pre_8xb32-linear-steplr-100e_in1k', 'resnet50_mocov2-pre_8xb32-linear-steplr-100e_in1k', 'resnet50_mocov3-100e-pre_8xb128-linear-coslr-90e_in1k', 'resnet50_mocov3-300e-pre_8xb128-linear-coslr-90e_in1k', 'resnet50_mocov3-800e-pre_8xb128-linear-coslr-90e_in1k', 'resnet50_simclr-200e-pre_8xb512-linear-coslr-90e_in1k', 'resnet50_simclr-800e-pre_8xb512-linear-coslr-90e_in1k', 'resnet50_simsiam-100e-pre_8xb512-linear-coslr-90e_in1k', 'resnet50_simsiam-200e-pre_8xb512-linear-coslr-90e_in1k', 'resnet50_swav-pre_8xb32-linear-coslr-100e_in1k', 'resnetv1c101_8xb32_in1k', 'resnetv1c152_8xb32_in1k', 'resnetv1c50_8xb32_in1k', 'resnetv1d101_8xb32_in1k', 'resnetv1d152_8xb32_in1k', 'resnetv1d50_8xb32_in1k']\n"
     ]
    }
   ],
   "source": [
    "from otx.v2.adapters.torch.mmengine.mmpretrain import list_models\n",
    "# MMPretrain's model\n",
    "model_list = list_models(\"resnet*\")\n",
    "print(model_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['otx_efficientnet_b0', 'otx_mobilenet_v3_large_1']\n"
     ]
    }
   ],
   "source": [
    "# OTX's model\n",
    "model_list = list_models(\"otx*\")\n",
    "print(model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-31 14:45:41,081 | INFO : init weight - https://github.com/osmr/imgclsmob/releases/download/v0.0.364/efficientnet_b0-0752-0e386130.pth.zip\n",
      "2023-07-31 14:45:41,108 | INFO : 'in_channels' config in model.head is updated from -1 to 1280\n",
      "2023-07-31 14:45:41,175 | INFO : init weight - https://github.com/osmr/imgclsmob/releases/download/v0.0.364/efficientnet_b0-0752-0e386130.pth.zip\n",
      "Model type: <class 'otx.v2.adapters.torch.mmengine.mmpretrain.modules.models.classifiers.sam_classifier.SAMImageClassifier'>\n"
     ]
    }
   ],
   "source": [
    "## Build Model from Config\n",
    "from otx.v2.adapters.torch.mmengine.mmpretrain import get_model\n",
    "otx_model = get_model(\n",
    "    model=\"../configs/classification/models/otx_efficientnet_b0.yaml\",\n",
    "    num_classes=dataset.num_classes\n",
    ")\n",
    "print(f\"Model type: {type(otx_model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-31 14:45:41,245 | INFO : init weight - https://github.com/osmr/imgclsmob/releases/download/v0.0.364/efficientnet_b0-0752-0e386130.pth.zip\n",
      "2023-07-31 14:45:41,265 | INFO : 'in_channels' config in model.head is updated from -1 to 1280\n",
      "2023-07-31 14:45:41,331 | INFO : init weight - https://github.com/osmr/imgclsmob/releases/download/v0.0.364/efficientnet_b0-0752-0e386130.pth.zip\n",
      "Model type: <class 'otx.v2.adapters.torch.mmengine.mmpretrain.modules.models.classifiers.sam_classifier.SAMImageClassifier'>\n"
     ]
    }
   ],
   "source": [
    "## Build Model from name\n",
    "otx_model = get_model(\n",
    "    model=model_list[0],  # == \"otx_efficientnet_b0\"\n",
    "    num_classes=dataset.num_classes\n",
    ")\n",
    "print(f\"Model type: {type(otx_model)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model provided by mmpretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model type: <class 'mmpretrain.models.classifiers.image.ImageClassifier'>\n"
     ]
    }
   ],
   "source": [
    "# mmpretrain's pre-defined model\n",
    "mmpretrain_model = get_model(\"resnet18_8xb32_in1k\")\n",
    "print(f\"Model type: {type(mmpretrain_model)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Users can use each framework's training provided by OTX. (Engine)\n",
    "\n",
    "- The engine requires the necessary models and DataLoaders for each framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/31 14:45:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.9.13 (main, Aug 25 2022, 23:26:10) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    numpy_random_seed: 1730906610\n",
      "    GPU 0,1: NVIDIA GeForce RTX 3090\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 11.7, V11.7.64\n",
      "    GCC: gcc (Ubuntu 9.5.0-1ubuntu1~22.04) 9.5.0\n",
      "    PyTorch: 1.13.1+cu117\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.7\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.5\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.14.1+cu117\n",
      "    OpenCV: 4.8.0\n",
      "    MMEngine: 0.7.4\n",
      "\n",
      "Runtime environment:\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 1730906610\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "07/31 14:45:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "07/31 14:45:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "2023-07-31 14:45:42,529 | WARNING : The config used in the build isstored as an object in the configurationfile because the object doesn't have it.This can result in a non-reusable configs.py.\n",
      "07/31 14:45:42 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "07/31 14:45:42 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "07/31 14:45:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /tmp/otx-test.\n",
      "07/31 14:45:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: otx_train_20230731_144541\n",
      "07/31 14:45:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][8/8]  lr: 1.0000e-02  eta: 0:00:02  time: 0.1482  data_time: 0.0014  memory: 413  loss: 1.1238\n",
      "07/31 14:45:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "07/31 14:45:43 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - `save_param_scheduler` is True but `self.param_schedulers` is None, so skip saving parameter schedulers\n",
      "07/31 14:45:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: otx_train_20230731_144541\n",
      "07/31 14:45:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [2][8/8]  lr: 1.0000e-02  eta: 0:00:00  time: 0.0276  data_time: 0.0012  memory: 413  loss: 0.8464\n",
      "07/31 14:45:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 2 epochs\n",
      "07/31 14:45:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: otx_train_20230731_144541\n",
      "07/31 14:45:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [3][8/8]  lr: 1.0000e-02  eta: 0:00:00  time: 0.0279  data_time: 0.0011  memory: 413  loss: 0.2336\n",
      "07/31 14:45:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 3 epochs\n",
      "/tmp/otx-test/best_accuracy_top1_epoch_3.pth\n"
     ]
    }
   ],
   "source": [
    "from otx.v2.adapters.torch.mmengine.mmpretrain.engine import MMPTEngine\n",
    "\n",
    "# OTX Model Training\n",
    "engine = MMPTEngine(work_dir=\"/tmp/otx-test\",)\n",
    "\n",
    "# Training without validation\n",
    "results = engine.train(\n",
    "    model=otx_model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    max_epochs=3,\n",
    ")\n",
    "\n",
    "print(results[\"checkpoint\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-31 14:45:44,722 | WARNING : The config used in the build isstored as an object in the configurationfile because the object doesn't have it.This can result in a non-reusable configs.py.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/31 14:45:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [3][32/32]    accuracy/top1: 56.2500  data_time: 0.0003  time: 0.0061\n",
      "07/31 14:45:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 56.2500 accuracy/top1 at 3 epoch is saved to best_accuracy_top1_epoch_3.pth.\n",
      "Val Metric: {'accuracy/top1': 56.25}\n",
      "2023-07-31 14:45:45,286 | WARNING : The config used in the build isstored as an object in the configurationfile because the object doesn't have it.This can result in a non-reusable configs.py.\n",
      "07/31 14:45:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [32/32]    accuracy/top1: 56.2500  data_time: 0.0003  time: 0.0061\n",
      "Test Metric: {'accuracy/top1': 56.25}\n"
     ]
    }
   ],
   "source": [
    "val_score = engine.validate(val_dataloader=val_dataloader)\n",
    "print(f\"Val Metric: {val_score}\")\n",
    "\n",
    "test_score = engine.test(test_dataloader=test_dataloader)\n",
    "print(f\"Test Metric: {test_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/31 14:45:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.9.13 (main, Aug 25 2022, 23:26:10) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    numpy_random_seed: 1632916443\n",
      "    GPU 0,1: NVIDIA GeForce RTX 3090\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 11.7, V11.7.64\n",
      "    GCC: gcc (Ubuntu 9.5.0-1ubuntu1~22.04) 9.5.0\n",
      "    PyTorch: 1.13.1+cu117\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.7\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.5\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.14.1+cu117\n",
      "    OpenCV: 4.8.0\n",
      "    MMEngine: 0.7.4\n",
      "\n",
      "Runtime environment:\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 1632916443\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "07/31 14:45:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "07/31 14:45:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "2023-07-31 14:45:45,773 | WARNING : The config used in the build isstored as an object in the configurationfile because the object doesn't have it.This can result in a non-reusable configs.py.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/31 14:45:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - init_weights of SAMImageClassifier has been called more than once.\n",
      "07/31 14:45:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "07/31 14:45:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /tmp/otx-test.\n",
      "07/31 14:45:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: otx_train_20230731_144545\n",
      "07/31 14:45:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][8/8]  lr: 1.0000e-02  eta: 0:00:00  time: 0.0263  data_time: 0.0012  memory: 476  loss: 0.7715\n",
      "07/31 14:45:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "07/31 14:45:46 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - `save_param_scheduler` is True but `self.param_schedulers` is None, so skip saving parameter schedulers\n",
      "07/31 14:45:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][32/32]    accuracy/top1: 100.0000  data_time: 0.0003  time: 0.0061\n",
      "07/31 14:45:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 100.0000 accuracy/top1 at 1 epoch is saved to best_accuracy_top1_epoch_1.pth.\n",
      "07/31 14:45:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: otx_train_20230731_144545\n",
      "07/31 14:45:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [2][8/8]  lr: 1.0000e-02  eta: 0:00:00  time: 0.0275  data_time: 0.0012  memory: 476  loss: 0.3138\n",
      "07/31 14:45:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 2 epochs\n",
      "07/31 14:45:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [2][32/32]    accuracy/top1: 3.1250  data_time: 0.0003  time: 0.0061\n",
      "07/31 14:45:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: otx_train_20230731_144545\n",
      "07/31 14:45:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [3][8/8]  lr: 1.0000e-02  eta: 0:00:00  time: 0.0343  data_time: 0.0014  memory: 476  loss: 1.2075\n",
      "07/31 14:45:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 3 epochs\n",
      "07/31 14:45:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [3][32/32]    accuracy/top1: 40.6250  data_time: 0.0003  time: 0.0061\n",
      "/tmp/otx-test/best_accuracy_top1_epoch_3.pth\n"
     ]
    }
   ],
   "source": [
    "# OR\n",
    "# Training with validation\n",
    "results = engine.train(\n",
    "    model=otx_model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    max_epochs=3,\n",
    ")\n",
    "trained_model = results[\"model\"]\n",
    "checkpoint = results[\"checkpoint\"]\n",
    "\n",
    "print(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-31 14:45:47,871 | WARNING : The config used in the build isstored as an object in the configurationfile because the object doesn't have it.This can result in a non-reusable configs.py.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/31 14:45:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [3][32/32]    accuracy/top1: 40.6250  data_time: 0.0003  time: 0.0060\n",
      "Val Metric: {'accuracy/top1': 40.625}\n",
      "2023-07-31 14:45:48,175 | WARNING : The config used in the build isstored as an object in the configurationfile because the object doesn't have it.This can result in a non-reusable configs.py.\n",
      "07/31 14:45:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [32/32]    accuracy/top1: 40.6250  data_time: 0.0003  time: 0.0061\n",
      "Test Metric: {'accuracy/top1': 40.625}\n"
     ]
    }
   ],
   "source": [
    "val_score = engine.validate()\n",
    "print(f\"Val Metric: {val_score}\")\n",
    "\n",
    "test_score = engine.test(test_dataloader=test_dataloader)\n",
    "print(f\"Test Metric: {test_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: /tmp/otx-test/best_accuracy_top1_epoch_3.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'pred_scores': array([0.49651948, 0.4911402 , 0.01234036], dtype=float32), 'pred_label': 0, 'pred_score': 0.4965194761753082}]\n"
     ]
    }
   ],
   "source": [
    "sample = \"/home/harimkan/workspace/repo/otx-fork-3/tests/assets/classification_dataset_class_incremental/2/22.jpg\"\n",
    "\n",
    "predict_output = engine.predict(\n",
    "    model=trained_model,\n",
    "    checkpoint=checkpoint,\n",
    "    img=sample\n",
    ")\n",
    "\n",
    "print(predict_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export (with mmdeploy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/31 14:45:49 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmengine\" in the \"Codebases\" registry tree. As a workaround, the current \"Codebases\" registry in \"mmdeploy\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmengine\" is a correct scope, or whether the registry is initialized.\n",
      "07/31 14:45:49 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmpretrain\" in the \"Codebases\" registry tree. As a workaround, the current \"Codebases\" registry in \"mmdeploy\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmpretrain\" is a correct scope, or whether the registry is initialized.\n",
      "07/31 14:45:49 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmpretrain\" in the \"mmpretrain_tasks\" registry tree. As a workaround, the current \"mmpretrain_tasks\" registry in \"mmdeploy\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmpretrain\" is a correct scope, or whether the registry is initialized.\n",
      "2023-07-31 14:45:49,297 | INFO : init weight - https://github.com/osmr/imgclsmob/releases/download/v0.0.364/efficientnet_b0-0752-0e386130.pth.zip\n",
      "07/31 14:45:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Export PyTorch model to ONNX: /tmp/otx-test/openvino.onnx.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/repo/otx-fork-3/venv/lib/python3.9/site-packages/mmpretrain/utils/setup_env.py:34: UserWarning: The current default scope \"mmengine\" is not \"mmpretrain\", `register_all_modules` will force the current default scope to be \"mmpretrain\". If this is not expected, please set `init_default_scope=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/31 14:45:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Args for Model Optimizer: mo --input_model=\"/tmp/otx-test/openvino.onnx\" --output_dir=\"/tmp/otx-test/\" --output=\"output\" --input=\"input\" --input_shape=\"[1, 3, 224, 224]\" --mean_values=\"[123.675, 116.28, 103.53]\" --scale_values=\"[58.395, 57.12, 57.375]\" \n",
      "07/31 14:45:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&source=prod&campid=ww_2023_bu_IOTG_OpenVINO-2022-3&content=upg_all&medium=organic or on https://github.com/openvinotoolkit/openvino\n",
      "[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.\n",
      "Find more information about API v2.0 and IR v11 at https://docs.openvino.ai/latest/openvino_2_0_transition_guide.html\n",
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: /tmp/otx-test/openvino.xml\n",
      "[ SUCCESS ] BIN file: /tmp/otx-test/openvino.bin\n",
      "\n",
      "07/31 14:45:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Successfully exported OpenVINO model: /tmp/otx-test/openvino.xml\n",
      "{'outputs': {'bin': '/tmp/otx-test/openvino.bin', 'xml': '/tmp/otx-test/openvino.xml'}}\n"
     ]
    }
   ],
   "source": [
    "export_output = engine.export(\n",
    "    model=trained_model,\n",
    "    checkpoint=checkpoint,\n",
    ")\n",
    "\n",
    "print(export_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OTX AutoEngine (Automation Training API)\n",
    "OTX provides a more convenient API called AutoEngine.\n",
    "\n",
    "- It's more convenient for users to use Engine, which provides auto-configuration and the features provided by OTX without having to choose a framework.\n",
    "- Prepare Dataset & DataLoader + Prepare Model + OTX Recipes + Training + ETC.\n",
    "- This will make all of the above steps happen automatically. (Auto: Model Selection & build, Dataset Configuration, Training, etc..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Detected dataset format: imagenet\n",
      "[*] Detected task type: CLASSIFICATION\n",
      "2023-07-31 14:45:52,922 | INFO : init weight - https://github.com/osmr/imgclsmob/releases/download/v0.0.364/efficientnet_b0-0752-0e386130.pth.zip\n",
      "2023-07-31 14:45:52,942 | INFO : 'in_channels' config in model.head is updated from -1 to 1280\n",
      "2023-07-31 14:45:53,012 | INFO : init weight - https://github.com/osmr/imgclsmob/releases/download/v0.0.364/efficientnet_b0-0752-0e386130.pth.zip\n",
      "2023-07-31 14:45:53,014 | WARNING : Currently, OTX does not accept val_dataloader as a dict configuration.\n",
      "2023-07-31 14:45:53,015 | WARNING : Currently, OTX does not accept test_dataloader as a dict configuration.\n",
      "2023-07-31 14:45:53,015 | WARNING : In Engine.config, remove ['framework', 'data', 'optimizer', 'max_epochs', 'max_iters', 'val_interval', 'precision'] that are unavailable to the Runner.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/31 14:45:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.9.13 (main, Aug 25 2022, 23:26:10) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    numpy_random_seed: 1205512832\n",
      "    GPU 0,1: NVIDIA GeForce RTX 3090\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 11.7, V11.7.64\n",
      "    GCC: gcc (Ubuntu 9.5.0-1ubuntu1~22.04) 9.5.0\n",
      "    PyTorch: 1.13.1+cu117\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.7\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.5\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.14.1+cu117\n",
      "    OpenCV: 4.8.0\n",
      "    MMEngine: 0.7.4\n",
      "\n",
      "Runtime environment:\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 1205512832\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "07/31 14:45:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "07/31 14:45:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "2023-07-31 14:45:53,225 | WARNING : The config used in the build isstored as an object in the configurationfile because the object doesn't have it.This can result in a non-reusable configs.py.\n",
      "07/31 14:45:53 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "07/31 14:45:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /tmp/OTX-API-test.\n",
      "07/31 14:45:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: otx_train_20230731_144553\n",
      "07/31 14:45:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][16/16]  lr: 1.0000e-02  eta: 0:00:00  time: 0.0280  data_time: 0.0044  memory: 547  loss: 0.7379\n",
      "07/31 14:45:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/repo/otx-fork-3/venv/lib/python3.9/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/31 14:45:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: otx_train_20230731_144553\n",
      "07/31 14:45:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [2][16/16]  lr: 5.0000e-03  eta: 0:00:00  time: 0.0272  data_time: 0.0040  memory: 547  loss: 1.8207\n",
      "07/31 14:45:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 2 epochs\n",
      "/tmp/OTX-API-test/best_accuracy_top1_epoch_2.pth\n"
     ]
    }
   ],
   "source": [
    "from otx.v2.api.core.engine import AutoEngine\n",
    "\n",
    "output_dir = \"/tmp/OTX-API-test\"\n",
    "data_roots = \"../../../../tests/assets/classification_dataset_class_incremental\"\n",
    "\n",
    "engine = AutoEngine(\n",
    "    work_dir=output_dir,\n",
    "    train_data_roots=data_roots,\n",
    ")\n",
    "\n",
    "# Customization training\n",
    "results = engine.train(batch_size=2, max_epochs=2)\n",
    "print(results[\"checkpoint\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Detected dataset format: imagenet\n",
      "[*] Detected task type: CLASSIFICATION\n",
      "2023-07-31 14:45:54,645 | INFO : init weight - https://github.com/osmr/imgclsmob/releases/download/v0.0.364/efficientnet_b0-0752-0e386130.pth.zip\n",
      "2023-07-31 14:45:54,664 | INFO : 'in_channels' config in model.head is updated from -1 to 1280\n",
      "2023-07-31 14:45:54,733 | INFO : init weight - https://github.com/osmr/imgclsmob/releases/download/v0.0.364/efficientnet_b0-0752-0e386130.pth.zip\n",
      "2023-07-31 14:45:54,735 | WARNING : Currently, OTX does not accept test_dataloader as a dict configuration.\n",
      "2023-07-31 14:45:54,736 | WARNING : In Engine.config, remove ['framework', 'data', 'optimizer', 'max_epochs', 'max_iters', 'val_interval', 'precision'] that are unavailable to the Runner.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/31 14:45:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.9.13 (main, Aug 25 2022, 23:26:10) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    numpy_random_seed: 1585278852\n",
      "    GPU 0,1: NVIDIA GeForce RTX 3090\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 11.7, V11.7.64\n",
      "    GCC: gcc (Ubuntu 9.5.0-1ubuntu1~22.04) 9.5.0\n",
      "    PyTorch: 1.13.1+cu117\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.7\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.5\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.14.1+cu117\n",
      "    OpenCV: 4.8.0\n",
      "    MMEngine: 0.7.4\n",
      "\n",
      "Runtime environment:\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 1585278852\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "07/31 14:45:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "07/31 14:45:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "2023-07-31 14:45:54,947 | WARNING : The config used in the build isstored as an object in the configurationfile because the object doesn't have it.This can result in a non-reusable configs.py.\n",
      "07/31 14:45:55 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "07/31 14:45:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /tmp/OTX-API-test.\n",
      "07/31 14:45:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: otx_train_20230731_144554\n",
      "07/31 14:45:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][16/16]  lr: 1.0000e-02  eta: 0:00:00  time: 0.0278  data_time: 0.0043  memory: 611  loss: 1.4787\n",
      "07/31 14:45:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "07/31 14:45:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][16/16]    accuracy/top1: 12.5000  data_time: 0.0005  time: 0.0067\n",
      "07/31 14:45:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 12.5000 accuracy/top1 at 1 epoch is saved to best_accuracy_top1_epoch_1.pth.\n",
      "07/31 14:45:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: otx_train_20230731_144554\n",
      "07/31 14:45:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [2][16/16]  lr: 5.0000e-03  eta: 0:00:00  time: 0.0278  data_time: 0.0042  memory: 611  loss: 1.8974\n",
      "07/31 14:45:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 2 epochs\n",
      "07/31 14:45:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [2][16/16]    accuracy/top1: 21.8750  data_time: 0.0005  time: 0.0067\n",
      "07/31 14:45:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /tmp/OTX-API-test/best_accuracy_top1_epoch_1.pth is removed\n",
      "07/31 14:45:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 21.8750 accuracy/top1 at 2 epoch is saved to best_accuracy_top1_epoch_2.pth.\n",
      "/tmp/OTX-API-test/best_accuracy_top1_epoch_2.pth\n"
     ]
    }
   ],
   "source": [
    "# With Validation\n",
    "engine = AutoEngine(\n",
    "    work_dir=output_dir,\n",
    "    train_data_roots=data_roots,\n",
    "    val_data_roots=data_roots,\n",
    ")\n",
    "\n",
    "# Customization training\n",
    "results = engine.train(batch_size=2, max_epochs=2)\n",
    "print(results[\"checkpoint\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
