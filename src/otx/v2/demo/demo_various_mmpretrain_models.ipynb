{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/repo/otx-main/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/harimkan/workspace/repo/otx-main/venv/lib/python3.9/site-packages/openvino/pyopenvino/__init__.py:10: FutureWarning: The module is private and following namespace `pyopenvino` will be removed in the future\n",
      "  warnings.warn(message=\"The module is private and following namespace \" \"`pyopenvino` will be removed in the future\", category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from otx.v2.adapters.torch.mmengine.mmpretrain import Dataset\n",
    "dataset = Dataset(\n",
    "    train_data_roots=\"../../../../../demo/dataset/cifar10-small/train_data\",\n",
    "    val_data_roots=\"../../../../../demo/dataset/cifar10-small/val_data\",\n",
    "    test_data_roots=\"../../../../../demo/dataset/cifar10-small/val_data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Detected dataset format: imagenet\n",
      "[*] Detected task type: CLASSIFICATION\n",
      "2023-08-18 18:05:58,914 | INFO : Try to create a 0 size memory pool.\n",
      "Dataset type: <class 'torch.utils.data.dataloader.DataLoader'>\n",
      "Length of DataLoader: 5\n",
      "Dataset size: 10\n",
      "Number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = dataset.train_dataloader(batch_size=2)\n",
    "\n",
    "print(f\"Dataset type: {type(train_dataloader)}\")\n",
    "print(f\"Length of DataLoader: {len(train_dataloader)}\")\n",
    "print(f\"Dataset size: {len(train_dataloader.dataset)}\")\n",
    "print(f\"Number of classes: {dataset.num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['convnext-base_32xb128-noema_in1k', 'convnext-base_32xb128_in1k', 'convnext-base_3rdparty-noema_in1k', 'convnext-base_3rdparty_in1k', 'convnext-base_3rdparty_in1k-384px', 'convnext-base_3rdparty_in21k', 'convnext-base_in21k-pre-3rdparty_in1k-384px', 'convnext-base_in21k-pre_3rdparty_in1k', 'convnext-large_3rdparty_in1k', 'convnext-large_3rdparty_in1k-384px', 'convnext-large_3rdparty_in21k', 'convnext-large_in21k-pre-3rdparty_in1k-384px', 'convnext-large_in21k-pre_3rdparty_in1k', 'convnext-small_32xb128-noema_in1k', 'convnext-small_32xb128_in1k', 'convnext-small_in21k-pre_3rdparty_in1k', 'convnext-small_in21k-pre_3rdparty_in1k-384px', 'convnext-tiny_32xb128-noema_in1k', 'convnext-tiny_32xb128_in1k', 'convnext-tiny_in21k-pre_3rdparty_in1k', 'convnext-tiny_in21k-pre_3rdparty_in1k-384px', 'convnext-v2-atto_3rdparty-fcmae_in1k', 'convnext-v2-atto_fcmae-pre_3rdparty_in1k', 'convnext-v2-base_3rdparty-fcmae_in1k', 'convnext-v2-base_fcmae-in21k-pre_3rdparty_in1k', 'convnext-v2-base_fcmae-in21k-pre_3rdparty_in1k-384px', 'convnext-v2-base_fcmae-pre_3rdparty_in1k', 'convnext-v2-femto_3rdparty-fcmae_in1k', 'convnext-v2-femto_fcmae-pre_3rdparty_in1k', 'convnext-v2-huge_3rdparty-fcmae_in1k', 'convnext-v2-huge_fcmae-in21k-pre_3rdparty_in1k-384px', 'convnext-v2-huge_fcmae-in21k-pre_3rdparty_in1k-512px', 'convnext-v2-huge_fcmae-pre_3rdparty_in1k', 'convnext-v2-large_3rdparty-fcmae_in1k', 'convnext-v2-large_fcmae-in21k-pre_3rdparty_in1k', 'convnext-v2-large_fcmae-in21k-pre_3rdparty_in1k-384px', 'convnext-v2-large_fcmae-pre_3rdparty_in1k', 'convnext-v2-nano_3rdparty-fcmae_in1k', 'convnext-v2-nano_fcmae-in21k-pre_3rdparty_in1k', 'convnext-v2-nano_fcmae-in21k-pre_3rdparty_in1k-384px', 'convnext-v2-nano_fcmae-pre_3rdparty_in1k', 'convnext-v2-pico_3rdparty-fcmae_in1k', 'convnext-v2-pico_fcmae-pre_3rdparty_in1k', 'convnext-v2-tiny_3rdparty-fcmae_in1k', 'convnext-v2-tiny_fcmae-in21k-pre_3rdparty_in1k', 'convnext-v2-tiny_fcmae-in21k-pre_3rdparty_in1k-384px', 'convnext-v2-tiny_fcmae-pre_3rdparty_in1k', 'convnext-xlarge_3rdparty_in21k', 'convnext-xlarge_in21k-pre-3rdparty_in1k-384px', 'convnext-xlarge_in21k-pre_3rdparty_in1k', 'convnextv2-tiny_spark-pre_300e_in1k']\n"
     ]
    }
   ],
   "source": [
    "from otx.v2.adapters.torch.mmengine.mmpretrain import list_models\n",
    "models = list_models(\"convnext*\")\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with convnext-base_32xb128_in1k from mmpretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/18 18:05:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Because batch augmentations are enabled, the data preprocessor automatically enables the `to_onehot` option to generate one-hot format labels.\n",
      "ImageClassifier(\n",
      "  (data_preprocessor): ClsDataPreprocessor()\n",
      "  (backbone): ConvNeXt(\n",
      "    (downsample_layers): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
      "        (1): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)\n",
      "        (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "      )\n",
      "    )\n",
      "    (stages): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): ConvNeXtBlock(\n",
      "          (depthwise_conv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
      "          (norm): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)\n",
      "          (pointwise_conv1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pointwise_conv2): Linear(in_features=512, out_features=128, bias=True)\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): ConvNeXtBlock(\n",
      "          (depthwise_conv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
      "          (norm): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)\n",
      "          (pointwise_conv1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pointwise_conv2): Linear(in_features=512, out_features=128, bias=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "        (2): ConvNeXtBlock(\n",
      "          (depthwise_conv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
      "          (norm): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)\n",
      "          (pointwise_conv1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pointwise_conv2): Linear(in_features=512, out_features=128, bias=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): ConvNeXtBlock(\n",
      "          (depthwise_conv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
      "          (norm): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)\n",
      "          (pointwise_conv1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pointwise_conv2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "        (1): ConvNeXtBlock(\n",
      "          (depthwise_conv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
      "          (norm): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)\n",
      "          (pointwise_conv1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pointwise_conv2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "        (2): ConvNeXtBlock(\n",
      "          (depthwise_conv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
      "          (norm): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)\n",
      "          (pointwise_conv1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pointwise_conv2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): ConvNeXtBlock(\n",
      "          (depthwise_conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "          (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (pointwise_conv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pointwise_conv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "        (1): ConvNeXtBlock(\n",
      "          (depthwise_conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "          (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (pointwise_conv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pointwise_conv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "        (2): ConvNeXtBlock(\n",
      "          (depthwise_conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "          (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (pointwise_conv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pointwise_conv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "        (3): ConvNeXtBlock(\n",
      "          (depthwise_conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "          (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (pointwise_conv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pointwise_conv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "        (4): ConvNeXtBlock(\n",
      "          (depthwise_conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "          (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (pointwise_conv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pointwise_conv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "        (5): ConvNeXtBlock(\n",
      "          (depthwise_conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "          (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (pointwise_conv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pointwise_conv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "        (6): ConvNeXtBlock(\n",
      "          (depthwise_conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "          (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (pointwise_conv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pointwise_conv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "        (7): ConvNeXtBlock(\n",
      "          (depthwise_conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "          (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (pointwise_conv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pointwise_conv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "        (8): ConvNeXtBlock(\n",
      "          (depthwise_conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "          (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (pointwise_conv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pointwise_conv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "        (9): ConvNeXtBlock(\n",
      "          (depthwise_conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "          (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (pointwise_conv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pointwise_conv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "        (10): ConvNeXtBlock(\n",
      "          (depthwise_conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "          (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (pointwise_conv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pointwise_conv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "        (11): ConvNeXtBlock(\n",
      "          (depthwise_conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "          (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (pointwise_conv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pointwise_conv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "        (12): ConvNeXtBlock(\n",
      "          (depthwise_conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "          (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (pointwise_conv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pointwise_conv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "        (13): ConvNeXtBlock(\n",
      "          (depthwise_conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "          (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (pointwise_conv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pointwise_conv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "        (14): ConvNeXtBlock(\n",
      "          (depthwise_conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "          (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (pointwise_conv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pointwise_conv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "        (15): ConvNeXtBlock(\n",
      "          (depthwise_conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "          (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (pointwise_conv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pointwise_conv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "        (16): ConvNeXtBlock(\n",
      "          (depthwise_conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "          (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (pointwise_conv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pointwise_conv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "        (17): ConvNeXtBlock(\n",
      "          (depthwise_conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "          (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (pointwise_conv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pointwise_conv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "        (18): ConvNeXtBlock(\n",
      "          (depthwise_conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "          (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (pointwise_conv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pointwise_conv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "        (19): ConvNeXtBlock(\n",
      "          (depthwise_conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "          (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (pointwise_conv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pointwise_conv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "        (20): ConvNeXtBlock(\n",
      "          (depthwise_conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "          (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (pointwise_conv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pointwise_conv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "        (21): ConvNeXtBlock(\n",
      "          (depthwise_conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "          (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (pointwise_conv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pointwise_conv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "        (22): ConvNeXtBlock(\n",
      "          (depthwise_conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "          (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (pointwise_conv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pointwise_conv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "        (23): ConvNeXtBlock(\n",
      "          (depthwise_conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "          (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (pointwise_conv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pointwise_conv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "        (24): ConvNeXtBlock(\n",
      "          (depthwise_conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "          (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (pointwise_conv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pointwise_conv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "        (25): ConvNeXtBlock(\n",
      "          (depthwise_conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "          (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (pointwise_conv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pointwise_conv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "        (26): ConvNeXtBlock(\n",
      "          (depthwise_conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "          (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (pointwise_conv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pointwise_conv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): ConvNeXtBlock(\n",
      "          (depthwise_conv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
      "          (norm): LayerNorm2d((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (pointwise_conv1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pointwise_conv2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "        (1): ConvNeXtBlock(\n",
      "          (depthwise_conv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
      "          (norm): LayerNorm2d((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (pointwise_conv1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pointwise_conv2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "        (2): ConvNeXtBlock(\n",
      "          (depthwise_conv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
      "          (norm): LayerNorm2d((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (pointwise_conv1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pointwise_conv2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop_path): DropPath()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm3): LayerNorm2d((1024,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  init_cfg=[{'type': 'TruncNormal', 'layer': ['Conv2d', 'Linear'], 'std': 0.02, 'bias': 0.0}, {'type': 'Constant', 'layer': ['LayerNorm'], 'val': 1.0, 'bias': 0.0}]\n",
      "  (head): LinearClsHead(\n",
      "    (loss_module): LabelSmoothLoss(\n",
      "      (ce): CrossEntropyLoss()\n",
      "    )\n",
      "    (fc): Linear(in_features=1024, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "init_cfg={'type': 'TruncNormal', 'layer': ['Conv2d', 'Linear'], 'std': 0.02, 'bias': 0.0}\n"
     ]
    }
   ],
   "source": [
    "from otx.v2.adapters.torch.mmengine.mmpretrain import get_model\n",
    "model = get_model(\n",
    "    model=\"convnext-base_32xb128_in1k\",\n",
    "    num_classes=dataset.num_classes\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/18 18:06:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.9.13 (main, Aug 25 2022, 23:26:10) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    numpy_random_seed: 136858950\n",
      "    GPU 0,1: NVIDIA GeForce RTX 3090\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 11.7, V11.7.64\n",
      "    GCC: gcc (Ubuntu 9.5.0-1ubuntu1~22.04) 9.5.0\n",
      "    PyTorch: 1.13.1+cu117\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.7\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.5\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.14.1+cu117\n",
      "    OpenCV: 4.8.0\n",
      "    MMEngine: 0.8.4\n",
      "\n",
      "Runtime environment:\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 136858950\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "08/18 18:06:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "08/18 18:06:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "2023-08-18 18:06:01,215 | WARNING : The config used in the build isstored as an object in the configurationfile because the object doesn't have it.This can result in a non-reusable configs.py.\n",
      "08/18 18:06:01 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "08/18 18:06:01 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "08/18 18:06:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /tmp/otx-test.\n",
      "08/18 18:06:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: otx_train_20230818_180600\n",
      "08/18 18:06:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][5/5]  lr: 1.0000e-02  eta: 0:00:01  time: 0.2162  data_time: 0.0012  memory: 1455  loss: 7.2135\n",
      "08/18 18:06:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "08/18 18:06:02 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - `save_param_scheduler` is True but `self.param_schedulers` is None, so skip saving parameter schedulers\n",
      "08/18 18:06:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: otx_train_20230818_180600\n",
      "08/18 18:06:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [2][5/5]  lr: 1.0000e-02  eta: 0:00:00  time: 0.1263  data_time: 0.0012  memory: 1453  loss: 8.6819\n",
      "08/18 18:06:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 2 epochs\n",
      "/tmp/otx-test/best_accuracy_top1_epoch_3.pth\n"
     ]
    }
   ],
   "source": [
    "from otx.v2.adapters.torch.mmengine.mmpretrain.engine import MMPTEngine\n",
    "\n",
    "# OTX Model Training\n",
    "engine = MMPTEngine(work_dir=\"/tmp/otx-test\",)\n",
    "\n",
    "# Training without validation\n",
    "results = engine.train(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    max_epochs=2,\n",
    ")\n",
    "\n",
    "print(results[\"checkpoint\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with Hugging-Face Model from mmpretrain (microsoft/resnet-50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to install huggingface\n",
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HuggingFaceClassifier(\n",
      "  (data_preprocessor): ClsDataPreprocessor()\n",
      "  (model): ResNetForImageClassification(\n",
      "    (resnet): ResNetModel(\n",
      "      (embedder): ResNetEmbeddings(\n",
      "        (embedder): ResNetConvLayer(\n",
      "          (convolution): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "          (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (pooler): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (encoder): ResNetEncoder(\n",
      "        (stages): ModuleList(\n",
      "          (0): ResNetStage(\n",
      "            (layers): Sequential(\n",
      "              (0): ResNetBottleNeckLayer(\n",
      "                (shortcut): ResNetShortCut(\n",
      "                  (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "                (layer): Sequential(\n",
      "                  (0): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (1): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (2): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): Identity()\n",
      "                  )\n",
      "                )\n",
      "                (activation): ReLU()\n",
      "              )\n",
      "              (1): ResNetBottleNeckLayer(\n",
      "                (shortcut): Identity()\n",
      "                (layer): Sequential(\n",
      "                  (0): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (1): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (2): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): Identity()\n",
      "                  )\n",
      "                )\n",
      "                (activation): ReLU()\n",
      "              )\n",
      "              (2): ResNetBottleNeckLayer(\n",
      "                (shortcut): Identity()\n",
      "                (layer): Sequential(\n",
      "                  (0): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (1): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (2): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): Identity()\n",
      "                  )\n",
      "                )\n",
      "                (activation): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): ResNetStage(\n",
      "            (layers): Sequential(\n",
      "              (0): ResNetBottleNeckLayer(\n",
      "                (shortcut): ResNetShortCut(\n",
      "                  (convolution): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "                (layer): Sequential(\n",
      "                  (0): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (1): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (2): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): Identity()\n",
      "                  )\n",
      "                )\n",
      "                (activation): ReLU()\n",
      "              )\n",
      "              (1): ResNetBottleNeckLayer(\n",
      "                (shortcut): Identity()\n",
      "                (layer): Sequential(\n",
      "                  (0): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (1): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (2): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): Identity()\n",
      "                  )\n",
      "                )\n",
      "                (activation): ReLU()\n",
      "              )\n",
      "              (2): ResNetBottleNeckLayer(\n",
      "                (shortcut): Identity()\n",
      "                (layer): Sequential(\n",
      "                  (0): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (1): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (2): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): Identity()\n",
      "                  )\n",
      "                )\n",
      "                (activation): ReLU()\n",
      "              )\n",
      "              (3): ResNetBottleNeckLayer(\n",
      "                (shortcut): Identity()\n",
      "                (layer): Sequential(\n",
      "                  (0): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (1): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (2): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): Identity()\n",
      "                  )\n",
      "                )\n",
      "                (activation): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (2): ResNetStage(\n",
      "            (layers): Sequential(\n",
      "              (0): ResNetBottleNeckLayer(\n",
      "                (shortcut): ResNetShortCut(\n",
      "                  (convolution): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "                (layer): Sequential(\n",
      "                  (0): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (1): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (2): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): Identity()\n",
      "                  )\n",
      "                )\n",
      "                (activation): ReLU()\n",
      "              )\n",
      "              (1): ResNetBottleNeckLayer(\n",
      "                (shortcut): Identity()\n",
      "                (layer): Sequential(\n",
      "                  (0): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (1): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (2): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): Identity()\n",
      "                  )\n",
      "                )\n",
      "                (activation): ReLU()\n",
      "              )\n",
      "              (2): ResNetBottleNeckLayer(\n",
      "                (shortcut): Identity()\n",
      "                (layer): Sequential(\n",
      "                  (0): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (1): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (2): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): Identity()\n",
      "                  )\n",
      "                )\n",
      "                (activation): ReLU()\n",
      "              )\n",
      "              (3): ResNetBottleNeckLayer(\n",
      "                (shortcut): Identity()\n",
      "                (layer): Sequential(\n",
      "                  (0): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (1): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (2): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): Identity()\n",
      "                  )\n",
      "                )\n",
      "                (activation): ReLU()\n",
      "              )\n",
      "              (4): ResNetBottleNeckLayer(\n",
      "                (shortcut): Identity()\n",
      "                (layer): Sequential(\n",
      "                  (0): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (1): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (2): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): Identity()\n",
      "                  )\n",
      "                )\n",
      "                (activation): ReLU()\n",
      "              )\n",
      "              (5): ResNetBottleNeckLayer(\n",
      "                (shortcut): Identity()\n",
      "                (layer): Sequential(\n",
      "                  (0): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (1): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (2): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): Identity()\n",
      "                  )\n",
      "                )\n",
      "                (activation): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (3): ResNetStage(\n",
      "            (layers): Sequential(\n",
      "              (0): ResNetBottleNeckLayer(\n",
      "                (shortcut): ResNetShortCut(\n",
      "                  (convolution): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "                  (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "                (layer): Sequential(\n",
      "                  (0): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (1): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (2): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): Identity()\n",
      "                  )\n",
      "                )\n",
      "                (activation): ReLU()\n",
      "              )\n",
      "              (1): ResNetBottleNeckLayer(\n",
      "                (shortcut): Identity()\n",
      "                (layer): Sequential(\n",
      "                  (0): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (1): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (2): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): Identity()\n",
      "                  )\n",
      "                )\n",
      "                (activation): ReLU()\n",
      "              )\n",
      "              (2): ResNetBottleNeckLayer(\n",
      "                (shortcut): Identity()\n",
      "                (layer): Sequential(\n",
      "                  (0): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (1): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (2): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): Identity()\n",
      "                  )\n",
      "                )\n",
      "                (activation): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    )\n",
      "    (classifier): Sequential(\n",
      "      (0): Flatten(start_dim=1, end_dim=-1)\n",
      "      (1): Linear(in_features=2048, out_features=1000, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (loss_module): CrossEntropyLoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from otx.v2.adapters.torch.mmengine.mmpretrain import get_model\n",
    "cfg = dict(type='HuggingFaceClassifier', model_name='microsoft/resnet-50', pretrained=True)\n",
    "\n",
    "hf_model = get_model(cfg)\n",
    "print(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/18 18:06:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.9.13 (main, Aug 25 2022, 23:26:10) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    numpy_random_seed: 1216755606\n",
      "    GPU 0,1: NVIDIA GeForce RTX 3090\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 11.7, V11.7.64\n",
      "    GCC: gcc (Ubuntu 9.5.0-1ubuntu1~22.04) 9.5.0\n",
      "    PyTorch: 1.13.1+cu117\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.7\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.5\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.14.1+cu117\n",
      "    OpenCV: 4.8.0\n",
      "    MMEngine: 0.8.4\n",
      "\n",
      "Runtime environment:\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 1216755606\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "08/18 18:06:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "08/18 18:06:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "2023-08-18 18:06:05,874 | WARNING : The config used in the build isstored as an object in the configurationfile because the object doesn't have it.This can result in a non-reusable configs.py.\n",
      "08/18 18:06:05 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "08/18 18:06:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /tmp/otx-test.\n",
      "08/18 18:06:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: otx_train_20230818_180605\n",
      "08/18 18:06:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][5/5]  lr: 1.0000e-02  eta: 0:00:00  time: 0.0362  data_time: 0.0009  memory: 1445  loss: 7.8773\n",
      "08/18 18:06:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "08/18 18:06:06 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - `save_param_scheduler` is True but `self.param_schedulers` is None, so skip saving parameter schedulers\n",
      "08/18 18:06:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: otx_train_20230818_180605\n",
      "08/18 18:06:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [2][5/5]  lr: 1.0000e-02  eta: 0:00:00  time: 0.0285  data_time: 0.0009  memory: 1554  loss: 7.8545\n",
      "08/18 18:06:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 2 epochs\n",
      "/tmp/otx-test/best_accuracy_top1_epoch_3.pth\n"
     ]
    }
   ],
   "source": [
    "from otx.v2.adapters.torch.mmengine.mmpretrain.engine import MMPTEngine\n",
    "\n",
    "# OTX Model Training\n",
    "engine = MMPTEngine(work_dir=\"/tmp/otx-test\",)\n",
    "\n",
    "# Training without validation\n",
    "results = engine.train(\n",
    "    model=hf_model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    max_epochs=2,\n",
    ")\n",
    "\n",
    "print(results[\"checkpoint\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timm Model from mmpretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimmClassifier(\n",
      "  (data_preprocessor): ClsDataPreprocessor()\n",
      "  (model): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act1): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
      "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      "  )\n",
      "  (loss_module): CrossEntropyLoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from otx.v2.adapters.torch.mmengine.mmpretrain import get_model\n",
    "cfg = dict(type='TimmClassifier', model_name='resnet50', pretrained=True)\n",
    "\n",
    "timm_model = get_model(cfg)\n",
    "print(timm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/18 18:06:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.9.13 (main, Aug 25 2022, 23:26:10) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    numpy_random_seed: 286981800\n",
      "    GPU 0,1: NVIDIA GeForce RTX 3090\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 11.7, V11.7.64\n",
      "    GCC: gcc (Ubuntu 9.5.0-1ubuntu1~22.04) 9.5.0\n",
      "    PyTorch: 1.13.1+cu117\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.7\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.5\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.14.1+cu117\n",
      "    OpenCV: 4.8.0\n",
      "    MMEngine: 0.8.4\n",
      "\n",
      "Runtime environment:\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 286981800\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "08/18 18:06:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "08/18 18:06:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "2023-08-18 18:06:07,213 | WARNING : The config used in the build isstored as an object in the configurationfile because the object doesn't have it.This can result in a non-reusable configs.py.\n",
      "08/18 18:06:07 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "08/18 18:06:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /tmp/otx-test.\n",
      "08/18 18:06:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: otx_train_20230818_180607\n",
      "08/18 18:06:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][5/5]  lr: 1.0000e-02  eta: 0:00:00  time: 0.0194  data_time: 0.0009  memory: 1747  loss: 15.3594\n",
      "08/18 18:06:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "08/18 18:06:07 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - `save_param_scheduler` is True but `self.param_schedulers` is None, so skip saving parameter schedulers\n",
      "08/18 18:06:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: otx_train_20230818_180607\n",
      "08/18 18:06:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [2][5/5]  lr: 1.0000e-02  eta: 0:00:00  time: 0.0209  data_time: 0.0009  memory: 1845  loss: 13.9121\n",
      "08/18 18:06:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 2 epochs\n",
      "/tmp/otx-test/best_accuracy_top1_epoch_3.pth\n"
     ]
    }
   ],
   "source": [
    "from otx.v2.adapters.torch.mmengine.mmpretrain.engine import MMPTEngine\n",
    "\n",
    "# OTX Model Training\n",
    "engine = MMPTEngine(work_dir=\"/tmp/otx-test\",)\n",
    "\n",
    "# Training without validation\n",
    "results = engine.train(\n",
    "    model=timm_model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    max_epochs=2,\n",
    ")\n",
    "\n",
    "print(results[\"checkpoint\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vision-Transformer (MobileViT) from mmpretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cn-clip_vit-base-p16_zeroshot-cls_cifar100', 'cn-clip_vit-huge-p14_zeroshot-cls_cifar100', 'cn-clip_vit-large-p14_zeroshot-cls_cifar100', 'davit-base_3rdparty_in1k', 'davit-small_3rdparty_in1k', 'davit-tiny_3rdparty_in1k', 'eva-mae-style_vit-base-p16_16xb256-coslr-400e_in1k', 'hivit-base-p16_16xb64_in1k', 'hivit-small-p16_16xb64_in1k', 'hivit-tiny-p16_16xb64_in1k', 'itpn-clip-b_hivit-base-p16_8xb256-amp-coslr-800e_in1k', 'itpn-pixel_hivit-base-p16_8xb512-amp-coslr-800e_in1k', 'itpn-pixel_hivit-large-p16_8xb512-amp-coslr-800e_in1k', 'levit-128_3rdparty_in1k', 'levit-128s_3rdparty_in1k', 'levit-192_3rdparty_in1k', 'levit-256_3rdparty_in1k', 'levit-384_3rdparty_in1k', 'mae_vit-base-p16_8xb512-amp-coslr-1600e_in1k', 'mae_vit-base-p16_8xb512-amp-coslr-300e_in1k', 'mae_vit-base-p16_8xb512-amp-coslr-400e_in1k', 'mae_vit-base-p16_8xb512-amp-coslr-800e_in1k', 'mae_vit-huge-p16_8xb512-amp-coslr-1600e_in1k', 'mae_vit-large-p16_8xb512-amp-coslr-1600e_in1k', 'mae_vit-large-p16_8xb512-amp-coslr-400e_in1k', 'mae_vit-large-p16_8xb512-amp-coslr-800e_in1k', 'maskfeat_vit-base-p16_8xb256-amp-coslr-300e_in1k', 'milan_vit-base-p16_16xb256-amp-coslr-400e_in1k', 'mobilevit-small_3rdparty_in1k', 'mobilevit-xsmall_3rdparty_in1k', 'mobilevit-xxsmall_3rdparty_in1k', 'mocov3_vit-base-p16_16xb256-amp-coslr-300e_in1k', 'mocov3_vit-large-p16_64xb64-amp-coslr-300e_in1k', 'mocov3_vit-small-p16_16xb256-amp-coslr-300e_in1k', 'mvitv2-base_3rdparty_in1k', 'mvitv2-large_3rdparty_in1k', 'mvitv2-small_3rdparty_in1k', 'mvitv2-tiny_3rdparty_in1k', 'revvit-base_3rdparty_in1k', 'revvit-small_3rdparty_in1k', 't2t-vit-t-14_8xb64_in1k', 't2t-vit-t-19_8xb64_in1k', 't2t-vit-t-24_8xb64_in1k', 'tinyvit-11m_3rdparty_in1k', 'tinyvit-11m_in21k-distill-pre_3rdparty_in1k', 'tinyvit-21m_3rdparty_in1k', 'tinyvit-21m_in21k-distill-pre_3rdparty_in1k', 'tinyvit-21m_in21k-distill-pre_3rdparty_in1k-384px', 'tinyvit-21m_in21k-distill-pre_3rdparty_in1k-512px', 'tinyvit-5m_3rdparty_in1k', 'tinyvit-5m_in21k-distill-pre_3rdparty_in1k', 'vit-base-p14_dinov2-pre_3rdparty', 'vit-base-p14_eva02-in21k-pre_3rdparty_in1k-448px', 'vit-base-p14_eva02-in21k-pre_in21k-medft_3rdparty_in1k-448px', 'vit-base-p14_eva02-pre_in21k', 'vit-base-p16_32xb128-mae_in1k', 'vit-base-p16_clip-laion2b-in12k-pre_3rdparty_in1k', 'vit-base-p16_clip-laion2b-in12k-pre_3rdparty_in1k-384px', 'vit-base-p16_clip-laion2b-pre_3rdparty_in1k', 'vit-base-p16_clip-laion2b-pre_3rdparty_in1k-384px', 'vit-base-p16_clip-openai-in12k-pre_3rdparty_in1k', 'vit-base-p16_clip-openai-in12k-pre_3rdparty_in1k-384px', 'vit-base-p16_clip-openai-pre_3rdparty_in1k', 'vit-base-p16_clip-openai-pre_3rdparty_in1k-384px', 'vit-base-p16_eva-mae-style-pre_8xb128-coslr-100e_in1k', 'vit-base-p16_eva-mae-style-pre_8xb2048-linear-coslr-100e_in1k', 'vit-base-p16_in21k-pre_3rdparty_in1k-384px', 'vit-base-p16_mae-1600e-pre_8xb128-coslr-100e_in1k', 'vit-base-p16_mae-1600e-pre_8xb2048-linear-coslr-90e_in1k', 'vit-base-p16_mae-300e-pre_8xb128-coslr-100e_in1k', 'vit-base-p16_mae-300e-pre_8xb2048-linear-coslr-90e_in1k', 'vit-base-p16_mae-400e-pre_8xb128-coslr-100e_in1k', 'vit-base-p16_mae-400e-pre_8xb2048-linear-coslr-90e_in1k', 'vit-base-p16_mae-800e-pre_8xb128-coslr-100e_in1k', 'vit-base-p16_mae-800e-pre_8xb2048-linear-coslr-90e_in1k', 'vit-base-p16_maskfeat-pre_8xb256-coslr-100e_in1k', 'vit-base-p16_milan-pre_8xb128-coslr-100e_in1k', 'vit-base-p16_milan-pre_8xb2048-linear-coslr-100e_in1k', 'vit-base-p16_mocov3-pre_8xb128-linear-coslr-90e_in1k', 'vit-base-p16_mocov3-pre_8xb64-coslr-150e_in1k', 'vit-base-p16_sam-pre_3rdparty_sa1b-1024px', 'vit-base-p32_clip-laion2b-in12k-pre_3rdparty_in1k', 'vit-base-p32_clip-laion2b-in12k-pre_3rdparty_in1k-384px', 'vit-base-p32_clip-laion2b-in12k-pre_3rdparty_in1k-448px', 'vit-base-p32_clip-laion2b-pre_3rdparty_in1k', 'vit-base-p32_clip-openai-in12k-pre_3rdparty_in1k-384px', 'vit-base-p32_clip-openai-pre_3rdparty_in1k', 'vit-base-p32_in21k-pre_3rdparty_in1k-384px', 'vit-giant-p14_dinov2-pre_3rdparty', 'vit-huge-p14_mae-1600e-pre_32xb8-coslr-50e_in1k-448px', 'vit-huge-p14_mae-1600e-pre_8xb128-coslr-50e_in1k', 'vit-huge-p16_sam-pre_3rdparty_sa1b-1024px', 'vit-large-p14_clip-openai-pre_3rdparty', 'vit-large-p14_dinov2-pre_3rdparty', 'vit-large-p14_eva02-in21k-pre_in21k-medft_3rdparty_in1k-448px', 'vit-large-p14_eva02-pre_in21k', 'vit-large-p14_eva02-pre_m38m', 'vit-large-p14_eva02_m38m-pre_in21k-medft_3rdparty_in1k-448px', 'vit-large-p16_in21k-pre_3rdparty_in1k-384px', 'vit-large-p16_mae-1600e-pre_8xb128-coslr-50e_in1k', 'vit-large-p16_mae-1600e-pre_8xb2048-linear-coslr-90e_in1k', 'vit-large-p16_mae-400e-pre_8xb128-coslr-50e_in1k', 'vit-large-p16_mae-400e-pre_8xb2048-linear-coslr-90e_in1k', 'vit-large-p16_mae-800e-pre_8xb128-coslr-50e_in1k', 'vit-large-p16_mae-800e-pre_8xb2048-linear-coslr-90e_in1k', 'vit-large-p16_mocov3-pre_8xb64-coslr-100e_in1k', 'vit-large-p16_sam-pre_3rdparty_sa1b-1024px', 'vit-small-p14_dinov2-pre_3rdparty', 'vit-small-p14_eva02-in21k-pre_3rdparty_in1k-336px', 'vit-small-p14_eva02-pre_in21k', 'vit-small-p16_mocov3-pre_8xb128-linear-coslr-90e_in1k', 'vit-tiny-p14_eva02-in21k-pre_3rdparty_in1k-336px', 'vit-tiny-p14_eva02-pre_in21k']\n"
     ]
    }
   ],
   "source": [
    "from otx.v2.adapters.torch.mmengine.mmpretrain import list_models\n",
    "models = list_models(\"*vit*\")\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageClassifier(\n",
      "  (data_preprocessor): ClsDataPreprocessor()\n",
      "  (backbone): MobileViT(\n",
      "    (stem): ConvModule(\n",
      "      (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activate): Swish()\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv): Sequential(\n",
      "            (0): ConvModule(\n",
      "              (conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (1): ConvModule(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (2): ConvModule(\n",
      "              (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv): Sequential(\n",
      "            (0): ConvModule(\n",
      "              (conv): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (1): ConvModule(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (2): ConvModule(\n",
      "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (conv): Sequential(\n",
      "            (0): ConvModule(\n",
      "              (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (1): ConvModule(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (2): ConvModule(\n",
      "              (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): InvertedResidual(\n",
      "          (conv): Sequential(\n",
      "            (0): ConvModule(\n",
      "              (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (1): ConvModule(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (2): ConvModule(\n",
      "              (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv): Sequential(\n",
      "            (0): ConvModule(\n",
      "              (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (1): ConvModule(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (2): ConvModule(\n",
      "              (conv): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): MobileVitBlock(\n",
      "          (local_rep): Sequential(\n",
      "            (0): ConvModule(\n",
      "              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (1): ConvModule(\n",
      "              (conv): Conv2d(96, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            )\n",
      "          )\n",
      "          (global_rep): Sequential(\n",
      "            (0): TransformerEncoderLayer(\n",
      "              (ln1): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): MultiheadAttention(\n",
      "                (qkv): Linear(in_features=144, out_features=432, bias=True)\n",
      "                (proj): Linear(in_features=144, out_features=144, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (out_drop): DropPath()\n",
      "                (gamma1): Identity()\n",
      "              )\n",
      "              (ln2): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
      "              (ffn): FFN(\n",
      "                (layers): Sequential(\n",
      "                  (0): Sequential(\n",
      "                    (0): Linear(in_features=144, out_features=288, bias=True)\n",
      "                    (1): Swish()\n",
      "                    (2): Dropout(p=0.0, inplace=False)\n",
      "                  )\n",
      "                  (1): Linear(in_features=288, out_features=144, bias=True)\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (dropout_layer): DropPath()\n",
      "                (gamma2): Identity()\n",
      "              )\n",
      "            )\n",
      "            (1): TransformerEncoderLayer(\n",
      "              (ln1): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): MultiheadAttention(\n",
      "                (qkv): Linear(in_features=144, out_features=432, bias=True)\n",
      "                (proj): Linear(in_features=144, out_features=144, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (out_drop): DropPath()\n",
      "                (gamma1): Identity()\n",
      "              )\n",
      "              (ln2): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
      "              (ffn): FFN(\n",
      "                (layers): Sequential(\n",
      "                  (0): Sequential(\n",
      "                    (0): Linear(in_features=144, out_features=288, bias=True)\n",
      "                    (1): Swish()\n",
      "                    (2): Dropout(p=0.0, inplace=False)\n",
      "                  )\n",
      "                  (1): Linear(in_features=288, out_features=144, bias=True)\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (dropout_layer): DropPath()\n",
      "                (gamma2): Identity()\n",
      "              )\n",
      "            )\n",
      "            (2): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (conv_proj): ConvModule(\n",
      "            (conv): Conv2d(144, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (conv_fusion): ConvModule(\n",
      "            (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv): Sequential(\n",
      "            (0): ConvModule(\n",
      "              (conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (1): ConvModule(\n",
      "              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
      "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (2): ConvModule(\n",
      "              (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): MobileVitBlock(\n",
      "          (local_rep): Sequential(\n",
      "            (0): ConvModule(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (1): ConvModule(\n",
      "              (conv): Conv2d(128, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            )\n",
      "          )\n",
      "          (global_rep): Sequential(\n",
      "            (0): TransformerEncoderLayer(\n",
      "              (ln1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): MultiheadAttention(\n",
      "                (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "                (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (out_drop): DropPath()\n",
      "                (gamma1): Identity()\n",
      "              )\n",
      "              (ln2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "              (ffn): FFN(\n",
      "                (layers): Sequential(\n",
      "                  (0): Sequential(\n",
      "                    (0): Linear(in_features=192, out_features=384, bias=True)\n",
      "                    (1): Swish()\n",
      "                    (2): Dropout(p=0.0, inplace=False)\n",
      "                  )\n",
      "                  (1): Linear(in_features=384, out_features=192, bias=True)\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (dropout_layer): DropPath()\n",
      "                (gamma2): Identity()\n",
      "              )\n",
      "            )\n",
      "            (1): TransformerEncoderLayer(\n",
      "              (ln1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): MultiheadAttention(\n",
      "                (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "                (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (out_drop): DropPath()\n",
      "                (gamma1): Identity()\n",
      "              )\n",
      "              (ln2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "              (ffn): FFN(\n",
      "                (layers): Sequential(\n",
      "                  (0): Sequential(\n",
      "                    (0): Linear(in_features=192, out_features=384, bias=True)\n",
      "                    (1): Swish()\n",
      "                    (2): Dropout(p=0.0, inplace=False)\n",
      "                  )\n",
      "                  (1): Linear(in_features=384, out_features=192, bias=True)\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (dropout_layer): DropPath()\n",
      "                (gamma2): Identity()\n",
      "              )\n",
      "            )\n",
      "            (2): TransformerEncoderLayer(\n",
      "              (ln1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): MultiheadAttention(\n",
      "                (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "                (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (out_drop): DropPath()\n",
      "                (gamma1): Identity()\n",
      "              )\n",
      "              (ln2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "              (ffn): FFN(\n",
      "                (layers): Sequential(\n",
      "                  (0): Sequential(\n",
      "                    (0): Linear(in_features=192, out_features=384, bias=True)\n",
      "                    (1): Swish()\n",
      "                    (2): Dropout(p=0.0, inplace=False)\n",
      "                  )\n",
      "                  (1): Linear(in_features=384, out_features=192, bias=True)\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (dropout_layer): DropPath()\n",
      "                (gamma2): Identity()\n",
      "              )\n",
      "            )\n",
      "            (3): TransformerEncoderLayer(\n",
      "              (ln1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): MultiheadAttention(\n",
      "                (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "                (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (out_drop): DropPath()\n",
      "                (gamma1): Identity()\n",
      "              )\n",
      "              (ln2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "              (ffn): FFN(\n",
      "                (layers): Sequential(\n",
      "                  (0): Sequential(\n",
      "                    (0): Linear(in_features=192, out_features=384, bias=True)\n",
      "                    (1): Swish()\n",
      "                    (2): Dropout(p=0.0, inplace=False)\n",
      "                  )\n",
      "                  (1): Linear(in_features=384, out_features=192, bias=True)\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (dropout_layer): DropPath()\n",
      "                (gamma2): Identity()\n",
      "              )\n",
      "            )\n",
      "            (4): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (conv_proj): ConvModule(\n",
      "            (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (conv_fusion): ConvModule(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv): Sequential(\n",
      "            (0): ConvModule(\n",
      "              (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (1): ConvModule(\n",
      "              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)\n",
      "              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (2): ConvModule(\n",
      "              (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): MobileVitBlock(\n",
      "          (local_rep): Sequential(\n",
      "            (0): ConvModule(\n",
      "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): Swish()\n",
      "            )\n",
      "            (1): ConvModule(\n",
      "              (conv): Conv2d(160, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            )\n",
      "          )\n",
      "          (global_rep): Sequential(\n",
      "            (0): TransformerEncoderLayer(\n",
      "              (ln1): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): MultiheadAttention(\n",
      "                (qkv): Linear(in_features=240, out_features=720, bias=True)\n",
      "                (proj): Linear(in_features=240, out_features=240, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (out_drop): DropPath()\n",
      "                (gamma1): Identity()\n",
      "              )\n",
      "              (ln2): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
      "              (ffn): FFN(\n",
      "                (layers): Sequential(\n",
      "                  (0): Sequential(\n",
      "                    (0): Linear(in_features=240, out_features=480, bias=True)\n",
      "                    (1): Swish()\n",
      "                    (2): Dropout(p=0.0, inplace=False)\n",
      "                  )\n",
      "                  (1): Linear(in_features=480, out_features=240, bias=True)\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (dropout_layer): DropPath()\n",
      "                (gamma2): Identity()\n",
      "              )\n",
      "            )\n",
      "            (1): TransformerEncoderLayer(\n",
      "              (ln1): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): MultiheadAttention(\n",
      "                (qkv): Linear(in_features=240, out_features=720, bias=True)\n",
      "                (proj): Linear(in_features=240, out_features=240, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (out_drop): DropPath()\n",
      "                (gamma1): Identity()\n",
      "              )\n",
      "              (ln2): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
      "              (ffn): FFN(\n",
      "                (layers): Sequential(\n",
      "                  (0): Sequential(\n",
      "                    (0): Linear(in_features=240, out_features=480, bias=True)\n",
      "                    (1): Swish()\n",
      "                    (2): Dropout(p=0.0, inplace=False)\n",
      "                  )\n",
      "                  (1): Linear(in_features=480, out_features=240, bias=True)\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (dropout_layer): DropPath()\n",
      "                (gamma2): Identity()\n",
      "              )\n",
      "            )\n",
      "            (2): TransformerEncoderLayer(\n",
      "              (ln1): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): MultiheadAttention(\n",
      "                (qkv): Linear(in_features=240, out_features=720, bias=True)\n",
      "                (proj): Linear(in_features=240, out_features=240, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (out_drop): DropPath()\n",
      "                (gamma1): Identity()\n",
      "              )\n",
      "              (ln2): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
      "              (ffn): FFN(\n",
      "                (layers): Sequential(\n",
      "                  (0): Sequential(\n",
      "                    (0): Linear(in_features=240, out_features=480, bias=True)\n",
      "                    (1): Swish()\n",
      "                    (2): Dropout(p=0.0, inplace=False)\n",
      "                  )\n",
      "                  (1): Linear(in_features=480, out_features=240, bias=True)\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (dropout_layer): DropPath()\n",
      "                (gamma2): Identity()\n",
      "              )\n",
      "            )\n",
      "            (3): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (conv_proj): ConvModule(\n",
      "            (conv): Conv2d(240, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "          (conv_fusion): ConvModule(\n",
      "            (conv): Conv2d(320, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): Swish()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv_1x1_exp): ConvModule(\n",
      "      (conv): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activate): Swish()\n",
      "    )\n",
      "  )\n",
      "  init_cfg=[{'type': 'Kaiming', 'layer': ['Conv2d']}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]\n",
      "  (neck): GlobalAveragePooling(\n",
      "    (gap): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      "  (head): LinearClsHead(\n",
      "    (loss_module): CrossEntropyLoss()\n",
      "    (fc): Linear(in_features=640, out_features=1000, bias=True)\n",
      "  )\n",
      "  init_cfg={'type': 'Normal', 'layer': 'Linear', 'std': 0.01}\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from otx.v2.adapters.torch.mmengine.mmpretrain import get_model\n",
    "vit_model = get_model(model=\"mobilevit-small_3rdparty_in1k\")\n",
    "print(vit_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/18 18:06:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.9.13 (main, Aug 25 2022, 23:26:10) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    numpy_random_seed: 2073026823\n",
      "    GPU 0,1: NVIDIA GeForce RTX 3090\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 11.7, V11.7.64\n",
      "    GCC: gcc (Ubuntu 9.5.0-1ubuntu1~22.04) 9.5.0\n",
      "    PyTorch: 1.13.1+cu117\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.7\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.5\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.14.1+cu117\n",
      "    OpenCV: 4.8.0\n",
      "    MMEngine: 0.8.4\n",
      "\n",
      "Runtime environment:\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 2073026823\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "08/18 18:06:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "08/18 18:06:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "2023-08-18 18:06:08,408 | WARNING : The config used in the build isstored as an object in the configurationfile because the object doesn't have it.This can result in a non-reusable configs.py.\n",
      "08/18 18:06:08 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "08/18 18:06:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /tmp/otx-test.\n",
      "08/18 18:06:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: otx_train_20230818_180608\n",
      "08/18 18:06:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][5/5]  lr: 1.0000e-02  eta: 0:00:00  time: 0.0354  data_time: 0.0010  memory: 2005  loss: 6.9070\n",
      "08/18 18:06:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "08/18 18:06:08 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - `save_param_scheduler` is True but `self.param_schedulers` is None, so skip saving parameter schedulers\n",
      "08/18 18:06:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: otx_train_20230818_180608\n",
      "08/18 18:06:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [2][5/5]  lr: 1.0000e-02  eta: 0:00:00  time: 0.0315  data_time: 0.0010  memory: 2005  loss: 6.7061\n",
      "08/18 18:06:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 2 epochs\n",
      "/tmp/otx-test/best_accuracy_top1_epoch_3.pth\n"
     ]
    }
   ],
   "source": [
    "from otx.v2.adapters.torch.mmengine.mmpretrain.engine import MMPTEngine\n",
    "\n",
    "# OTX Model Training\n",
    "engine = MMPTEngine(work_dir=\"/tmp/otx-test\",)\n",
    "\n",
    "# Training without validation\n",
    "results = engine.train(\n",
    "    model=vit_model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    max_epochs=2,\n",
    ")\n",
    "\n",
    "print(results[\"checkpoint\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With AutoRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Detected dataset format: imagenet\n",
      "[*] Detected task type: CLASSIFICATION\n",
      "MobileViT:  ['mobilevit-small_3rdparty_in1k', 'mobilevit-xsmall_3rdparty_in1k', 'mobilevit-xxsmall_3rdparty_in1k']\n",
      "2023-08-18 18:06:09,138 | WARNING : Currently, OTX does not accept val_dataloader as a dict configuration.\n",
      "2023-08-18 18:06:09,138 | WARNING : Currently, OTX does not accept test_dataloader as a dict configuration.\n",
      "2023-08-18 18:06:09,138 | WARNING : In Engine.config, remove ['framework', 'data', 'optimizer', 'max_epochs', 'max_iters', 'val_interval', 'precision'] that are unavailable to the Runner.\n",
      "08/18 18:06:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.9.13 (main, Aug 25 2022, 23:26:10) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    numpy_random_seed: 1768351892\n",
      "    GPU 0,1: NVIDIA GeForce RTX 3090\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 11.7, V11.7.64\n",
      "    GCC: gcc (Ubuntu 9.5.0-1ubuntu1~22.04) 9.5.0\n",
      "    PyTorch: 1.13.1+cu117\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.7\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.5\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.14.1+cu117\n",
      "    OpenCV: 4.8.0\n",
      "    MMEngine: 0.8.4\n",
      "\n",
      "Runtime environment:\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 1768351892\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "08/18 18:06:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "08/18 18:06:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "2023-08-18 18:06:09,279 | WARNING : The config used in the build isstored as an object in the configurationfile because the object doesn't have it.This can result in a non-reusable configs.py.\n",
      "08/18 18:06:09 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "08/18 18:06:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /tmp/OTX-API-test.\n",
      "08/18 18:06:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: otx_train_20230818_180609\n",
      "08/18 18:06:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][5/5]  lr: 1.0000e-02  eta: 0:00:00  time: 0.0306  data_time: 0.0048  memory: 2231  loss: 6.8581\n",
      "08/18 18:06:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "08/18 18:06:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: otx_train_20230818_180609\n",
      "08/18 18:06:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [2][5/5]  lr: 5.0000e-03  eta: 0:00:00  time: 0.0292  data_time: 0.0047  memory: 2231  loss: 6.6105\n",
      "08/18 18:06:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 2 epochs\n",
      "/tmp/OTX-API-test/epoch_2.pth\n"
     ]
    }
   ],
   "source": [
    "from otx.v2.api.core import AutoRunner\n",
    "\n",
    "output_dir = \"/tmp/OTX-API-test\"\n",
    "data_roots = \"../../../../../demo/dataset/cifar10-small/train_data\"\n",
    "\n",
    "auto_engine = AutoRunner(\n",
    "    work_dir=output_dir,\n",
    "    train_data_roots=data_roots,\n",
    ")\n",
    "\n",
    "model_list = auto_engine.list_models(\"mobilevit\")\n",
    "print(\"MobileViT: \", model_list)\n",
    "\n",
    "# Customization training\n",
    "results = auto_engine.train(\n",
    "    model=\"mobilevit-small_3rdparty_in1k\",\n",
    "    batch_size=2,\n",
    "    max_epochs=2\n",
    ")\n",
    "print(results[\"checkpoint\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
