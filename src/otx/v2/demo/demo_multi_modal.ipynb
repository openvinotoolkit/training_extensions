{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Modality Inference\n",
    "- BLIP\n",
    "- BLIP-2\n",
    "- OFA\n",
    "- Flamingo (SKIP: Hugging-Face API)\n",
    "- Mini-GPT4 (SKIP: Hugging-Face API)\n",
    "- LLaVA (SKIP: Need to prepare multiple weights)\n",
    "- Otter (SKIP: Hugging-Face API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/repo/otx-main/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/harimkan/workspace/repo/otx-main/venv/lib/python3.9/site-packages/openvino/pyopenvino/__init__.py:10: FutureWarning: The module is private and following namespace `pyopenvino` will be removed in the future\n",
      "  warnings.warn(message=\"The module is private and following namespace \" \"`pyopenvino` will be removed in the future\", category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from otx.v2.adapters.torch.mmengine.mmpretrain.engine import MMPTEngine\n",
    "\n",
    "# Engine for demo\n",
    "engine  = MMPTEngine(\n",
    "    work_dir=\"/tmp/test-multi-modal-infer\",\n",
    ")\n",
    "\n",
    "# Sample for demo (single image)\n",
    "sample = \"../../../../tests/assets/car_tree_bug/images/train/Slide4.PNG\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLIP\n",
    "- https://github.com/open-mmlab/mmpretrain/tree/main/configs/blip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'BlipTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BlipCaption(\n",
      "  (data_preprocessor): MultiModalDataPreprocessor()\n",
      "  (visual_encoder): VisionTransformer(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (adaptive_padding): AdaptivePadding()\n",
      "      (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "    )\n",
      "    (drop_after_pos): Dropout(p=0.0, inplace=False)\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): MultiheadAttention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (out_drop): DropPath()\n",
      "          (gamma1): Identity()\n",
      "        )\n",
      "        (ln2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): MultiheadAttention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (out_drop): DropPath()\n",
      "          (gamma1): Identity()\n",
      "        )\n",
      "        (ln2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): TransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): MultiheadAttention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (out_drop): DropPath()\n",
      "          (gamma1): Identity()\n",
      "        )\n",
      "        (ln2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (3): TransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): MultiheadAttention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (out_drop): DropPath()\n",
      "          (gamma1): Identity()\n",
      "        )\n",
      "        (ln2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (4): TransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): MultiheadAttention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (out_drop): DropPath()\n",
      "          (gamma1): Identity()\n",
      "        )\n",
      "        (ln2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (5): TransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): MultiheadAttention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (out_drop): DropPath()\n",
      "          (gamma1): Identity()\n",
      "        )\n",
      "        (ln2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (6): TransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): MultiheadAttention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (out_drop): DropPath()\n",
      "          (gamma1): Identity()\n",
      "        )\n",
      "        (ln2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (7): TransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): MultiheadAttention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (out_drop): DropPath()\n",
      "          (gamma1): Identity()\n",
      "        )\n",
      "        (ln2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (8): TransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): MultiheadAttention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (out_drop): DropPath()\n",
      "          (gamma1): Identity()\n",
      "        )\n",
      "        (ln2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (9): TransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): MultiheadAttention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (out_drop): DropPath()\n",
      "          (gamma1): Identity()\n",
      "        )\n",
      "        (ln2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (10): TransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): MultiheadAttention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (out_drop): DropPath()\n",
      "          (gamma1): Identity()\n",
      "        )\n",
      "        (ln2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (11): TransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): MultiheadAttention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (out_drop): DropPath()\n",
      "          (gamma1): Identity()\n",
      "        )\n",
      "        (ln2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pre_norm): Identity()\n",
      "    (ln1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (seq_gen_head): SeqGenerationHead(\n",
      "    (decoder): XBertLMHeadDecoder(\n",
      "      (bert): BertModel(\n",
      "        (embeddings): BertEmbeddings(\n",
      "          (word_embeddings): Embedding(30524, 768, padding_idx=0)\n",
      "          (position_embeddings): Embedding(512, 768)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (encoder): BertEncoder(\n",
      "          (layer): ModuleList(\n",
      "            (0): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (crossattention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (1): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (crossattention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (2): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (crossattention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (3): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (crossattention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (4): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (crossattention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (5): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (crossattention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (6): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (crossattention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (7): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (crossattention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (8): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (crossattention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (9): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (crossattention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (10): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (crossattention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (11): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (crossattention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (cls): BertOnlyMLMHead(\n",
      "        (predictions): BertLMPredictionHead(\n",
      "          (transform): BertPredictionHeadTransform(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (transform_act_fn): GELUActivation()\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (decoder): Linear(in_features=768, out_features=30524, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (loss_fn): LabelSmoothLoss(\n",
      "      (ce): CrossEntropyLoss()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# BLIP\n",
    "from otx.v2.adapters.torch.mmengine.mmpretrain.model import get_model\n",
    "blip_model = get_model(\"blip-base_3rdparty_caption\")\n",
    "print(blip_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/harimkan/workspace/repo/otx-main/venv/lib/python3.9/site-packages/rich/live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/harimkan/workspace/repo/otx-main/venv/lib/python3.9/site-packages/rich/live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'pred_caption': 'oneself punched gardiner oneselfこ duration applications hunched licenses duration duration wat disappearance duration +こ'}]\n"
     ]
    }
   ],
   "source": [
    "pred_result = engine.predict(\n",
    "    model=blip_model,\n",
    "    img=sample\n",
    ")\n",
    "print(pred_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLIP-2\n",
    "- https://github.com/open-mmlab/mmpretrain/tree/main/configs/blip2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blip2Caption(\n",
      "  (data_preprocessor): MultiModalDataPreprocessor()\n",
      "  (vision_backbone): BEiTViT(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (adaptive_padding): AdaptivePadding()\n",
      "      (projection): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))\n",
      "    )\n",
      "    (drop_after_pos): Dropout(p=0, inplace=False)\n",
      "    (layers): ModuleList(\n",
      "      (0): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (1): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (2): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (3): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (4): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (5): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (6): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (7): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (8): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (9): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (10): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (11): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (12): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (13): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (14): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (15): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (16): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (17): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (18): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (19): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (20): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (21): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (22): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (23): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (24): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (25): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (26): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (27): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (28): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (29): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (30): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (31): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (32): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (33): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (34): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (35): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (36): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (37): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (38): BEiTTransformerEncoderLayer(\n",
      "        (ln1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): BEiTAttention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (1): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "          )\n",
      "          (dropout_layer): DropPath()\n",
      "          (gamma2): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (ln_vision_backbone): LayerNorm((1408,), eps=1e-05, elementwise_affine=True)\n",
      "  (vision_neck): LinearClsHead(\n",
      "    (loss_module): CrossEntropyLoss()\n",
      "    (fc): Linear(in_features=768, out_features=2560, bias=True)\n",
      "  )\n",
      "  init_cfg={'type': 'Normal', 'layer': 'Linear', 'std': 0.01}\n",
      "  (text_backbone): OPTForCausalLM(\n",
      "    (model): OPTModel(\n",
      "      (decoder): OPTDecoder(\n",
      "        (embed_tokens): Embedding(50272, 2560, padding_idx=1)\n",
      "        (embed_positions): OPTLearnedPositionalEmbedding(2050, 2560)\n",
      "        (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "        (layers): ModuleList(\n",
      "          (0): OPTDecoderLayer(\n",
      "            (self_attn): OPTAttention(\n",
      "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "            )\n",
      "            (activation_fn): ReLU()\n",
      "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
      "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
      "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (1): OPTDecoderLayer(\n",
      "            (self_attn): OPTAttention(\n",
      "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "            )\n",
      "            (activation_fn): ReLU()\n",
      "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
      "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
      "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (2): OPTDecoderLayer(\n",
      "            (self_attn): OPTAttention(\n",
      "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "            )\n",
      "            (activation_fn): ReLU()\n",
      "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
      "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
      "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (3): OPTDecoderLayer(\n",
      "            (self_attn): OPTAttention(\n",
      "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "            )\n",
      "            (activation_fn): ReLU()\n",
      "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
      "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
      "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (4): OPTDecoderLayer(\n",
      "            (self_attn): OPTAttention(\n",
      "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "            )\n",
      "            (activation_fn): ReLU()\n",
      "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
      "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
      "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (5): OPTDecoderLayer(\n",
      "            (self_attn): OPTAttention(\n",
      "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "            )\n",
      "            (activation_fn): ReLU()\n",
      "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
      "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
      "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (6): OPTDecoderLayer(\n",
      "            (self_attn): OPTAttention(\n",
      "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "            )\n",
      "            (activation_fn): ReLU()\n",
      "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
      "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
      "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (7): OPTDecoderLayer(\n",
      "            (self_attn): OPTAttention(\n",
      "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "            )\n",
      "            (activation_fn): ReLU()\n",
      "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
      "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
      "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (8): OPTDecoderLayer(\n",
      "            (self_attn): OPTAttention(\n",
      "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "            )\n",
      "            (activation_fn): ReLU()\n",
      "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
      "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
      "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (9): OPTDecoderLayer(\n",
      "            (self_attn): OPTAttention(\n",
      "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "            )\n",
      "            (activation_fn): ReLU()\n",
      "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
      "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
      "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (10): OPTDecoderLayer(\n",
      "            (self_attn): OPTAttention(\n",
      "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "            )\n",
      "            (activation_fn): ReLU()\n",
      "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
      "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
      "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (11): OPTDecoderLayer(\n",
      "            (self_attn): OPTAttention(\n",
      "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "            )\n",
      "            (activation_fn): ReLU()\n",
      "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
      "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
      "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (12): OPTDecoderLayer(\n",
      "            (self_attn): OPTAttention(\n",
      "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "            )\n",
      "            (activation_fn): ReLU()\n",
      "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
      "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
      "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (13): OPTDecoderLayer(\n",
      "            (self_attn): OPTAttention(\n",
      "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "            )\n",
      "            (activation_fn): ReLU()\n",
      "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
      "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
      "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (14): OPTDecoderLayer(\n",
      "            (self_attn): OPTAttention(\n",
      "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "            )\n",
      "            (activation_fn): ReLU()\n",
      "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
      "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
      "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (15): OPTDecoderLayer(\n",
      "            (self_attn): OPTAttention(\n",
      "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "            )\n",
      "            (activation_fn): ReLU()\n",
      "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
      "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
      "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (16): OPTDecoderLayer(\n",
      "            (self_attn): OPTAttention(\n",
      "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "            )\n",
      "            (activation_fn): ReLU()\n",
      "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
      "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
      "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (17): OPTDecoderLayer(\n",
      "            (self_attn): OPTAttention(\n",
      "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "            )\n",
      "            (activation_fn): ReLU()\n",
      "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
      "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
      "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (18): OPTDecoderLayer(\n",
      "            (self_attn): OPTAttention(\n",
      "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "            )\n",
      "            (activation_fn): ReLU()\n",
      "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
      "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
      "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (19): OPTDecoderLayer(\n",
      "            (self_attn): OPTAttention(\n",
      "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "            )\n",
      "            (activation_fn): ReLU()\n",
      "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
      "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
      "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (20): OPTDecoderLayer(\n",
      "            (self_attn): OPTAttention(\n",
      "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "            )\n",
      "            (activation_fn): ReLU()\n",
      "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
      "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
      "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (21): OPTDecoderLayer(\n",
      "            (self_attn): OPTAttention(\n",
      "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "            )\n",
      "            (activation_fn): ReLU()\n",
      "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
      "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
      "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (22): OPTDecoderLayer(\n",
      "            (self_attn): OPTAttention(\n",
      "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "            )\n",
      "            (activation_fn): ReLU()\n",
      "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
      "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
      "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (23): OPTDecoderLayer(\n",
      "            (self_attn): OPTAttention(\n",
      "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "            )\n",
      "            (activation_fn): ReLU()\n",
      "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
      "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
      "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (24): OPTDecoderLayer(\n",
      "            (self_attn): OPTAttention(\n",
      "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "            )\n",
      "            (activation_fn): ReLU()\n",
      "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
      "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
      "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (25): OPTDecoderLayer(\n",
      "            (self_attn): OPTAttention(\n",
      "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "            )\n",
      "            (activation_fn): ReLU()\n",
      "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
      "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
      "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (26): OPTDecoderLayer(\n",
      "            (self_attn): OPTAttention(\n",
      "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "            )\n",
      "            (activation_fn): ReLU()\n",
      "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
      "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
      "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (27): OPTDecoderLayer(\n",
      "            (self_attn): OPTAttention(\n",
      "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "            )\n",
      "            (activation_fn): ReLU()\n",
      "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
      "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
      "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (28): OPTDecoderLayer(\n",
      "            (self_attn): OPTAttention(\n",
      "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "            )\n",
      "            (activation_fn): ReLU()\n",
      "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
      "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
      "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (29): OPTDecoderLayer(\n",
      "            (self_attn): OPTAttention(\n",
      "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "            )\n",
      "            (activation_fn): ReLU()\n",
      "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
      "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
      "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (30): OPTDecoderLayer(\n",
      "            (self_attn): OPTAttention(\n",
      "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "            )\n",
      "            (activation_fn): ReLU()\n",
      "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
      "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
      "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (31): OPTDecoderLayer(\n",
      "            (self_attn): OPTAttention(\n",
      "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "            )\n",
      "            (activation_fn): ReLU()\n",
      "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
      "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
      "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (lm_head): Linear(in_features=2560, out_features=50272, bias=False)\n",
      "  )\n",
      "  (multimodal_backbone): Qformer(\n",
      "    (bert): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): None\n",
      "        (position_embeddings): None\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (crossattention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=1408, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=1408, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): None\n",
      "            (output): None\n",
      "            (intermediate_query): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output_query): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): None\n",
      "            (output): None\n",
      "            (intermediate_query): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output_query): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (crossattention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=1408, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=1408, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): None\n",
      "            (output): None\n",
      "            (intermediate_query): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output_query): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): None\n",
      "            (output): None\n",
      "            (intermediate_query): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output_query): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (crossattention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=1408, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=1408, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): None\n",
      "            (output): None\n",
      "            (intermediate_query): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output_query): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): None\n",
      "            (output): None\n",
      "            (intermediate_query): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output_query): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (crossattention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=1408, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=1408, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): None\n",
      "            (output): None\n",
      "            (intermediate_query): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output_query): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): None\n",
      "            (output): None\n",
      "            (intermediate_query): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output_query): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (crossattention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=1408, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=1408, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): None\n",
      "            (output): None\n",
      "            (intermediate_query): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output_query): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): None\n",
      "            (output): None\n",
      "            (intermediate_query): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output_query): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (crossattention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=1408, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=1408, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): None\n",
      "            (output): None\n",
      "            (intermediate_query): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output_query): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): None\n",
      "            (output): None\n",
      "            (intermediate_query): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output_query): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (cls): None\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# BLIP-2\n",
    "from otx.v2.adapters.torch.mmengine.mmpretrain.model import get_model\n",
    "blip_2_model = get_model(\"blip2-opt2.7b_3rdparty-zeroshot_caption\")\n",
    "print(blip_2_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'pred_caption': 'of'}]\n"
     ]
    }
   ],
   "source": [
    "pred_result = engine.predict(\n",
    "    model=blip_2_model,\n",
    "    img=sample\n",
    ")\n",
    "print(pred_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OFA\n",
    "- https://github.com/open-mmlab/mmpretrain/tree/main/configs/ofa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OFA(\n",
      "  (data_preprocessor): MultiModalDataPreprocessor()\n",
      "  (model): OFAEncoderDecoder(\n",
      "    (encoder): OFAEncoder(\n",
      "      (embed_tokens): Embedding(59457, 768, padding_idx=1)\n",
      "      (embed_images): OFAResNet(\n",
      "        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "        (layer1): ResLayer(\n",
      "          (0): Bottleneck(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (1): Bottleneck(\n",
      "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (2): Bottleneck(\n",
      "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "        )\n",
      "        (layer2): ResLayer(\n",
      "          (0): Bottleneck(\n",
      "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (1): Bottleneck(\n",
      "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (2): Bottleneck(\n",
      "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (3): Bottleneck(\n",
      "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "        )\n",
      "        (layer3): ResLayer(\n",
      "          (0): Bottleneck(\n",
      "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (1): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (2): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (3): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (4): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (5): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (6): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (7): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (8): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (9): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (10): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (11): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (12): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (13): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (14): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (15): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (16): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (17): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (18): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (19): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (20): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (21): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (22): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      init_cfg=[{'type': 'Kaiming', 'layer': ['Conv2d']}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]\n",
      "      (image_proj): Linear(in_features=1024, out_features=768, bias=True)\n",
      "      (embedding_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (embed_type): Embedding(2, 768)\n",
      "      (image_embedding_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (embed_positions): Embedding(1026, 768)\n",
      "      (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (embed_image_positions): Embedding(1765, 768)\n",
      "      (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (dropout): Identity()\n",
      "      (token_rel_pos_table_list): ModuleList(\n",
      "        (0): Embedding(511, 12)\n",
      "        (1): Embedding(511, 12)\n",
      "        (2): Embedding(511, 12)\n",
      "        (3): Embedding(511, 12)\n",
      "        (4): Embedding(511, 12)\n",
      "        (5): Embedding(511, 12)\n",
      "      )\n",
      "      (image_rel_pos_table_list): ModuleList(\n",
      "        (0): Embedding(6892, 12)\n",
      "        (1): Embedding(6892, 12)\n",
      "        (2): Embedding(6892, 12)\n",
      "        (3): Embedding(6892, 12)\n",
      "        (4): Embedding(6892, 12)\n",
      "        (5): Embedding(6892, 12)\n",
      "      )\n",
      "      (layers): ModuleList(\n",
      "        (0): OFAEncoderLayer(\n",
      "          (attn): MultiheadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (act_drop): Identity()\n",
      "          (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (ffn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn_mid_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (ffn_mid_ln): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): OFAEncoderLayer(\n",
      "          (attn): MultiheadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (act_drop): Identity()\n",
      "          (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (ffn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn_mid_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (ffn_mid_ln): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): OFAEncoderLayer(\n",
      "          (attn): MultiheadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (act_drop): Identity()\n",
      "          (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (ffn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn_mid_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (ffn_mid_ln): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (3): OFAEncoderLayer(\n",
      "          (attn): MultiheadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (act_drop): Identity()\n",
      "          (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (ffn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn_mid_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (ffn_mid_ln): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (4): OFAEncoderLayer(\n",
      "          (attn): MultiheadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (act_drop): Identity()\n",
      "          (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (ffn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn_mid_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (ffn_mid_ln): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (5): OFAEncoderLayer(\n",
      "          (attn): MultiheadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (act_drop): Identity()\n",
      "          (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (ffn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn_mid_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (ffn_mid_ln): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (final_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (decoder): OFADecoder(\n",
      "      (embed_tokens): Embedding(59457, 768, padding_idx=1)\n",
      "      (embedding_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (code_embedding_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (embed_positions): Embedding(1026, 768)\n",
      "      (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (embed_image_positions): Embedding(1765, 768)\n",
      "      (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (dropout): Identity()\n",
      "      (token_rel_pos_table_list): ModuleList(\n",
      "        (0): Embedding(511, 12)\n",
      "        (1): Embedding(511, 12)\n",
      "        (2): Embedding(511, 12)\n",
      "        (3): Embedding(511, 12)\n",
      "        (4): Embedding(511, 12)\n",
      "        (5): Embedding(511, 12)\n",
      "      )\n",
      "      (image_rel_pos_table_list): ModuleList(\n",
      "        (0): Embedding(6892, 12)\n",
      "        (1): Embedding(6892, 12)\n",
      "        (2): Embedding(6892, 12)\n",
      "        (3): Embedding(6892, 12)\n",
      "        (4): Embedding(6892, 12)\n",
      "        (5): Embedding(6892, 12)\n",
      "      )\n",
      "      (layers): ModuleList(\n",
      "        (0): OFADecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (cross_attn): MultiheadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (act_drop): Identity()\n",
      "          (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (ffn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (self_attn_mid_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (cross_attn_mid_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (ffn_mid_ln): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): OFADecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (cross_attn): MultiheadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (act_drop): Identity()\n",
      "          (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (ffn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (self_attn_mid_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (cross_attn_mid_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (ffn_mid_ln): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): OFADecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (cross_attn): MultiheadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (act_drop): Identity()\n",
      "          (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (ffn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (self_attn_mid_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (cross_attn_mid_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (ffn_mid_ln): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (3): OFADecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (cross_attn): MultiheadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (act_drop): Identity()\n",
      "          (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (ffn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (self_attn_mid_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (cross_attn_mid_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (ffn_mid_ln): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (4): OFADecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (cross_attn): MultiheadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (act_drop): Identity()\n",
      "          (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (ffn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (self_attn_mid_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (cross_attn_mid_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (ffn_mid_ln): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (5): OFADecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (cross_attn): MultiheadAttention(\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (act_drop): Identity()\n",
      "          (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (ffn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (self_attn_mid_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (cross_attn_mid_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (ffn_mid_ln): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (final_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (output_projection): Linear(in_features=768, out_features=59457, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# OFA\n",
    "from otx.v2.adapters.torch.mmengine.mmpretrain.model import get_model\n",
    "ofa_model = get_model(\"ofa-base_3rdparty-finetuned_caption\")\n",
    "print(ofa_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'pred_caption': 'Downloads Downloads Downloads vul vul vul Downloads Downloads KKK KKK KKK wonderfully wonderfully wonderfully Indonesian Indonesian Indonesian'}]\n"
     ]
    }
   ],
   "source": [
    "pred_result = engine.predict(\n",
    "    model=ofa_model,\n",
    "    img=sample\n",
    ")\n",
    "print(pred_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flamingo\n",
    "- https://github.com/open-mmlab/mmpretrain/tree/main/configs/flamingo\n",
    "- SKIP: Need to Hugging-Face model settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-GPT4\n",
    "- https://github.com/open-mmlab/mmpretrain/tree/main/configs/minigpt4\n",
    "- SKIP: Need to Hugging-Face token settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLaVA\n",
    "- https://github.com/open-mmlab/mmpretrain/tree/main/configs/llava\n",
    "- SKIP: Need to download model weights separately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otter\n",
    "- https://github.com/open-mmlab/mmpretrain/tree/main/configs/otter\n",
    "- SKIP: Need to Hugging-Face token settings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
