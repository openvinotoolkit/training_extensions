{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTX API DEMO (Anomalib Example)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customization Training API\n",
    "\n",
    "Select a framework & import adapter modules.\n",
    "\n",
    "We'll choose Anomalib here, and we'll import the following modules."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset & DataLoader\n",
    "1. Prepare a dataset and enter path into Dataset\n",
    "\n",
    "    - Convert to OTX's DatasetEntity and Label Schema by leveraging Datumaro's features through paths (path -> Datumaro -> OTX DatasetEntity & LabelSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use wandb logger install it using `pip install wandb`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/otx/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from otx.v2.adapters.torch.lightning.anomalib import Dataset\n",
    "dataset = Dataset(\n",
    "    train_data_roots=\"../../../../tests/assets/anomaly/hazelnut/train\",\n",
    "    val_data_roots=\"../../../../tests/assets/anomaly/hazelnut/test\",\n",
    "    test_data_roots=\"../../../../tests/assets/anomaly/hazelnut/test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/otx/venv/lib/python3.10/site-packages/datumaro/__init__.py:7: DeprecationWarning: We are planning to clean up the entities in datumaro/__init__.py until datumaro==1.5.0. This will affect the following import pattern: \"import datumaro as dm; dm.<entity>\". If you are using this pattern in your code, please revisit it after upgrading datumaro>=1.5.0.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset type: <class 'torch.utils.data.dataloader.DataLoader'>\n",
      "Length of DataLoader: 1\n",
      "Dataset size: 28\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = dataset.train_dataloader(batch_size=32)\n",
    "print(f\"Dataset type: {type(train_dataloader)}\")\n",
    "print(f\"Length of DataLoader: {len(train_dataloader)}\")\n",
    "print(f\"Dataset size: {len(train_dataloader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset type: <class 'torch.utils.data.dataloader.DataLoader'>\n",
      "Length of DataLoader: 1\n",
      "Dataset size: 23\n"
     ]
    }
   ],
   "source": [
    "val_dataloader = dataset.val_dataloader(batch_size=32)\n",
    "print(f\"Dataset type: {type(val_dataloader)}\")\n",
    "print(f\"Length of DataLoader: {len(val_dataloader)}\")\n",
    "print(f\"Dataset size: {len(val_dataloader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset type: <class 'torch.utils.data.dataloader.DataLoader'>\n",
      "Length of DataLoader: 23\n",
      "Dataset size: 23\n"
     ]
    }
   ],
   "source": [
    "test_dataloader = dataset.test_dataloader()\n",
    "print(f\"Dataset type: {type(test_dataloader)}\")\n",
    "print(f\"Length of DataLoader: {len(test_dataloader)}\")\n",
    "print(f\"Dataset size: {len(test_dataloader.dataset)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Model\n",
    "Config to build the model. -> Provide function for building models so that each framework's config can be used\n",
    "\n",
    "    - Users can build a torch.nn.Module via config as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/otx/venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:36: DeprecationWarning: From v0.10 an `'Binary*'`, `'Multiclass*', `'Multilabel*'` version now exist of each classification metric. Moving forward we recommend using these versions. This base metric will still work as it did prior to v0.10 until v0.11. From v0.11 the `task` argument introduced in this metric will be required and the general order of arguments may change, such that this metric will just function as an single entrypoint to calling the three specialized versions.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/harimkan/workspace/otx/venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `PrecisionRecallCurve` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "FeatureExtractor is deprecated. Use TimmFeatureExtractor instead. Both FeatureExtractor and TimmFeatureExtractor will be removed in a future release.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model type: <class 'anomalib.models.padim.lightning_model.PadimLightning'>\n"
     ]
    }
   ],
   "source": [
    "from otx.v2.adapters.torch.lightning.anomalib import get_model\n",
    "model_config = {\n",
    "    \"model\": {\n",
    "        \"name\": \"padim\",\n",
    "        \"backbone\": \"resnet18\",\n",
    "        \"pre_trained\": True,\n",
    "        \"layers\": [\"layer1\", \"layer2\", \"layer3\"],\n",
    "        \"normalization_method\": \"min_max\",\n",
    "        \"input_size\": [256, 256],\n",
    "    }\n",
    "}\n",
    "model = get_model(model_config)\n",
    "print(f\"Model type: {type(model)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Users can use each framework's training provided by OTX. (Engine)\n",
    "\n",
    "- The engine requires the necessary models and DataLoaders for each framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/otx/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:108: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\n",
      "Missing logger folder: /tmp/OTX-API-test/20231016_151349_train\n",
      "/home/harimkan/workspace/otx/venv/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py:183: UserWarning: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name                  | Type                     | Params\n",
      "-------------------------------------------------------------------\n",
      "0 | image_threshold       | AnomalyScoreThreshold    | 0     \n",
      "1 | pixel_threshold       | AnomalyScoreThreshold    | 0     \n",
      "2 | model                 | PadimModel               | 2.8 M \n",
      "3 | normalization_metrics | MinMax                   | 0     \n",
      "4 | image_metrics         | AnomalibMetricCollection | 0     \n",
      "5 | pixel_metrics         | AnomalibMetricCollection | 0     \n",
      "-------------------------------------------------------------------\n",
      "2.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.8 M     Total params\n",
      "11.131    Total estimated model params size (MB)\n",
      "/home/harimkan/workspace/otx/venv/lib/python3.10/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
      "/home/harimkan/workspace/otx/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/harimkan/workspace/otx/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:02<00:00,  2.27s/it, loss=nan, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/otx/venv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:138: UserWarning: `training_step` returned `None`. If this was on purpose, ignore this warning...\n",
      "  self.warning_cache.warn(\"`training_step` returned `None`. If this was on purpose, ignore this warning...\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:01<00:00,  1.50s/it, loss=nan, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:01<00:00,  1.78s/it, loss=nan, v_num=0]\n",
      "/tmp/OTX-API-test/20231016_151349_train/models/weights.pth\n"
     ]
    }
   ],
   "source": [
    "from otx.v2.adapters.torch.lightning.anomalib import Engine\n",
    "work_path = \"/tmp/OTX-API-test\"\n",
    "engine = Engine(work_dir=work_path)\n",
    "\n",
    "train_results = engine.train(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    max_epochs=5,\n",
    ")\n",
    "\n",
    "print(train_results[\"checkpoint\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1)` was configured so validation will run after every batch.\n",
      "\n",
      "  | Name                  | Type                     | Params\n",
      "-------------------------------------------------------------------\n",
      "0 | image_threshold       | AnomalyScoreThreshold    | 0     \n",
      "1 | pixel_threshold       | AnomalyScoreThreshold    | 0     \n",
      "2 | model                 | PadimModel               | 2.8 M \n",
      "3 | normalization_metrics | MinMax                   | 0     \n",
      "4 | image_metrics         | AnomalibMetricCollection | 0     \n",
      "5 | pixel_metrics         | AnomalibMetricCollection | 0     \n",
      "-------------------------------------------------------------------\n",
      "2.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.8 M     Total params\n",
      "11.131    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/otx/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:488: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n",
      "/home/harimkan/workspace/otx/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 2/2 [00:09<00:00,  4.92s/it, loss=nan, v_num=1]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 2/2 [00:10<00:00,  5.02s/it, loss=nan, v_num=1]\n",
      "/tmp/OTX-API-test/20231016_151349_train/models/weights.pth\n"
     ]
    }
   ],
   "source": [
    "train_results = engine.train(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    val_interval=1,\n",
    "    max_epochs=2,\n",
    ")\n",
    "\n",
    "print(train_results[\"checkpoint\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /tmp/OTX-API-test/20231016_151349_train/models/weights.pth\n",
      "Loaded model weights from checkpoint at /tmp/OTX-API-test/20231016_151349_train/models/weights.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/otx/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:55: LightningDeprecationWarning: Setting `Trainer(resume_from_checkpoint=)` is deprecated in v1.5 and will be removed in v2.0. Please pass `Trainer.fit(ckpt_path=)` directly instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1)` was configured so validation will run after every batch.\n",
      "Missing logger folder: /tmp/OTX-API-test/20231016_151349_test\n",
      "/home/harimkan/workspace/otx/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:488: PossibleUserWarning: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n",
      "/home/harimkan/workspace/otx/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val Metric: [{}]\n",
      "Testing DataLoader 0: 100%|██████████| 23/23 [00:04<00:00,  5.61it/s]\n",
      "Test Metric: [{}]\n"
     ]
    }
   ],
   "source": [
    "# Validation & Testing\n",
    "val_score = engine.validate(val_dataloader=val_dataloader)\n",
    "print(f\"Val Metric: {val_score}\")\n",
    "\n",
    "test_score = engine.test(test_dataloader=test_dataloader)\n",
    "print(f\"Test Metric: {test_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1)` was configured so validation will run after every batch.\n",
      "Missing logger folder: /tmp/OTX-API-test/20231016_151349_predict\n",
      "/home/harimkan/workspace/otx/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s]\n",
      "[{'image': tensor([[[[ 1.7523,  1.8037,  1.7352,  ...,  1.6153,  1.6495,  1.6495],\n",
      "          [ 1.7694,  1.7865,  1.7009,  ...,  1.6838,  1.6667,  1.6667],\n",
      "          [ 1.7352,  1.7180,  1.7523,  ...,  1.6838,  1.7009,  1.6838],\n",
      "          ...,\n",
      "          [ 1.7009,  1.7694,  1.7352,  ...,  1.6838,  1.5982,  1.6153],\n",
      "          [ 1.8208,  1.8037,  1.7865,  ...,  1.6495,  1.6495,  1.6324],\n",
      "          [ 1.7865,  1.8037,  1.7694,  ...,  1.6324,  1.6324,  1.6324]],\n",
      "\n",
      "         [[ 1.6933,  1.7283,  1.6758,  ...,  1.5532,  1.5882,  1.5882],\n",
      "          [ 1.7108,  1.7108,  1.6408,  ...,  1.6232,  1.6057,  1.6057],\n",
      "          [ 1.6583,  1.6408,  1.6758,  ...,  1.6232,  1.6408,  1.6232],\n",
      "          ...,\n",
      "          [ 1.6232,  1.6933,  1.6758,  ...,  1.6232,  1.5357,  1.5532],\n",
      "          [ 1.7458,  1.7283,  1.7283,  ...,  1.5882,  1.5882,  1.5707],\n",
      "          [ 1.7108,  1.7458,  1.7283,  ...,  1.5707,  1.5707,  1.5707]],\n",
      "\n",
      "         [[-0.3753, -0.3404, -0.3927,  ..., -0.4624, -0.4450, -0.4624],\n",
      "          [-0.3578, -0.3578, -0.4275,  ..., -0.3927, -0.4101, -0.4450],\n",
      "          [-0.3927, -0.4275, -0.3927,  ..., -0.4101, -0.4101, -0.4275],\n",
      "          ...,\n",
      "          [-0.4624, -0.3753, -0.3927,  ..., -0.4275, -0.5321, -0.5147],\n",
      "          [-0.3404, -0.3404, -0.3404,  ..., -0.4624, -0.4798, -0.4973],\n",
      "          [-0.3578, -0.3230, -0.3927,  ..., -0.4798, -0.4798, -0.4973]]]]), 'image_path': ['../../../../tests/assets/anomaly/hazelnut/test/colour/01.jpg'], 'anomaly_maps': tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), 'pred_scores': tensor([0.5848]), 'pred_labels': tensor([True]), 'pred_masks': tensor([[[[False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          ...,\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False]]]]), 'pred_boxes': [tensor([[100.,  84., 120.,  99.],\n",
      "        [141., 129., 152., 139.]])], 'box_scores': [tensor([0.5409, 0.5848])], 'box_labels': [tensor([1., 1.])]}]\n"
     ]
    }
   ],
   "source": [
    "pred_results = engine.predict(\n",
    "    img=\"../../../../tests/assets/anomaly/hazelnut/test/colour/01.jpg\",\n",
    "    checkpoint=train_results[\"checkpoint\"]\n",
    ")\n",
    "print(pred_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/otx/venv/lib/python3.10/site-packages/torch/onnx/_internal/jit_utils.py:306: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
      "/home/harimkan/workspace/otx/venv/lib/python3.10/site-packages/torch/onnx/utils.py:689: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "/home/harimkan/workspace/otx/venv/lib/python3.10/site-packages/torch/onnx/utils.py:1186: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Diagnostic Run torch.onnx.export version 2.0.0+cpu ==============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.\n",
      "Find more information about API v2.0 and IR v11 at https://docs.openvino.ai/latest/openvino_2_0_transition_guide.html\n",
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: /tmp/OTX-API-test/20231016_151349_export/openvino/openvino.xml\n",
      "[ SUCCESS ] BIN file: /tmp/OTX-API-test/20231016_151349_export/openvino/openvino.bin\n",
      "{'outputs': {'onnx': '/tmp/OTX-API-test/20231016_151349_export/onnx/onnx_model.onnx', 'bin': '/tmp/OTX-API-test/20231016_151349_export/openvino/openvino.bin', 'xml': '/tmp/OTX-API-test/20231016_151349_export/openvino/openvino.xml'}}\n"
     ]
    }
   ],
   "source": [
    "export_result = engine.export(\n",
    "    checkpoint=train_results[\"checkpoint\"]\n",
    ")\n",
    "\n",
    "print(export_result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OTX AutoRunner (Automation Training API)\n",
    "OTX provides a more convenient API called AutoRunner.\n",
    "\n",
    "- It's more convenient for users to use Engine, which provides auto-configuration and the features provided by OTX without having to choose a framework.\n",
    "- Prepare Dataset & DataLoader + Prepare Model + OTX Recipes + Training + ETC.\n",
    "- This will make all of the above steps happen automatically. (Auto: Model Selection & build, Dataset Configuration, Training, etc..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/otx/venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:36: DeprecationWarning: From v0.10 an `'Binary*'`, `'Multiclass*', `'Multilabel*'` version now exist of each classification metric. Moving forward we recommend using these versions. This base metric will still work as it did prior to v0.10 until v0.11. From v0.11 the `task` argument introduced in this metric will be required and the general order of arguments may change, such that this metric will just function as an single entrypoint to calling the three specialized versions.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/harimkan/workspace/otx/venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `PrecisionRecallCurve` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "FeatureExtractor is deprecated. Use TimmFeatureExtractor instead. Both FeatureExtractor and TimmFeatureExtractor will be removed in a future release.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
      "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "`Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "`Trainer(limit_predict_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "/home/harimkan/workspace/otx/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:108: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\n",
      "Missing logger folder: /tmp/OTX-API-test/20231016_151522_train\n",
      "Cannot perform pixel-level evaluation when task type is classification. Ignoring the following pixel-level metrics: ['F1Score', 'AUROC']\n",
      "/home/harimkan/workspace/otx/venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `ROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/harimkan/workspace/otx/venv/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py:183: UserWarning: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name                  | Type                     | Params\n",
      "-------------------------------------------------------------------\n",
      "0 | image_threshold       | AnomalyScoreThreshold    | 0     \n",
      "1 | pixel_threshold       | AnomalyScoreThreshold    | 0     \n",
      "2 | model                 | PadimModel               | 2.8 M \n",
      "3 | normalization_metrics | MinMax                   | 0     \n",
      "4 | image_metrics         | AnomalibMetricCollection | 0     \n",
      "5 | pixel_metrics         | AnomalibMetricCollection | 0     \n",
      "-------------------------------------------------------------------\n",
      "2.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.8 M     Total params\n",
      "11.131    Total estimated model params size (MB)\n",
      "/home/harimkan/workspace/otx/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/harimkan/workspace/otx/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 14/14 [00:01<00:00, 10.81it/s, loss=nan, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 14/14 [00:01<00:00,  8.63it/s, loss=nan, v_num=0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': PadimLightning(\n",
       "   (image_threshold): AnomalyScoreThreshold()\n",
       "   (pixel_threshold): AnomalyScoreThreshold()\n",
       "   (model): PadimModel(\n",
       "     (feature_extractor): FeatureExtractor(\n",
       "       (feature_extractor): FeatureListNet(\n",
       "         (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "         (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (act1): ReLU(inplace=True)\n",
       "         (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "         (layer1): Sequential(\n",
       "           (0): BasicBlock(\n",
       "             (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (drop_block): Identity()\n",
       "             (act1): ReLU(inplace=True)\n",
       "             (aa): Identity()\n",
       "             (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (act2): ReLU(inplace=True)\n",
       "           )\n",
       "           (1): BasicBlock(\n",
       "             (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (drop_block): Identity()\n",
       "             (act1): ReLU(inplace=True)\n",
       "             (aa): Identity()\n",
       "             (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (act2): ReLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "         (layer2): Sequential(\n",
       "           (0): BasicBlock(\n",
       "             (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "             (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (drop_block): Identity()\n",
       "             (act1): ReLU(inplace=True)\n",
       "             (aa): Identity()\n",
       "             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (act2): ReLU(inplace=True)\n",
       "             (downsample): Sequential(\n",
       "               (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             )\n",
       "           )\n",
       "           (1): BasicBlock(\n",
       "             (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (drop_block): Identity()\n",
       "             (act1): ReLU(inplace=True)\n",
       "             (aa): Identity()\n",
       "             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (act2): ReLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "         (layer3): Sequential(\n",
       "           (0): BasicBlock(\n",
       "             (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (drop_block): Identity()\n",
       "             (act1): ReLU(inplace=True)\n",
       "             (aa): Identity()\n",
       "             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (act2): ReLU(inplace=True)\n",
       "             (downsample): Sequential(\n",
       "               (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "               (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             )\n",
       "           )\n",
       "           (1): BasicBlock(\n",
       "             (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (drop_block): Identity()\n",
       "             (act1): ReLU(inplace=True)\n",
       "             (aa): Identity()\n",
       "             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (act2): ReLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (anomaly_map_generator): AnomalyMapGenerator(\n",
       "       (blur): GaussianBlur2d()\n",
       "     )\n",
       "     (gaussian): MultiVariateGaussian()\n",
       "   )\n",
       "   (normalization_metrics): MinMax()\n",
       "   (image_metrics): AnomalibMetricCollection(\n",
       "     (F1Score): F1Score()\n",
       "     (AUROC): AUROC(),\n",
       "     prefix=image_\n",
       "   )\n",
       "   (pixel_metrics): AnomalibMetricCollection,\n",
       "     prefix=pixel_\n",
       "   )\n",
       " ),\n",
       " 'checkpoint': '/tmp/OTX-API-test/20231016_151522_train/models/weights.pth'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from otx.v2.api.core import AutoRunner\n",
    "\n",
    "output_dir = \"/tmp/OTX-API-test\"\n",
    "data_roots = \"../../../../tests/assets/anomaly/hazelnut/train\"\n",
    "default_config_path = \"../configs/anomaly_classification/otx_anomalib_default.yaml\"\n",
    "\n",
    "engine = AutoRunner(\n",
    "    task=\"anomaly_classification\",  # TODO: Need to add Automation-task detection for Anomaly\n",
    "    work_dir=output_dir,\n",
    "    train_data_roots=data_roots,\n",
    "    config=default_config_path,\n",
    ")\n",
    "\n",
    "engine.train(batch_size=2, max_epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
