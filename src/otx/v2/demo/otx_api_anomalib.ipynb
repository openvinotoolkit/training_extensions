{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTX API DEMO (Anomalib Example)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customization Training API\n",
    "\n",
    "Select a framework & import adapter modules.\n",
    "\n",
    "We'll choose Anomalib here, and we'll import the following modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/repo/otx-fork-3/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use wandb logger install it using `pip install wandb`\n"
     ]
    }
   ],
   "source": [
    "from otx.v2.adapters.torch.anomalib import Dataset, get_model, Engine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset & DataLoader\n",
    "1. Prepare a dataset and enter path into Dataset\n",
    "\n",
    "    - Convert to OTX's DatasetEntity and Label Schema by leveraging Datumaro's features through paths (path -> Datumaro -> OTX DatasetEntity & LabelSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(\n",
    "    train_data_roots=\"/home/harimkan/workspace/repo/otx-fork-3/tests/assets/anomaly/hazelnut/train\",\n",
    "    val_data_roots=\"/home/harimkan/workspace/repo/otx-fork-3/tests/assets/anomaly/hazelnut/test\",\n",
    "    test_data_roots=\"/home/harimkan/workspace/repo/otx-fork-3/tests/assets/anomaly/hazelnut/test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Detected task type: ANOMALY_CLASSIFICATION\n",
      "Dataset type: <class 'torch.utils.data.dataloader.DataLoader'>\n",
      "Length of DataLoader: 28\n",
      "Dataset size: 28\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = dataset.train_dataloader()\n",
    "print(f\"Dataset type: {type(train_dataloader)}\")\n",
    "print(f\"Length of DataLoader: {len(train_dataloader)}\")\n",
    "print(f\"Dataset size: {len(train_dataloader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset type: <class 'torch.utils.data.dataloader.DataLoader'>\n",
      "Length of DataLoader: 23\n",
      "Dataset size: 23\n"
     ]
    }
   ],
   "source": [
    "val_dataloader = dataset.val_dataloader()\n",
    "print(f\"Dataset type: {type(val_dataloader)}\")\n",
    "print(f\"Length of DataLoader: {len(val_dataloader)}\")\n",
    "print(f\"Dataset size: {len(val_dataloader.dataset)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Model\n",
    "Config to build the model. -> Provide function for building models so that each framework's config can be used\n",
    "\n",
    "    - Users can build a torch.nn.Module via config as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/repo/otx-fork-3/venv/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: DeprecationWarning: From v0.10 an `'Binary*'`, `'Multiclass*', `'Multilabel*'` version now exist of each classification metric. Moving forward we recommend using these versions. This base metric will still work as it did prior to v0.10 until v0.11. From v0.11 the `task` argument introduced in this metric will be required and the general order of arguments may change, such that this metric will just function as an single entrypoint to calling the three specialized versions.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/harimkan/workspace/repo/otx-fork-3/venv/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `PrecisionRecallCurve` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "WARNING:anomalib.models.components.feature_extractors.timm:FeatureExtractor is deprecated. Use TimmFeatureExtractor instead. Both FeatureExtractor and TimmFeatureExtractor will be removed in a future release.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model type: <class 'anomalib.models.padim.lightning_model.PadimLightning'>\n"
     ]
    }
   ],
   "source": [
    "model_config = {\n",
    "    \"model\": {\n",
    "        \"name\": \"padim\",\n",
    "        \"backbone\": \"resnet18\",\n",
    "        \"pre_trained\": True,\n",
    "        \"layers\": [\"layer1\", \"layer2\", \"layer3\"],\n",
    "        \"normalization_method\": \"min_max\",\n",
    "        \"input_size\": [256, 256],\n",
    "    }\n",
    "}\n",
    "model = get_model(model_config)\n",
    "print(f\"Model type: {type(model)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Users can use each framework's training provided by OTX. (Engine)\n",
    "\n",
    "- The engine requires the necessary models and DataLoaders for each framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/harimkan/workspace/repo/otx-fork-3/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/setup.py:176: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=2)`.\n",
      "  rank_zero_warn(\n",
      "/home/harimkan/workspace/repo/otx-fork-3/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:108: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\n",
      "/home/harimkan/workspace/repo/otx-fork-3/venv/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py:183: UserWarning: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name                  | Type                     | Params\n",
      "-------------------------------------------------------------------\n",
      "0 | image_threshold       | AnomalyScoreThreshold    | 0     \n",
      "1 | pixel_threshold       | AnomalyScoreThreshold    | 0     \n",
      "2 | model                 | PadimModel               | 2.8 M \n",
      "3 | normalization_metrics | MinMax                   | 0     \n",
      "4 | image_metrics         | AnomalibMetricCollection | 0     \n",
      "5 | pixel_metrics         | AnomalibMetricCollection | 0     \n",
      "-------------------------------------------------------------------\n",
      "2.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.8 M     Total params\n",
      "11.131    Total estimated model params size (MB)\n",
      "/home/harimkan/workspace/repo/otx-fork-3/venv/lib/python3.9/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
      "/home/harimkan/workspace/repo/otx-fork-3/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/harimkan/workspace/repo/otx-fork-3/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (28) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  32%|███▏      | 9/28 [00:00<00:00, 56.72it/s, loss=nan, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/repo/otx-fork-3/venv/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:138: UserWarning: `training_step` returned `None`. If this was on purpose, ignore this warning...\n",
      "  self.warning_cache.warn(\"`training_step` returned `None`. If this was on purpose, ignore this warning...\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  43%|████▎     | 12/28 [00:00<00:00, 56.60it/s, loss=nan, v_num=4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 28/28 [00:00<00:00, 53.75it/s, loss=nan, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 28/28 [00:00<00:00, 40.34it/s, loss=nan, v_num=4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': PadimLightning(\n",
       "   (image_threshold): AnomalyScoreThreshold()\n",
       "   (pixel_threshold): AnomalyScoreThreshold()\n",
       "   (model): PadimModel(\n",
       "     (feature_extractor): FeatureExtractor(\n",
       "       (feature_extractor): FeatureListNet(\n",
       "         (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "         (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (act1): ReLU(inplace=True)\n",
       "         (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "         (layer1): Sequential(\n",
       "           (0): BasicBlock(\n",
       "             (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (drop_block): Identity()\n",
       "             (act1): ReLU(inplace=True)\n",
       "             (aa): Identity()\n",
       "             (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (act2): ReLU(inplace=True)\n",
       "           )\n",
       "           (1): BasicBlock(\n",
       "             (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (drop_block): Identity()\n",
       "             (act1): ReLU(inplace=True)\n",
       "             (aa): Identity()\n",
       "             (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (act2): ReLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "         (layer2): Sequential(\n",
       "           (0): BasicBlock(\n",
       "             (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "             (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (drop_block): Identity()\n",
       "             (act1): ReLU(inplace=True)\n",
       "             (aa): Identity()\n",
       "             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (act2): ReLU(inplace=True)\n",
       "             (downsample): Sequential(\n",
       "               (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             )\n",
       "           )\n",
       "           (1): BasicBlock(\n",
       "             (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (drop_block): Identity()\n",
       "             (act1): ReLU(inplace=True)\n",
       "             (aa): Identity()\n",
       "             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (act2): ReLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "         (layer3): Sequential(\n",
       "           (0): BasicBlock(\n",
       "             (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (drop_block): Identity()\n",
       "             (act1): ReLU(inplace=True)\n",
       "             (aa): Identity()\n",
       "             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (act2): ReLU(inplace=True)\n",
       "             (downsample): Sequential(\n",
       "               (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "               (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             )\n",
       "           )\n",
       "           (1): BasicBlock(\n",
       "             (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (drop_block): Identity()\n",
       "             (act1): ReLU(inplace=True)\n",
       "             (aa): Identity()\n",
       "             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (act2): ReLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (anomaly_map_generator): AnomalyMapGenerator(\n",
       "       (blur): GaussianBlur2d()\n",
       "     )\n",
       "     (gaussian): MultiVariateGaussian()\n",
       "   )\n",
       "   (normalization_metrics): MinMax()\n",
       "   (image_metrics): AnomalibMetricCollection,\n",
       "     prefix=image_\n",
       "   )\n",
       "   (pixel_metrics): AnomalibMetricCollection,\n",
       "     prefix=pixel_\n",
       "   )\n",
       " ),\n",
       " 'checkpoint': None}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_path = \"/tmp/OTX-API-test\"\n",
    "engine = Engine(work_dir=work_path)\n",
    "\n",
    "engine.train(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    max_epochs=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1)` was configured so validation will run after every batch.\n",
      "\n",
      "  | Name                  | Type                     | Params\n",
      "-------------------------------------------------------------------\n",
      "0 | image_threshold       | AnomalyScoreThreshold    | 0     \n",
      "1 | pixel_threshold       | AnomalyScoreThreshold    | 0     \n",
      "2 | model                 | PadimModel               | 2.8 M \n",
      "3 | normalization_metrics | MinMax                   | 0     \n",
      "4 | image_metrics         | AnomalibMetricCollection | 0     \n",
      "5 | pixel_metrics         | AnomalibMetricCollection | 0     \n",
      "-------------------------------------------------------------------\n",
      "2.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.8 M     Total params\n",
      "11.131    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/repo/otx-fork-3/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:488: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n",
      "/home/harimkan/workspace/repo/otx-fork-3/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 672/672 [01:29<00:00,  7.54it/s, loss=nan, v_num=5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 672/672 [01:29<00:00,  7.53it/s, loss=nan, v_num=5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': PadimLightning(\n",
       "   (image_threshold): AnomalyScoreThreshold()\n",
       "   (pixel_threshold): AnomalyScoreThreshold()\n",
       "   (model): PadimModel(\n",
       "     (feature_extractor): FeatureExtractor(\n",
       "       (feature_extractor): FeatureListNet(\n",
       "         (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "         (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (act1): ReLU(inplace=True)\n",
       "         (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "         (layer1): Sequential(\n",
       "           (0): BasicBlock(\n",
       "             (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (drop_block): Identity()\n",
       "             (act1): ReLU(inplace=True)\n",
       "             (aa): Identity()\n",
       "             (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (act2): ReLU(inplace=True)\n",
       "           )\n",
       "           (1): BasicBlock(\n",
       "             (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (drop_block): Identity()\n",
       "             (act1): ReLU(inplace=True)\n",
       "             (aa): Identity()\n",
       "             (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (act2): ReLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "         (layer2): Sequential(\n",
       "           (0): BasicBlock(\n",
       "             (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "             (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (drop_block): Identity()\n",
       "             (act1): ReLU(inplace=True)\n",
       "             (aa): Identity()\n",
       "             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (act2): ReLU(inplace=True)\n",
       "             (downsample): Sequential(\n",
       "               (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             )\n",
       "           )\n",
       "           (1): BasicBlock(\n",
       "             (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (drop_block): Identity()\n",
       "             (act1): ReLU(inplace=True)\n",
       "             (aa): Identity()\n",
       "             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (act2): ReLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "         (layer3): Sequential(\n",
       "           (0): BasicBlock(\n",
       "             (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (drop_block): Identity()\n",
       "             (act1): ReLU(inplace=True)\n",
       "             (aa): Identity()\n",
       "             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (act2): ReLU(inplace=True)\n",
       "             (downsample): Sequential(\n",
       "               (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "               (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             )\n",
       "           )\n",
       "           (1): BasicBlock(\n",
       "             (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (drop_block): Identity()\n",
       "             (act1): ReLU(inplace=True)\n",
       "             (aa): Identity()\n",
       "             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (act2): ReLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (anomaly_map_generator): AnomalyMapGenerator(\n",
       "       (blur): GaussianBlur2d()\n",
       "     )\n",
       "     (gaussian): MultiVariateGaussian()\n",
       "   )\n",
       "   (normalization_metrics): MinMax()\n",
       "   (image_metrics): AnomalibMetricCollection,\n",
       "     prefix=image_\n",
       "   )\n",
       "   (pixel_metrics): AnomalibMetricCollection,\n",
       "     prefix=pixel_\n",
       "   )\n",
       " ),\n",
       " 'checkpoint': None}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.train(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    val_interval=1,\n",
    "    max_epochs=2,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OTX AutoEngine (Automation Training API)\n",
    "OTX provides a more convenient API called AutoEngine.\n",
    "\n",
    "- It's more convenient for users to use Engine, which provides auto-configuration and the features provided by OTX without having to choose a framework.\n",
    "- Prepare Dataset & DataLoader + Prepare Model + OTX Recipes + Training + ETC.\n",
    "- This will make all of the above steps happen automatically. (Auto: Model Selection & build, Dataset Configuration, Training, etc..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:anomalib.models.components.feature_extractors.timm:FeatureExtractor is deprecated. Use TimmFeatureExtractor instead. Both FeatureExtractor and TimmFeatureExtractor will be removed in a future release.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
      "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "`Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "`Trainer(limit_predict_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: results/padim/mvtec/bottle/run/lightning_logs\n",
      "WARNING:anomalib.utils.callbacks.metrics_configuration:Cannot perform pixel-level evaluation when task type is classification. Ignoring the following pixel-level metrics: ['F1Score', 'AUROC']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/repo/otx-fork-3/venv/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `ROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name                  | Type                     | Params\n",
      "-------------------------------------------------------------------\n",
      "0 | image_threshold       | AnomalyScoreThreshold    | 0     \n",
      "1 | pixel_threshold       | AnomalyScoreThreshold    | 0     \n",
      "2 | model                 | PadimModel               | 2.8 M \n",
      "3 | normalization_metrics | MinMax                   | 0     \n",
      "4 | image_metrics         | AnomalibMetricCollection | 0     \n",
      "5 | pixel_metrics         | AnomalibMetricCollection | 0     \n",
      "-------------------------------------------------------------------\n",
      "2.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.8 M     Total params\n",
      "11.131    Total estimated model params size (MB)\n",
      "/home/harimkan/workspace/repo/otx-fork-3/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 14/14 [00:00<00:00, 62.19it/s, loss=nan, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 14/14 [00:00<00:00, 31.18it/s, loss=nan, v_num=0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': PadimLightning(\n",
       "   (image_threshold): AnomalyScoreThreshold()\n",
       "   (pixel_threshold): AnomalyScoreThreshold()\n",
       "   (model): PadimModel(\n",
       "     (feature_extractor): FeatureExtractor(\n",
       "       (feature_extractor): FeatureListNet(\n",
       "         (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "         (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (act1): ReLU(inplace=True)\n",
       "         (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "         (layer1): Sequential(\n",
       "           (0): BasicBlock(\n",
       "             (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (drop_block): Identity()\n",
       "             (act1): ReLU(inplace=True)\n",
       "             (aa): Identity()\n",
       "             (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (act2): ReLU(inplace=True)\n",
       "           )\n",
       "           (1): BasicBlock(\n",
       "             (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (drop_block): Identity()\n",
       "             (act1): ReLU(inplace=True)\n",
       "             (aa): Identity()\n",
       "             (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (act2): ReLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "         (layer2): Sequential(\n",
       "           (0): BasicBlock(\n",
       "             (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "             (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (drop_block): Identity()\n",
       "             (act1): ReLU(inplace=True)\n",
       "             (aa): Identity()\n",
       "             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (act2): ReLU(inplace=True)\n",
       "             (downsample): Sequential(\n",
       "               (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "               (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             )\n",
       "           )\n",
       "           (1): BasicBlock(\n",
       "             (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (drop_block): Identity()\n",
       "             (act1): ReLU(inplace=True)\n",
       "             (aa): Identity()\n",
       "             (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (act2): ReLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "         (layer3): Sequential(\n",
       "           (0): BasicBlock(\n",
       "             (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (drop_block): Identity()\n",
       "             (act1): ReLU(inplace=True)\n",
       "             (aa): Identity()\n",
       "             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (act2): ReLU(inplace=True)\n",
       "             (downsample): Sequential(\n",
       "               (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "               (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             )\n",
       "           )\n",
       "           (1): BasicBlock(\n",
       "             (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (drop_block): Identity()\n",
       "             (act1): ReLU(inplace=True)\n",
       "             (aa): Identity()\n",
       "             (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (act2): ReLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (anomaly_map_generator): AnomalyMapGenerator(\n",
       "       (blur): GaussianBlur2d()\n",
       "     )\n",
       "     (gaussian): MultiVariateGaussian()\n",
       "   )\n",
       "   (normalization_metrics): MinMax()\n",
       "   (image_metrics): AnomalibMetricCollection(\n",
       "     (F1Score): F1Score()\n",
       "     (AUROC): AUROC(),\n",
       "     prefix=image_\n",
       "   )\n",
       "   (pixel_metrics): AnomalibMetricCollection,\n",
       "     prefix=pixel_\n",
       "   )\n",
       " ),\n",
       " 'checkpoint': None}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from otx.v2.api.core.engine import AutoEngine\n",
    "\n",
    "output_dir = \"/tmp/OTX-API-test\"\n",
    "data_roots = \"../../../../tests/assets/anomaly/hazelnut/train\"\n",
    "default_config_path = \"../configs/anomaly_classification/otx_anomalib_padim.yaml\"\n",
    "\n",
    "engine = AutoEngine(\n",
    "    task=\"anomaly_classification\",  # TODO: Need to add Automation-task detection for Anomaly\n",
    "    work_dir=output_dir,\n",
    "    train_data_roots=data_roots,\n",
    "    config=default_config_path,\n",
    ")\n",
    "\n",
    "engine.train(batch_size=2, max_epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
