{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTX API DEMO (MMPretrain Example)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customization Training API\n",
    "\n",
    "Select a framework & import adapter modules.\n",
    "\n",
    "We'll choose MMpretrain here."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Environment:\n",
    "- mmpretrain-1.0.0rc8\n",
    "- mmcv-2.0.1\n",
    "- mmengine-0.7.4\n",
    "- mmdeploy-1.2.0\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset & DataLoader\n",
    "1. Prepare a dataset and enter path into Dataset\n",
    "\n",
    "    - Convert to OTX's DatasetEntity and Label Schema by leveraging Datumaro's features through paths (path -> Datumaro -> OTX DatasetEntity & LabelSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/repo/otx-fork-3/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/harimkan/workspace/repo/otx-fork-3/venv/lib/python3.9/site-packages/openvino/pyopenvino/__init__.py:10: FutureWarning: The module is private and following namespace `pyopenvino` will be removed in the future\n",
      "  warnings.warn(message=\"The module is private and following namespace \" \"`pyopenvino` will be removed in the future\", category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from otx.v2.adapters.torch.mmengine.mmpretrain import Dataset\n",
    "dataset = Dataset(\n",
    "    train_data_roots=\"../dataset/cifar10-small/train_data\",\n",
    "    val_data_roots=\"../dataset/cifar10-small/val_data\",\n",
    "    test_data_roots=\"../dataset/cifar10-small/val_data\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-1. Build Torch Dataset from MMCV config (filepath or dict) -> torch.utils.data.Dataset\n",
    "\n",
    "    - User can build a dataset from a config file or dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Detected dataset format: imagenet\n",
      "[*] Detected task type: CLASSIFICATION\n",
      "2023-08-04 09:37:41,681 | INFO : Try to create a 0 size memory pool.\n",
      "Dataset type: <class 'torch.utils.data.dataloader.DataLoader'>\n",
      "Length of DataLoader: 10\n",
      "Dataset size: 10\n",
      "Number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = dataset.train_dataloader()\n",
    "\n",
    "print(f\"Dataset type: {type(train_dataloader)}\")\n",
    "print(f\"Length of DataLoader: {len(train_dataloader)}\")\n",
    "print(f\"Dataset size: {len(train_dataloader.dataset)}\")\n",
    "print(f\"Number of classes: {dataset.num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader type: <class 'torch.utils.data.dataloader.DataLoader'>\n",
      "Length of DataLoader: 5\n",
      "Dataset size: 10\n"
     ]
    }
   ],
   "source": [
    "# Customize batch_size & num_workers\n",
    "train_dataloader = dataset.train_dataloader(\n",
    "    batch_size=2,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "print(f\"DataLoader type: {type(train_dataloader)}\")\n",
    "print(f\"Length of DataLoader: {len(train_dataloader)}\")\n",
    "print(f\"Dataset size: {len(train_dataloader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader type: <class 'torch.utils.data.dataloader.DataLoader'>\n",
      "Length of DataLoader: 10\n",
      "Dataset size: 10\n"
     ]
    }
   ],
   "source": [
    "val_dataloader = dataset.val_dataloader()\n",
    "\n",
    "print(f\"DataLoader type: {type(val_dataloader)}\")\n",
    "print(f\"Length of DataLoader: {len(val_dataloader)}\")\n",
    "print(f\"Dataset size: {len(val_dataloader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader type: <class 'torch.utils.data.dataloader.DataLoader'>\n",
      "Length of DataLoader: 10\n",
      "Dataset size: 10\n"
     ]
    }
   ],
   "source": [
    "test_dataloader = dataset.test_dataloader()\n",
    "\n",
    "print(f\"DataLoader type: {type(test_dataloader)}\")\n",
    "print(f\"Length of DataLoader: {len(test_dataloader)}\")\n",
    "print(f\"Dataset size: {len(test_dataloader.dataset)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Model\n",
    "### Model provided by OTX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['resnet101-csra_1xb16_voc07-448px', 'resnet101_8xb16_cifar10', 'resnet101_8xb32_in1k', 'resnet152_8xb16_cifar10', 'resnet152_8xb32_in1k', 'resnet18_8xb16_cifar10', 'resnet18_8xb32_in1k', 'resnet34_8xb16_cifar10', 'resnet34_8xb32_in1k', 'resnet50-arcface_8xb32_inshop', 'resnet50_8xb16_cifar10', 'resnet50_8xb16_cifar100', 'resnet50_8xb256-rsb-a1-600e_in1k', 'resnet50_8xb256-rsb-a2-300e_in1k', 'resnet50_8xb256-rsb-a3-100e_in1k', 'resnet50_8xb32-fp16_in1k', 'resnet50_8xb32_in1k', 'resnet50_8xb8_cub', 'resnet50_barlowtwins-pre_8xb32-linear-coslr-100e_in1k', 'resnet50_byol-pre_8xb512-linear-coslr-90e_in1k', 'resnet50_densecl-pre_8xb32-linear-steplr-100e_in1k', 'resnet50_mocov2-pre_8xb32-linear-steplr-100e_in1k', 'resnet50_mocov3-100e-pre_8xb128-linear-coslr-90e_in1k', 'resnet50_mocov3-300e-pre_8xb128-linear-coslr-90e_in1k', 'resnet50_mocov3-800e-pre_8xb128-linear-coslr-90e_in1k', 'resnet50_simclr-200e-pre_8xb512-linear-coslr-90e_in1k', 'resnet50_simclr-800e-pre_8xb512-linear-coslr-90e_in1k', 'resnet50_simsiam-100e-pre_8xb512-linear-coslr-90e_in1k', 'resnet50_simsiam-200e-pre_8xb512-linear-coslr-90e_in1k', 'resnet50_swav-pre_8xb32-linear-coslr-100e_in1k', 'resnetv1c101_8xb32_in1k', 'resnetv1c152_8xb32_in1k', 'resnetv1c50_8xb32_in1k', 'resnetv1d101_8xb32_in1k', 'resnetv1d152_8xb32_in1k', 'resnetv1d50_8xb32_in1k']\n"
     ]
    }
   ],
   "source": [
    "from otx.v2.adapters.torch.mmengine.mmpretrain import list_models\n",
    "# MMPretrain's model\n",
    "model_list = list_models(\"resnet*\")\n",
    "print(model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['otx_efficientnet_b0', 'otx_mobilenet_v3_large_1']\n"
     ]
    }
   ],
   "source": [
    "# OTX's model\n",
    "model_list = list_models(\"otx*\")\n",
    "print(model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model type: <class 'mmpretrain.models.classifiers.image.ImageClassifier'>\n"
     ]
    }
   ],
   "source": [
    "from otx.v2.adapters.torch.mmengine.mmpretrain import get_model\n",
    "# mmpretrain's pre-defined model\n",
    "mmpretrain_model = get_model(\"resnet18_8xb32_in1k\")\n",
    "print(f\"Model type: {type(mmpretrain_model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-04 09:37:42,613 | INFO : init weight - https://github.com/osmr/imgclsmob/releases/download/v0.0.364/efficientnet_b0-0752-0e386130.pth.zip\n",
      "2023-08-04 09:37:42,638 | INFO : 'in_channels' config in model.head is updated from -1 to 1280\n",
      "2023-08-04 09:37:42,704 | INFO : init weight - https://github.com/osmr/imgclsmob/releases/download/v0.0.364/efficientnet_b0-0752-0e386130.pth.zip\n",
      "Model type: <class 'otx.v2.adapters.torch.mmengine.mmpretrain.modules.models.classifiers.custom_image_classifier.CustomImageClassifier'>\n"
     ]
    }
   ],
   "source": [
    "## Build Model from model_name\n",
    "\n",
    "otx_model = get_model(\n",
    "    model=\"otx_efficientnet_b0\",\n",
    "    num_classes=dataset.num_classes\n",
    ")\n",
    "print(f\"Model type: {type(otx_model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-04 09:37:42,777 | INFO : init weight - https://github.com/osmr/imgclsmob/releases/download/v0.0.364/efficientnet_b0-0752-0e386130.pth.zip\n",
      "2023-08-04 09:37:42,799 | INFO : 'in_channels' config in model.head is updated from -1 to 1280\n",
      "2023-08-04 09:37:42,868 | INFO : init weight - https://github.com/osmr/imgclsmob/releases/download/v0.0.364/efficientnet_b0-0752-0e386130.pth.zip\n",
      "Model type: <class 'otx.v2.adapters.torch.mmengine.mmpretrain.modules.models.classifiers.custom_image_classifier.CustomImageClassifier'>\n"
     ]
    }
   ],
   "source": [
    "## Build Model from Config\n",
    "otx_model = get_model(\n",
    "    model=\"/home/harimkan/workspace/repo/otx-fork-3/src/otx/v2/configs/classification/models/otx_efficientnet_b0.yaml\",\n",
    "    num_classes=dataset.num_classes\n",
    ")\n",
    "print(f\"Model type: {type(otx_model)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Users can use each framework's training provided by OTX. (Engine)\n",
    "\n",
    "- The engine requires the necessary models and DataLoaders for each framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/04 09:37:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.9.13 (main, Aug 25 2022, 23:26:10) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    numpy_random_seed: 828882717\n",
      "    GPU 0,1: NVIDIA GeForce RTX 3090\n",
      "    CUDA_HOME: /usr\n",
      "    NVCC: Cuda compilation tools, release 11.5, V11.5.119\n",
      "    GCC: gcc (Ubuntu 9.5.0-1ubuntu1~22.04) 9.5.0\n",
      "    PyTorch: 1.13.1+cu117\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.7\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.5\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.14.1+cu117\n",
      "    OpenCV: 4.8.0\n",
      "    MMEngine: 0.7.4\n",
      "\n",
      "Runtime environment:\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 828882717\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "08/04 09:37:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "08/04 09:37:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "2023-08-04 09:37:44,020 | WARNING : The config used in the build isstored as an object in the configurationfile because the object doesn't have it.This can result in a non-reusable configs.py.\n",
      "08/04 09:37:44 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "08/04 09:37:44 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "08/04 09:37:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /tmp/otx-test.\n",
      "08/04 09:37:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: otx_train_20230804_093742\n",
      "08/04 09:37:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][5/5]  lr: 1.0000e-02  eta: 0:00:02  time: 0.2377  data_time: 0.0139  memory: 305  loss: 2.4191\n",
      "08/04 09:37:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "08/04 09:37:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - `save_param_scheduler` is True but `self.param_schedulers` is None, so skip saving parameter schedulers\n",
      "08/04 09:37:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: otx_train_20230804_093742\n",
      "08/04 09:37:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [2][5/5]  lr: 1.0000e-02  eta: 0:00:00  time: 0.1413  data_time: 0.0162  memory: 305  loss: 2.5514\n",
      "08/04 09:37:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 2 epochs\n",
      "08/04 09:37:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: otx_train_20230804_093742\n",
      "08/04 09:37:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [3][5/5]  lr: 1.0000e-02  eta: 0:00:00  time: 0.0448  data_time: 0.0181  memory: 305  loss: 2.6579\n",
      "08/04 09:37:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 3 epochs\n",
      "/tmp/otx-test/best_accuracy_top1_epoch_3.pth\n"
     ]
    }
   ],
   "source": [
    "from otx.v2.adapters.torch.mmengine.mmpretrain.engine import MMPTEngine\n",
    "\n",
    "# OTX Model Training\n",
    "engine = MMPTEngine(work_dir=\"/tmp/otx-test\",)\n",
    "\n",
    "# Training without validation\n",
    "results = engine.train(\n",
    "    model=otx_model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    max_epochs=3,\n",
    ")\n",
    "\n",
    "print(results[\"checkpoint\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-04 09:37:46,317 | WARNING : The config used in the build isstored as an object in the configurationfile because the object doesn't have it.This can result in a non-reusable configs.py.\n",
      "08/04 09:37:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [3][10/10]    accuracy/top1: 20.0000  data_time: 0.0005  time: 0.0067\n",
      "08/04 09:37:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 20.0000 accuracy/top1 at 3 epoch is saved to best_accuracy_top1_epoch_3.pth.\n",
      "Val Metric: {'accuracy/top1': 20.0}\n",
      "2023-08-04 09:37:46,747 | WARNING : The config used in the build isstored as an object in the configurationfile because the object doesn't have it.This can result in a non-reusable configs.py.\n",
      "08/04 09:37:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [10/10]    accuracy/top1: 20.0000  data_time: 0.0005  time: 0.0064\n",
      "Test Metric: {'accuracy/top1': 20.0}\n"
     ]
    }
   ],
   "source": [
    "val_score = engine.validate(val_dataloader=val_dataloader)\n",
    "print(f\"Val Metric: {val_score}\")\n",
    "\n",
    "test_score = engine.test(test_dataloader=test_dataloader)\n",
    "print(f\"Test Metric: {test_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/04 09:37:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.9.13 (main, Aug 25 2022, 23:26:10) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    numpy_random_seed: 945853104\n",
      "    GPU 0,1: NVIDIA GeForce RTX 3090\n",
      "    CUDA_HOME: /usr\n",
      "    NVCC: Cuda compilation tools, release 11.5, V11.5.119\n",
      "    GCC: gcc (Ubuntu 9.5.0-1ubuntu1~22.04) 9.5.0\n",
      "    PyTorch: 1.13.1+cu117\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.7\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.5\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.14.1+cu117\n",
      "    OpenCV: 4.8.0\n",
      "    MMEngine: 0.7.4\n",
      "\n",
      "Runtime environment:\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 945853104\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "08/04 09:37:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "08/04 09:37:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "2023-08-04 09:37:47,102 | WARNING : The config used in the build isstored as an object in the configurationfile because the object doesn't have it.This can result in a non-reusable configs.py.\n",
      "08/04 09:37:47 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - init_weights of CustomImageClassifier has been called more than once.\n",
      "08/04 09:37:47 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "08/04 09:37:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /tmp/otx-test.\n",
      "08/04 09:37:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: otx_train_20230804_093746\n",
      "08/04 09:37:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][5/5]  lr: 1.0000e-02  eta: 0:00:00  time: 0.0439  data_time: 0.0186  memory: 367  loss: 2.5951\n",
      "08/04 09:37:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "08/04 09:37:47 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - `save_param_scheduler` is True but `self.param_schedulers` is None, so skip saving parameter schedulers\n",
      "08/04 09:37:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][10/10]    accuracy/top1: 70.0000  data_time: 0.0004  time: 0.0066\n",
      "08/04 09:37:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 70.0000 accuracy/top1 at 1 epoch is saved to best_accuracy_top1_epoch_1.pth.\n",
      "08/04 09:37:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: otx_train_20230804_093746\n",
      "08/04 09:37:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [2][5/5]  lr: 1.0000e-02  eta: 0:00:00  time: 0.0453  data_time: 0.0189  memory: 367  loss: 2.6060\n",
      "08/04 09:37:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 2 epochs\n",
      "08/04 09:37:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [2][10/10]    accuracy/top1: 20.0000  data_time: 0.0004  time: 0.0065\n",
      "08/04 09:37:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: otx_train_20230804_093746\n",
      "08/04 09:37:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [3][5/5]  lr: 1.0000e-02  eta: 0:00:00  time: 0.0465  data_time: 0.0190  memory: 367  loss: 2.5291\n",
      "08/04 09:37:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 3 epochs\n",
      "08/04 09:37:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [3][10/10]    accuracy/top1: 20.0000  data_time: 0.0004  time: 0.0064\n",
      "/tmp/otx-test/best_accuracy_top1_epoch_3.pth\n"
     ]
    }
   ],
   "source": [
    "# OR\n",
    "# Training with validation\n",
    "results = engine.train(\n",
    "    model=otx_model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    max_epochs=3,\n",
    ")\n",
    "\n",
    "print(results[\"checkpoint\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-04 09:37:48,937 | WARNING : The config used in the build isstored as an object in the configurationfile because the object doesn't have it.This can result in a non-reusable configs.py.\n",
      "08/04 09:37:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [3][10/10]    accuracy/top1: 20.0000  data_time: 0.0004  time: 0.0066\n",
      "Val Metric: {'accuracy/top1': 20.0}\n",
      "2023-08-04 09:37:49,108 | WARNING : The config used in the build isstored as an object in the configurationfile because the object doesn't have it.This can result in a non-reusable configs.py.\n",
      "08/04 09:37:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [10/10]    accuracy/top1: 20.0000  data_time: 0.0004  time: 0.0066\n",
      "Test Metric: {'accuracy/top1': 20.0}\n"
     ]
    }
   ],
   "source": [
    "val_score = engine.validate()\n",
    "print(f\"Val Metric: {val_score}\")\n",
    "\n",
    "test_score = engine.test(test_dataloader=test_dataloader)\n",
    "print(f\"Test Metric: {test_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: /tmp/otx-test/best_accuracy_top1_epoch_3.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'pred_scores': array([0.05100308, 0.05405842, 0.06625324, 0.11286344, 0.17333312,\n",
      "       0.1106501 , 0.09116399, 0.09596299, 0.0818723 , 0.16283934],\n",
      "      dtype=float32), 'pred_label': 4, 'pred_score': 0.17333312332630157}]\n"
     ]
    }
   ],
   "source": [
    "sample = \"/home/harimkan/workspace/repo/demo/dataset/cifar10-small/train_data/bird/image_0042649.jpg\"\n",
    "\n",
    "predict_output = engine.predict(\n",
    "    model=results[\"model\"],\n",
    "    checkpoint=results[\"checkpoint\"],\n",
    "    img=sample\n",
    ")\n",
    "\n",
    "print(predict_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export (with mmdeploy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/04 09:37:50 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmengine\" in the \"Codebases\" registry tree. As a workaround, the current \"Codebases\" registry in \"mmdeploy\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmengine\" is a correct scope, or whether the registry is initialized.\n",
      "08/04 09:37:50 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmpretrain\" in the \"Codebases\" registry tree. As a workaround, the current \"Codebases\" registry in \"mmdeploy\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmpretrain\" is a correct scope, or whether the registry is initialized.\n",
      "08/04 09:37:50 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmpretrain\" in the \"mmpretrain_tasks\" registry tree. As a workaround, the current \"mmpretrain_tasks\" registry in \"mmdeploy\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmpretrain\" is a correct scope, or whether the registry is initialized.\n",
      "2023-08-04 09:37:50,101 | INFO : init weight - https://github.com/osmr/imgclsmob/releases/download/v0.0.364/efficientnet_b0-0752-0e386130.pth.zip\n",
      "08/04 09:37:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Export PyTorch model to ONNX: /tmp/otx-test/openvino.onnx.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/repo/otx-fork-3/venv/lib/python3.9/site-packages/mmpretrain/utils/setup_env.py:34: UserWarning: The current default scope \"mmengine\" is not \"mmpretrain\", `register_all_modules` will force the current default scope to be \"mmpretrain\". If this is not expected, please set `init_default_scope=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/04 09:37:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Args for Model Optimizer: mo --input_model=\"/tmp/otx-test/openvino.onnx\" --output_dir=\"/tmp/otx-test/\" --output=\"output\" --input=\"input\" --input_shape=\"[1, 3, 224, 224]\" --mean_values=\"[123.675, 116.28, 103.53]\" --scale_values=\"[58.395, 57.12, 57.375]\" \n",
      "08/04 09:37:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&source=prod&campid=ww_2023_bu_IOTG_OpenVINO-2022-3&content=upg_all&medium=organic or on https://github.com/openvinotoolkit/openvino\n",
      "[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.\n",
      "Find more information about API v2.0 and IR v11 at https://docs.openvino.ai/latest/openvino_2_0_transition_guide.html\n",
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: /tmp/otx-test/openvino.xml\n",
      "[ SUCCESS ] BIN file: /tmp/otx-test/openvino.bin\n",
      "\n",
      "08/04 09:37:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Successfully exported OpenVINO model: /tmp/otx-test/openvino.xml\n",
      "{'outputs': {'bin': '/tmp/otx-test/openvino.bin', 'xml': '/tmp/otx-test/openvino.xml'}}\n"
     ]
    }
   ],
   "source": [
    "export_output = engine.export(\n",
    "    model=results[\"model\"],\n",
    "    checkpoint=results[\"checkpoint\"],\n",
    ")\n",
    "\n",
    "print(export_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi-SL Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Detected dataset format: imagenet\n",
      "[*] Detected task type: CLASSIFICATION\n",
      "[*] Semisupervised training type detected with unlabeled data: ../dataset/cifar10-small/unlabeled_data\n",
      "2023-08-04 09:37:53,644 | INFO : possible max iterations = 5\n"
     ]
    }
   ],
   "source": [
    "# Semi-SL\n",
    "from otx.v2.adapters.torch.mmengine.mmpretrain import Dataset\n",
    "semisl_dataset = Dataset(\n",
    "    train_data_roots=\"../dataset/cifar10-small/train_data\",\n",
    "    val_data_roots=\"../dataset/cifar10-small/val_data\",\n",
    "    test_data_roots=\"../dataset/cifar10-small/val_data\",\n",
    "    unlabeled_data_roots=\"../dataset/cifar10-small/unlabeled_data\"\n",
    ")\n",
    "\n",
    "strong_pipeline = [\n",
    "    dict(type=\"OTXRandAugment\", num_aug=8, magnitude=10),\n",
    "]\n",
    "\n",
    "pipeline = {\n",
    "    \"train\": [\n",
    "        dict(type=\"Resize\", scale=[224, 224]),\n",
    "        dict(type=\"mmpretrain.PackInputs\"),\n",
    "    ],\n",
    "    \"unlabeled\": [\n",
    "        dict(type=\"Resize\", scale=[224, 224]),\n",
    "        dict(type=\"PostAug\", keys=dict(img_strong=strong_pipeline)),\n",
    "        dict(type=\"mmpretrain.PackMultiKeyInputs\", input_key=\"img\", multi_key=[\"img_strong\"]),\n",
    "    ]\n",
    "}\n",
    "\n",
    "semisl_train_dataloader = semisl_dataset.train_dataloader(\n",
    "    pipeline=pipeline,\n",
    "    batch_size=2,\n",
    "    unlabeled_batch_size=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-04 09:37:53,720 | INFO : init weight - https://github.com/osmr/imgclsmob/releases/download/v0.0.364/efficientnet_b0-0752-0e386130.pth.zip\n"
     ]
    }
   ],
   "source": [
    "from otx.v2.adapters.torch.mmengine.mmpretrain import get_model\n",
    "semi_sl_model = dict(\n",
    "    model=dict(\n",
    "        type='SemiSLClassifier',\n",
    "        backbone=dict(\n",
    "            type='OTXEfficientNet',\n",
    "            pretrained=True,\n",
    "            version='b0'),\n",
    "        neck=dict(\n",
    "            type='GlobalAveragePooling'),\n",
    "        head=dict(\n",
    "            type='SemiLinearClsHead',\n",
    "            num_classes=10,\n",
    "            in_channels=1280,\n",
    "            loss=dict(\n",
    "                type='CrossEntropyLoss',\n",
    "                loss_weight=1.0),\n",
    "            topk=(1, 5)),\n",
    "        pretrained=None\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "semisl_model = get_model(model=semi_sl_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/04 09:37:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.9.13 (main, Aug 25 2022, 23:26:10) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    numpy_random_seed: 256737421\n",
      "    GPU 0,1: NVIDIA GeForce RTX 3090\n",
      "    CUDA_HOME: /usr\n",
      "    NVCC: Cuda compilation tools, release 11.5, V11.5.119\n",
      "    GCC: gcc (Ubuntu 9.5.0-1ubuntu1~22.04) 9.5.0\n",
      "    PyTorch: 1.13.1+cu117\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.7\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.5\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.14.1+cu117\n",
      "    OpenCV: 4.8.0\n",
      "    MMEngine: 0.7.4\n",
      "\n",
      "Runtime environment:\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 256737421\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "08/04 09:37:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "08/04 09:37:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "2023-08-04 09:37:53,937 | WARNING : The config used in the build isstored as an object in the configurationfile because the object doesn't have it.This can result in a non-reusable configs.py.\n",
      "08/04 09:37:54 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "08/04 09:37:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /tmp/semi-sl.\n",
      "08/04 09:37:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: otx_train_20230804_093753\n",
      "08/04 09:37:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][5/5]  lr: 1.0000e-02  eta: 0:00:00  time: 0.0791  data_time: 0.0102  memory: 884  loss: 2.3014  unlabeled_loss: 0.0000\n",
      "08/04 09:37:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "08/04 09:37:54 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - `save_param_scheduler` is True but `self.param_schedulers` is None, so skip saving parameter schedulers\n",
      "08/04 09:37:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: otx_train_20230804_093753\n",
      "08/04 09:37:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [2][5/5]  lr: 1.0000e-02  eta: 0:00:00  time: 0.0709  data_time: 0.0098  memory: 884  loss: 2.9003  unlabeled_loss: 0.0806\n",
      "08/04 09:37:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 2 epochs\n",
      "08/04 09:37:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: otx_train_20230804_093753\n",
      "08/04 09:37:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [3][5/5]  lr: 1.0000e-02  eta: 0:00:00  time: 0.0626  data_time: 0.0093  memory: 884  loss: 3.1828  unlabeled_loss: 0.2041\n",
      "08/04 09:37:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 3 epochs\n",
      "/tmp/semi-sl/epoch_3.pth\n"
     ]
    }
   ],
   "source": [
    "from otx.v2.adapters.torch.mmengine.mmpretrain.engine import MMPTEngine\n",
    "engine = MMPTEngine(work_dir=\"/tmp/semi-sl\")\n",
    "results = engine.train(\n",
    "    model=semisl_model,\n",
    "    train_dataloader=semisl_train_dataloader,\n",
    "    max_epochs=3,\n",
    ")\n",
    "\n",
    "print(results[\"checkpoint\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OTX AutoEngine (Automation Training API)\n",
    "OTX provides a more convenient API called AutoEngine.\n",
    "\n",
    "- It's more convenient for users to use Engine, which provides auto-configuration and the features provided by OTX without having to choose a framework.\n",
    "- Prepare Dataset & DataLoader + Prepare Model + OTX Recipes + Training + ETC.\n",
    "- This will make all of the above steps happen automatically. (Auto: Model Selection & build, Dataset Configuration, Training, etc..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Detected dataset format: imagenet\n",
      "[*] Detected task type: CLASSIFICATION\n",
      "2023-08-04 09:37:55,571 | INFO : init weight - https://github.com/osmr/imgclsmob/releases/download/v0.0.364/efficientnet_b0-0752-0e386130.pth.zip\n",
      "2023-08-04 09:37:55,591 | INFO : 'in_channels' config in model.head is updated from -1 to 1280\n",
      "2023-08-04 09:37:55,659 | INFO : init weight - https://github.com/osmr/imgclsmob/releases/download/v0.0.364/efficientnet_b0-0752-0e386130.pth.zip\n",
      "2023-08-04 09:37:55,661 | WARNING : Currently, OTX does not accept val_dataloader as a dict configuration.\n",
      "2023-08-04 09:37:55,662 | WARNING : Currently, OTX does not accept test_dataloader as a dict configuration.\n",
      "2023-08-04 09:37:55,662 | WARNING : In Engine.config, remove ['framework', 'data', 'optimizer', 'max_epochs', 'max_iters', 'val_interval', 'precision'] that are unavailable to the Runner.\n",
      "08/04 09:37:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.9.13 (main, Aug 25 2022, 23:26:10) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    numpy_random_seed: 1028466089\n",
      "    GPU 0,1: NVIDIA GeForce RTX 3090\n",
      "    CUDA_HOME: /usr\n",
      "    NVCC: Cuda compilation tools, release 11.5, V11.5.119\n",
      "    GCC: gcc (Ubuntu 9.5.0-1ubuntu1~22.04) 9.5.0\n",
      "    PyTorch: 1.13.1+cu117\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.7\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.5\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.14.1+cu117\n",
      "    OpenCV: 4.8.0\n",
      "    MMEngine: 0.7.4\n",
      "\n",
      "Runtime environment:\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 1028466089\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "08/04 09:37:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "08/04 09:37:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "2023-08-04 09:37:55,873 | WARNING : The config used in the build isstored as an object in the configurationfile because the object doesn't have it.This can result in a non-reusable configs.py.\n",
      "08/04 09:37:55 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "08/04 09:37:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /tmp/OTX-API-test.\n",
      "08/04 09:37:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: otx_train_20230804_093755\n",
      "08/04 09:37:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][5/5]  lr: 1.0000e-02  eta: 0:00:00  time: 0.0293  data_time: 0.0047  memory: 610  loss: 2.8494\n",
      "08/04 09:37:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/repo/otx-fork-3/venv/lib/python3.9/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/04 09:37:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: otx_train_20230804_093755\n",
      "08/04 09:37:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [2][5/5]  lr: 5.0000e-03  eta: 0:00:00  time: 0.0291  data_time: 0.0047  memory: 610  loss: 2.5213\n",
      "08/04 09:37:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 2 epochs\n",
      "/tmp/OTX-API-test/best_accuracy_top1_epoch_2.pth\n"
     ]
    }
   ],
   "source": [
    "from otx.v2.api.core.engine import AutoEngine\n",
    "\n",
    "output_dir = \"/tmp/OTX-API-test\"\n",
    "data_roots = \"../dataset/cifar10-small/train_data\"\n",
    "\n",
    "engine = AutoEngine(\n",
    "    work_dir=output_dir,\n",
    "    train_data_roots=data_roots,\n",
    ")\n",
    "\n",
    "# Customization training\n",
    "results = engine.train(\n",
    "    batch_size=2,\n",
    "    max_epochs=2\n",
    ")\n",
    "print(results[\"checkpoint\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
