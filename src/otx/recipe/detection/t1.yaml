model:
  class_path: otx.algo.detection.atss.ATSS
  init_args:
    num_classes: 1000
    variant: mobilenetv2

optimizer:
  class_path: torch.optim.SGD
  init_args:
    lr: 0.004
    momentum: 0.9
    weight_decay: 0.0001

scheduler:
  class_path: lightning.pytorch.cli.ReduceLROnPlateau
  init_args:
    mode: min
    factor: 0.1
    patience: 10
    monitor: train/loss

engine:
  task: DETECTION
  device: auto

callback_monitor: val/map_50

data: ../_base_/data/torchvision_base.yaml
overrides:
  max_epochs: 10
  data:
    task: DETECTION
    config:
      data_format: coco_instances
      include_polygons: false
      train_subset:
        batch_size: 2
        num_workers: 2
        transforms:
          # - _target_: otx.core.data.transform_libs.torchvision.PerturbBoundingBoxes
          #   offset: 20
          - class_path: torchvision.transforms.v2.Resize
            init_args:
              size: 1023
              max_size: 1024
          - class_path: otx.core.data.transform_libs.torchvision.PadtoSquare
          - class_path: torchvision.transforms.v2.ToDtype
            init_args:
              dtype: ${as_torch_dtype:torch.float32}
              scale: False
          - class_path: torchvision.transforms.v2.Normalize
            init_args:
              mean: [123.675, 116.28, 103.53]
              std: [58.395, 57.12, 57.375]
      val_subset:
        batch_size: 1
        num_workers: 2
        transforms:
          - class_path: torchvision.transforms.v2.Resize
            init_args:
              size: 1023
              max_size: 1024
          - class_path: otx.core.data.transform_libs.torchvision.PadtoSquare
          - class_path: torchvision.transforms.v2.ToDtype
            init_args:
              dtype: ${as_torch_dtype:torch.float32}
              scale: False
          - class_path: torchvision.transforms.v2.Normalize
            init_args:
              mean: [123.675, 116.28, 103.53]
              std: [58.395, 57.12, 57.375]
      test_subset:
        batch_size: 1
        num_workers: 2
        transforms:
          - class_path: torchvision.transforms.v2.Resize
            init_args:
              size: 1023
              max_size: 1024
          - class_path: otx.core.data.transform_libs.torchvision.PadtoSquare
          - class_path: torchvision.transforms.v2.ToDtype
            init_args:
              dtype: ${as_torch_dtype:torch.float32}
              scale: False
          - class_path: torchvision.transforms.v2.Normalize
            init_args:
              mean: [123.675, 116.28, 103.53]
              std: [58.395, 57.12, 57.375]
