class_path: otx.core.model.module.segmentation.OTXSegmentationLitModule
init_args:
  torch_compile: false
  otx_model:
    class_path: otx.core.model.entity.segmentation.MMSegCompatibleModel
    init_args:
      config:
        backbone:
          init_cfg:
            checkpoint: https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segnext/mscan_t_20230227-119e8c9f.pth
            type: Pretrained
          act_cfg:
            type: GELU
          attention_kernel_paddings:
            - 2
            - - 0
              - 3
            - - 0
              - 5
            - - 0
              - 10
          attention_kernel_sizes:
            - 5
            - - 1
              - 7
            - - 1
              - 11
            - - 1
              - 21
          depths:
            - 3
            - 3
            - 5
            - 2
          drop_path_rate: 0.1
          drop_rate: 0.0
          embed_dims:
            - 32
            - 64
            - 160
            - 256
          mlp_ratios:
            - 8
            - 8
            - 4
            - 4
          norm_cfg:
            requires_grad: true
            type: BN
          type: MSCAN
        data_preprocessor:
          bgr_to_rgb: false
          mean:
            - 123.675
            - 116.28
            - 103.53
          pad_val: 0
          seg_pad_val: 255
          size:
            - 512
            - 512
          std:
            - 58.395
            - 57.12
            - 57.375
          test_cfg:
            size_divisor: 32
          type: SegDataPreProcessor
        decode_head:
          align_corners: false
          channels: 256
          dropout_ratio: 0.1
          ham_channels: 256
          ham_kwargs:
            MD_R: 16
            MD_S: 1
            eval_steps: 7
            inv_t: 100
            rand_init: true
            train_steps: 6
          in_channels:
            - 64
            - 160
            - 256
          in_index:
            - 1
            - 2
            - 3
          loss_decode:
            loss_weight: 1.0
            type: CrossEntropyLoss
            use_sigmoid: false
          norm_cfg:
            num_groups: 32
            requires_grad: true
            type: GN
          num_classes: 150
          type: LightHamHead
        pretrained: null
        test_cfg:
          mode: whole
        train_cfg: {}
        type: EncoderDecoder
  optimizer:
    class_path: torch.optim.AdamW
    init_args:
      lr: 0.00006
      betas:
        - 0.9
        - 0.999
      weight_decay: 0.01
  scheduler:
    class_path: torch.optim.lr_scheduler.PolynomialLR
    init_args:
      total_iters: 5
      power: 1.0
      last_epoch: -1
