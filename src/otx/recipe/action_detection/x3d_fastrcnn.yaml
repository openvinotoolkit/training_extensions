# @package _global_
defaults:
  - override /trainer: default
  - override /base: action_detection
  - override /callbacks: action_detection
  - override /data: mmaction_detection
  - override /model: mmaction_detection
data:
  train_subset:
    batch_size: 8
    transforms:
      - type: LoadVideoForDetection
      - type: LoadAnnotations
      - type: SampleAVAFrames
        clip_len: 32
        frame_interval: 2
      - type: RawFrameDecode
        io_backend: disk
      - type: RandomRescale
        scale_range:
          - 256
          - 320
      - type: RandomCrop
        size: 256
      - type: Flip
        flip_ratio: 0.5
      - type: FormatShape
        input_format: NCTHW
        collapse: true
      - type: PackActionInputs
  val_subset:
    batch_size: 1
    transforms:
      - type: LoadVideoForDetection
      - type: LoadAnnotations
      - type: SampleAVAFrames
        clip_len: 32
        frame_interval: 2
        test_mode: true
      - type: RawFrameDecode
        io_backend: disk
      - type: Resize
        scale:
          - -1
          - 256
      - type: FormatShape
        input_format: NCTHW
        collapse: true
      - type: PackActionInputs
  test_subset:
    batch_size: 1
    transforms:
      - type: LoadVideoForDetection
      - type: LoadAnnotations
      - type: SampleAVAFrames
        clip_len: 32
        frame_interval: 2
        test_mode: true
      - type: RawFrameDecode
        io_backend: disk
      - type: Resize
        scale:
          - -1
          - 256
      - type: FormatShape
        input_format: NCTHW
        collapse: true
      - type: PackActionInputs
model:
  otx_model:
    _target_: otx.algo.action_detection.x3d_fastrcnn.X3DFastRCNN
    topk: ???

  optimizer:
    _target_: torch.optim.SGD
    lr: 0.005
    momentum: 0.9
    weight_decay: 0.00001
trainer:
  precision: 32
