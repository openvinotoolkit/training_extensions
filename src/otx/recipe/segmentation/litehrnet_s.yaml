# @package _global_
defaults:
  - override /base: segmentation
  - override /callbacks: segmentation
  - override /data: segmentation
  - override /model: mmseg
data:
  train_subset:
    batch_size: 8
    transforms:
      - type: LoadImageFromFile
      - reduce_zero_label: true
        type: LoadAnnotations
      - keep_ratio: false
        ratio_range:
          - 0.5
          - 2.0
        scale:
          - 544
          - 544
        type: RandomResize
      - cat_max_ratio: 0.75
        crop_size:
          - 512
          - 512
        type: RandomCrop
      - prob: 0.5
        type: RandomFlip
      - type: PhotoMetricDistortion
      - type: PackSegInputs
  val_subset:
    batch_size: 1
    transforms:
      - type: LoadImageFromFile
      - keep_ratio: false
        scale:
          - 544
          - 544
        type: Resize
      - reduce_zero_label: true
        type: LoadAnnotations
      - type: PackSegInputs
  test_subset:
    batch_size: 1
    transforms:
      - type: LoadImageFromFile
      - keep_ratio: false
        scale:
          - 544
          - 544
        type: Resize
      - reduce_zero_label: true
        type: LoadAnnotations
      - type: PackSegInputs
model:
  otx_model:
    config:
      load_from: "https://storage.openvinotoolkit.org/repositories/openvino_training_extensions/models/custom_semantic_segmentation/litehrnetsv2_imagenet1k_rsc.pth"
      backbone:
        type: LiteHRNet
        norm_cfg:
          type: BN
          requires_grad: true
        norm_eval: false
        extra:
          stem:
            stem_channels: 32
            out_channels: 32
            expand_ratio: 1
            strides:
              - 2
              - 2
            extra_stride: true
            input_norm: false
          num_stages: 2
          stages_spec:
            num_modules:
              - 4
              - 4
            num_branches:
              - 2
              - 3
            num_blocks:
              - 2
              - 2
            module_type:
              - LITE
              - LITE
            with_fuse:
              - true
              - true
            reduce_ratios:
              - 8
              - 8
            num_channels:
              - - 60
                - 120
              - - 60
                - 120
                - 240
          out_modules:
            conv:
              enable: false
              channels: 160
            position_att:
              enable: false
              key_channels: 64
              value_channels: 240
              psp_size:
                - 1
                - 3
                - 6
                - 8
            local_att:
              enable: false
          out_aggregator:
            enable: false
          add_input: false
      data_preprocessor:
        bgr_to_rgb: false
        mean:
          - 123.675
          - 116.28
          - 103.53
        pad_val: 0
        seg_pad_val: 255
        size:
          - 512
          - 512
        std:
          - 58.395
          - 57.12
          - 57.375
        test_cfg:
          size_divisor: 32
        type: SegDataPreProcessor
      decode_head:
        type: FCNHead
        in_channels:
          - 60
          - 120
          - 240
        in_index:
          - 0
          - 1
          - 2
        input_transform: resize_concat
        channels: 420
        kernel_size: 1
        num_convs: 1
        concat_input: false
        dropout_ratio: -1
        num_classes: 2
        norm_cfg:
          type: BN
          requires_grad: true
        align_corners: false
        loss_decode:
          type: CrossEntropyLoss
          use_sigmoid: false
          loss_weight: 1.0
      pretrained: null
      test_cfg:
        mode: whole
      train_cfg: {}
      type: EncoderDecoder
  optimizer:
    _target_: torch.optim.Adam
    _partial_: true
    lr: 0.001
    betas: [0.9, 0.999]
    weight_decay: 0.0
  scheduler:
    _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
    _partial_: true
    mode: min
    factor: 0.1
    patience: 10
  export_config:
    input_height: 544
    input_width: 544
    mean:
      - 123.675
      - 116.28
      - 103.53
    std:
      - 58.395
      - 57.12
      - 57.375
