task: OBJECT_DETECTION_3D
input_size:
  - 384
  - 1280
mem_cache_size: 1GB
mem_cache_img_max_size: null
image_color_channel: RGB
stack_images: true
data_format: kitti3d
unannotated_items_ratio: 0.0
train_subset:
  subset_name: train
  transform_lib_type: TORCHVISION
  batch_size: 8
<<<<<<< HEAD
  num_workers: 0
=======
  num_workers: 2
>>>>>>> releases/2.3.0
  to_tv_image: false
  transforms:
    - class_path: otx.core.data.transform_libs.torchvision.Decode3DInputsAffineTransforms
      init_args:
        input_size: $(input_size)
        random_horizontal_flip: true
        random_crop: true
        p_crop: 0.5
        random_scale: 0.05
        random_shift: 0.05
    - class_path: torchvision.transforms.v2.ToDtype
      init_args:
        dtype: ${as_torch_dtype:torch.float32}
    - class_path: torchvision.transforms.v2.Normalize
      init_args:
        mean: [123.675, 116.28, 103.53]
        std: [58.395, 57.12, 57.375]

  sampler:
    class_path: torch.utils.data.RandomSampler

val_subset:
  subset_name: val
  transform_lib_type: TORCHVISION
  batch_size: 16
<<<<<<< HEAD
  num_workers: 0
=======
  num_workers: 2
>>>>>>> releases/2.3.0
  to_tv_image: false
  transforms:
    - class_path: otx.core.data.transform_libs.torchvision.Decode3DInputsAffineTransforms
      init_args:
        input_size: $(input_size)
        decode_annotations: false
    - class_path: torchvision.transforms.v2.ToDtype
      init_args:
        dtype: ${as_torch_dtype:torch.float32}
    - class_path: torchvision.transforms.v2.Normalize
      init_args:
        mean: [123.675, 116.28, 103.53]
        std: [58.395, 57.12, 57.375]
  sampler:
    class_path: torch.utils.data.RandomSampler

test_subset:
  subset_name: test
  transform_lib_type: TORCHVISION
  batch_size: 16
<<<<<<< HEAD
  num_workers: 0
=======
  num_workers: 2
>>>>>>> releases/2.3.0
  to_tv_image: false
  transforms:
    - class_path: otx.core.data.transform_libs.torchvision.Decode3DInputsAffineTransforms
      init_args:
        input_size: $(input_size)
        decode_annotations: false
    - class_path: torchvision.transforms.v2.ToDtype
      init_args:
        dtype: ${as_torch_dtype:torch.float32}
    - class_path: torchvision.transforms.v2.Normalize
      init_args:
        mean: [123.675, 116.28, 103.53]
        std: [58.395, 57.12, 57.375]
  sampler:
    class_path: torch.utils.data.RandomSampler
