task: ACTION_CLASSIFICATION
config:
  data_format: kinetics
  mem_cache_size: 1GB
  mem_cache_img_max_size:
    - 500
    - 500
  image_color_channel: RGB
  stack_images: False
  unannotated_items_ratio: 0.0
  train_subset:
    subset_name: train
    transform_lib_type: MMACTION
    to_tv_image: False
    batch_size: 8
    num_workers: 2
    transforms:
      - type: LoadVideoForClassification
      - type: DecordInit
      - type: SampleFrames
        clip_len: 8
        frame_interval: 4
        num_clips: 1
      - type: DecordDecode
      - type: Resize
        scale:
          - -1
          - 256
      - type: RandomResizedCrop
      - type: Resize
        scale:
          - 224
          - 224
        keep_ratio: false
      - type: Flip
        flip_ratio: 0.5
      - type: FormatShape
        input_format: NCTHW
      - type: PackActionInputs
        meta_keys:
          - img_shape
          - ori_shape
          - scale_factor
    sampler:
      class_path: torch.utils.data.RandomSampler
  val_subset:
    subset_name: val
    transform_lib_type: MMACTION
    to_tv_image: False
    batch_size: 8
    num_workers: 2
    transforms:
      - type: LoadVideoForClassification
      - type: DecordInit
      - type: SampleFrames
        clip_len: 8
        frame_interval: 4
        num_clips: 1
        test_mode: true
      - type: DecordDecode
      - type: Resize
        scale:
          - -1
          - 256
      - type: CenterCrop
        crop_size: 224
      - type: FormatShape
        input_format: NCTHW
      - type: PackActionInputs
        meta_keys:
          - img_shape
          - ori_shape
          - scale_factor
    sampler:
      class_path: torch.utils.data.RandomSampler
  test_subset:
    subset_name: test
    transform_lib_type: MMACTION
    to_tv_image: False
    batch_size: 8
    num_workers: 2
    transforms:
      - type: LoadVideoForClassification
      - type: DecordInit
      - type: SampleFrames
        clip_len: 8
        frame_interval: 4
        num_clips: 1
        test_mode: true
      - type: DecordDecode
      - type: Resize
        scale:
          - -1
          - 256
      - type: CenterCrop
        crop_size: 224
      - type: FormatShape
        input_format: NCTHW
      - type: PackActionInputs
        meta_keys:
          - img_shape
          - ori_shape
          - scale_factor
    sampler:
      class_path: torch.utils.data.RandomSampler
