dataset:
  task: visual_prompting
  train_batch_size: 1
  val_batch_size: 1
  test_batch_size: 1
  num_workers: 4
  image_size: 1024 # dimensions to which images are resized (mandatory)
  normalize:
    mean:
      - 123.675
      - 116.28
      - 103.53
    std:
      - 58.395
      - 57.12
      - 57.375
  offset_bbox: 0
  use_point: false
  use_bbox: false

model:
  name: SAM
  image_size: 1024
  mask_threshold: 0.
  return_logits: true
  backbone: vit_b
  freeze_image_encoder: true
  freeze_prompt_encoder: true
  freeze_mask_decoder: true
  checkpoint: https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth
  # just for inference
  return_single_mask: false
  use_stability_score: false
  stability_score_offset: 1.
  return_extra_metrics: false
  # zero-shot
  default_threshold_reference: 0.3
  default_threshold_target: 0.65
  save_outputs: True

# PL Trainer Args. Don't add extra parameter here.
trainer:
  enable_checkpointing: false
  gradient_clip_val: 0
  gradient_clip_algorithm: norm
  num_nodes: 1
  devices: 1
  enable_progress_bar: true
  overfit_batches: 0.0
  track_grad_norm: -1
  check_val_every_n_epoch: 1 # Don't validate before extracting features.
  fast_dev_run: false
  accumulate_grad_batches: 1
  max_epochs: 1
  min_epochs: null
  max_steps: -1
  min_steps: null
  max_time: null
  limit_train_batches: 1.0
  limit_val_batches: 0 # No validation
  limit_test_batches: 1.0
  limit_predict_batches: 1.0
  val_check_interval: 1.0
  log_every_n_steps: 10
  accelerator: auto # <"cpu", "gpu", "tpu", "ipu", "hpu", "auto">
  strategy: null
  sync_batchnorm: false
  precision: 32
  enable_model_summary: true
  num_sanity_val_steps: 0
  profiler: null
  benchmark: false
  deterministic: false
  reload_dataloaders_every_n_epochs: 0
  auto_lr_find: false
  replace_sampler_ddp: true
  detect_anomaly: false
  auto_scale_batch_size: false
  plugins: null
  move_metrics_to_cpu: false
  multiple_trainloader_mode: max_size_cycle
