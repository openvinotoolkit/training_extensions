engine: ../engine/segmentation.yaml

model:
  class_path: otx.core.model.module.segmentation.OTXSegmentationLitModule
  init_args:
    torch_compile: false
    otx_model:
      class_path: otx.core.model.entity.segmentation.MMSegCompatibleModel
      init_args:
        config:
          load_from: "https://storage.openvinotoolkit.org/repositories/openvino_training_extensions/models/custom_semantic_segmentation/litehrnet18_imagenet1k_rsc.pth"
          backbone:
            type: LiteHRNet
            norm_cfg:
              type: BN
              requires_grad: true
            norm_eval: false
            extra:
              stem:
                stem_channels: 32
                out_channels: 32
                expand_ratio: 1
                strides:
                  - 2
                  - 2
                extra_stride: false
                input_norm: false
              num_stages: 3
              stages_spec:
                num_modules:
                  - 2
                  - 4
                  - 2
                num_branches:
                  - 2
                  - 3
                  - 4
                num_blocks:
                  - 2
                  - 2
                  - 2
                module_type:
                  - LITE
                  - LITE
                  - LITE
                with_fuse:
                  - true
                  - true
                  - true
                reduce_ratios:
                  - 8
                  - 8
                  - 8
                num_channels:
                  - - 40
                    - 80
                  - - 40
                    - 80
                    - 160
                  - - 40
                    - 80
                    - 160
                    - 320
              out_modules:
                conv:
                  enable: false
                  channels: 320
                position_att:
                  enable: false
                  key_channels: 128
                  value_channels: 320
                  psp_size:
                    - 1
                    - 3
                    - 6
                    - 8
                local_att:
                  enable: false
              out_aggregator:
                enable: false
              add_input: false
          data_preprocessor:
            bgr_to_rgb: true
            mean:
              - 123.675
              - 116.28
              - 103.53
            pad_val: 0
            seg_pad_val: 255
            size:
              - 512
              - 512
            std:
              - 58.395
              - 57.12
              - 57.375
            test_cfg:
              size_divisor: 32
            type: SegDataPreProcessor
          decode_head:
            type: FCNHead
            in_channels:
              - 40
              - 80
              - 160
              - 320
            in_index:
              - 0
              - 1
              - 2
              - 3
            input_transform: resize_concat
            channels: 600
            kernel_size: 1
            num_convs: 1
            concat_input: false
            dropout_ratio: -1
            num_classes: 2
            norm_cfg:
              type: BN
              requires_grad: true
            align_corners: false
            loss_decode:
              type: CrossEntropyLoss
              use_sigmoid: false
              loss_weight: 1.0
          pretrained: null
          test_cfg:
            mode: whole
          train_cfg: {}
          type: EncoderDecoder
    optimizer:
      class_path: torch.optim.AdamW
      init_args:
        lr: 0.001
        betas:
          - 0.9
          - 0.999
        weight_decay: 0.0
    scheduler:
      class_path: lightning.pytorch.cli.ReduceLROnPlateau
      init_args:
        mode: min
        factor: 0.1
        patience: 10
        monitor: train/loss

data:
  task: SEMANTIC_SEGMENTATION
  config:
    mem_cache_size: 1GB
    mem_cache_img_max_size: null
    data_format: common_semantic_segmentation_with_subset_dirs
    include_polygons: true
    train_subset:
      subset_name: train
      batch_size: 8
      num_workers: 4
      transform_lib_type: MMSEG
      transforms:
        - type: LoadImageFromFile
        - reduce_zero_label: true
          type: LoadAnnotations
        - keep_ratio: false
          ratio_range:
            - 0.5
            - 2.0
          scale:
            - 544
            - 544
          type: RandomResize
        - cat_max_ratio: 0.75
          crop_size:
            - 512
            - 512
          type: RandomCrop
        - prob: 0.5
          type: RandomFlip
        - type: PhotoMetricDistortion
        - type: PackSegInputs
    val_subset:
      subset_name: val
      num_workers: 4
      batch_size: 1
      transform_lib_type: MMSEG
      transforms:
        - type: LoadImageFromFile
        - keep_ratio: false
          scale:
            - 544
            - 544
          type: Resize
        - reduce_zero_label: true
          type: LoadAnnotations
        - type: PackSegInputs
    test_subset:
      subset_name: test
      num_workers: 4
      batch_size: 1
      transform_lib_type: MMSEG
      transforms:
        - type: LoadImageFromFile
        - keep_ratio: false
          scale:
            - 544
            - 544
          type: Resize
        - reduce_zero_label: true
          type: LoadAnnotations
        - type: PackSegInputs
