{
    "model": "mobilenetv3",
    "input_info": {
      "sample_size": [2, 3, 224, 224]
    },
    "num_classes": 1000,
    "batch_size": 256,
    "weight_decay": 1e-5,
    "optimizer": {
        "type": "Adam",
        "base_lr": 1e-4,
        "schedule_type": "plateau",
	"scheduler_params": {
     	 "threshold": 0.1,
     	 "cooldown": 30
  	  }
    },
    "compression": {
        "algorithm": "quantization",
        "initializer": {
            "range": {
                "num_init_steps": 10
            }
        },
        // the following operation patterns are assumed to be treated as an
        // individual operation by the quantization algorithm, so that FQ layers,
        // are not inserted in between these operations
        "quantizable_subgraph_patterns": [["__mul__", "h_swish"],
                                          ["linear", "h_sigmoid"],
                                          ["conv2d", "batch_norm", "h_swish"]]
    }
}