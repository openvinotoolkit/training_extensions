<!DOCTYPE html>

<html lang="en" data-content_root="../../../../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>otx.algorithms.visual_prompting.tasks.inference &#8212; OpenVINOâ„¢ Training Extensions 1.6.1 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../../_static/styles/theme.css?digest=796348d33e8b1d947c94" rel="stylesheet">
<link href="../../../../../_static/styles/bootstrap.css?digest=796348d33e8b1d947c94" rel="stylesheet">
<link href="../../../../../_static/styles/pydata-sphinx-theme.css?digest=796348d33e8b1d947c94" rel="stylesheet">

  
  <link href="../../../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=796348d33e8b1d947c94" rel="stylesheet">
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2">
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2">
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../../../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/css/custom.css?v=d626d52b" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94">
<link rel="preload" as="script" href="../../../../../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94">

    <script src="../../../../../_static/documentation_options.js?v=662e1299"></script>
    <script src="../../../../../_static/doctools.js?v=888ff710"></script>
    <script src="../../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../../../_static/copybutton.js?v=f281be69"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/otx/algorithms/visual_prompting/tasks/inference';</script>
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="docsearch:language" content="en">
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>

  
  <input type="checkbox" class="sidebar-toggle" name="__primary" id="__primary">
  <label class="overlay overlay-primary" for="__primary"></label>

  
  <input type="checkbox" class="sidebar-toggle" name="__secondary" id="__secondary">
  <label class="overlay overlay-secondary" for="__secondary"></label>

  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
      
<form class="bd-search d-flex align-items-center" action="../../../../../search.html" method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
  </div>

  
  <nav class="bd-header navbar navbar-expand-lg bd-navbar" id="navbar-main"><div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
      <span class="fa-solid fa-bars"></span>
  </label>
  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../../../../../index.html">

  
  
  
  
  
  
  

  
    <img src="../../../../../_static/logos/otx-logo.png" class="logo__image only-light" alt="Logo image">
    <img src="../../../../../_static/logos/otx-logo.png" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    
  </div>

  
  <div class="col-lg-9 navbar-header-items">
    <div id="navbar-center" class="mr-auto">
      
    </div>

    <div id="navbar-end">
      
        <div class="navbar-end-item navbar-persistent--container">
          
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
        </div>
      
      
      <div class="navbar-end-item">
        <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          <a href="https://github.com/openvinotoolkit/training_extensions" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-toggle="tooltip"><img src="../../../../../_static/logos/github_icon.png" class="icon-link-image" alt="GitHub"/></a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>


  
  
    <div class="navbar-persistent--mobile">
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
    </div>
  

  
  <label class="sidebar-toggle secondary-toggle" for="__secondary">
      <span class="fa-solid fa-outdent"></span>
  </label>
  

</div>
  </nav>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar hide-on-wide">
        
  
  <div class="sidebar-header-items sidebar-primary__section">
    
    

    
    
    <div class="sidebar-header-items__end">
      
      <div class="navbar-end-item">
        <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          <a href="https://github.com/openvinotoolkit/training_extensions" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-toggle="tooltip"><img src="../../../../../_static/logos/github_icon.png" class="icon-link-image" alt="GitHub"/></a>
        </li>
      </ul>
      </div>
      
    </div>
    
  </div>

  

  
  <div class="sidebar-end-items sidebar-primary__section">
    <div class="sidebar-end-items__item">
    </div>
  </div>

  
  <div id="rtd-footer-container"></div>

      </div>
      <main id="main-content" class="bd-main">
        
        
        <div class="bd-content">
          <div class="bd-article-container">
            
            <div class="bd-header-article">
                
            </div>
            
            
            <article class="bd-article" role="main">
              
  <h1>Source code for otx.algorithms.visual_prompting.tasks.inference</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Visual Prompting Task.&quot;&quot;&quot;</span>

<span class="c1"># Copyright (C) 2023 Intel Corporation</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1"># http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing,</span>
<span class="c1"># software distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions</span>
<span class="c1"># and limitations under the License.</span>

<span class="kn">import</span> <span class="nn">ctypes</span>
<span class="kn">import</span> <span class="nn">io</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">shutil</span>
<span class="kn">import</span> <span class="nn">tempfile</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">OrderedDict</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">openvino</span> <span class="k">as</span> <span class="nn">ov</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">omegaconf</span> <span class="kn">import</span> <span class="n">DictConfig</span><span class="p">,</span> <span class="n">ListConfig</span>
<span class="kn">from</span> <span class="nn">openvino.tools</span> <span class="kn">import</span> <span class="n">mo</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning</span> <span class="kn">import</span> <span class="n">LightningModule</span><span class="p">,</span> <span class="n">Trainer</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.callbacks</span> <span class="kn">import</span> <span class="n">TQDMProgressBar</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.loggers</span> <span class="kn">import</span> <span class="n">CSVLogger</span>

<span class="kn">from</span> <span class="nn">otx.algorithms.common.configs.training_base</span> <span class="kn">import</span> <span class="n">TrainType</span>
<span class="kn">from</span> <span class="nn">otx.algorithms.common.utils</span> <span class="kn">import</span> <span class="n">set_random_seed</span>
<span class="kn">from</span> <span class="nn">otx.algorithms.visual_prompting.adapters.pytorch_lightning.callbacks</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">InferenceCallback</span><span class="p">,</span>
    <span class="n">ZeroShotInferenceCallback</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">otx.algorithms.visual_prompting.adapters.pytorch_lightning.config</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">get_visual_promtping_config</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">otx.algorithms.visual_prompting.adapters.pytorch_lightning.datasets</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">OTXVisualPromptingDataModule</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">otx.algorithms.visual_prompting.configs.base.configuration</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">VisualPromptingBaseConfig</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">otx.api.entities.datasets</span> <span class="kn">import</span> <span class="n">DatasetEntity</span>
<span class="kn">from</span> <span class="nn">otx.api.entities.inference_parameters</span> <span class="kn">import</span> <span class="n">InferenceParameters</span>
<span class="kn">from</span> <span class="nn">otx.api.entities.model</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">ModelEntity</span><span class="p">,</span>
    <span class="n">ModelFormat</span><span class="p">,</span>
    <span class="n">ModelOptimizationType</span><span class="p">,</span>
    <span class="n">ModelPrecision</span><span class="p">,</span>
    <span class="n">OptimizationMethod</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">otx.api.entities.resultset</span> <span class="kn">import</span> <span class="n">ResultSetEntity</span>
<span class="kn">from</span> <span class="nn">otx.api.entities.task_environment</span> <span class="kn">import</span> <span class="n">TaskEnvironment</span>
<span class="kn">from</span> <span class="nn">otx.api.entities.train_parameters</span> <span class="kn">import</span> <span class="n">TrainParameters</span>
<span class="kn">from</span> <span class="nn">otx.api.serialization.label_mapper</span> <span class="kn">import</span> <span class="n">label_schema_to_bytes</span>
<span class="kn">from</span> <span class="nn">otx.api.usecases.evaluation.metrics_helper</span> <span class="kn">import</span> <span class="n">MetricsHelper</span>
<span class="kn">from</span> <span class="nn">otx.api.usecases.tasks.interfaces.evaluate_interface</span> <span class="kn">import</span> <span class="n">IEvaluationTask</span>
<span class="kn">from</span> <span class="nn">otx.api.usecases.tasks.interfaces.export_interface</span> <span class="kn">import</span> <span class="n">ExportType</span><span class="p">,</span> <span class="n">IExportTask</span>
<span class="kn">from</span> <span class="nn">otx.api.usecases.tasks.interfaces.inference_interface</span> <span class="kn">import</span> <span class="n">IInferenceTask</span>
<span class="kn">from</span> <span class="nn">otx.api.usecases.tasks.interfaces.unload_interface</span> <span class="kn">import</span> <span class="n">IUnload</span>
<span class="kn">from</span> <span class="nn">otx.utils.logger</span> <span class="kn">import</span> <span class="n">get_logger</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">get_logger</span><span class="p">()</span>


<span class="c1"># pylint: disable=too-many-instance-attributes</span>
<div class="viewcode-block" id="InferenceTask">
<a class="viewcode-back" href="../../../../../guide/reference/_autosummary/otx.algorithms.visual_prompting.tasks.inference.html#otx.algorithms.visual_prompting.tasks.inference.InferenceTask">[docs]</a>
<span class="k">class</span> <span class="nc">InferenceTask</span><span class="p">(</span><span class="n">IInferenceTask</span><span class="p">,</span> <span class="n">IEvaluationTask</span><span class="p">,</span> <span class="n">IExportTask</span><span class="p">,</span> <span class="n">IUnload</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Base Visual Prompting Task.</span>

<span class="sd">    Train, Infer, and Export an Visual Prompting Task.</span>

<span class="sd">    Args:</span>
<span class="sd">        task_environment (TaskEnvironment): OTX Task environment.</span>
<span class="sd">        output_path (Optional[str]): output path where task output are saved.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">task_environment</span><span class="p">:</span> <span class="n">TaskEnvironment</span><span class="p">,</span> <span class="n">output_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">enabled</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Initializing the task environment.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">task_environment</span> <span class="o">=</span> <span class="n">task_environment</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">=</span> <span class="n">task_environment</span><span class="o">.</span><span class="n">model_template</span><span class="o">.</span><span class="n">task_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="o">=</span> <span class="n">task_environment</span><span class="o">.</span><span class="n">model_template</span><span class="o">.</span><span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">task_environment</span><span class="o">.</span><span class="n">get_labels</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hyper_parameters</span><span class="p">:</span> <span class="n">VisualPromptingBaseConfig</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_environment</span><span class="o">.</span><span class="n">get_hyper_parameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyper_parameters</span><span class="o">.</span><span class="n">algo_backend</span><span class="o">.</span><span class="n">train_type</span>  <span class="c1"># type: ignore[attr-defined]</span>

        <span class="n">template_file_path</span> <span class="o">=</span> <span class="n">task_environment</span><span class="o">.</span><span class="n">model_template</span><span class="o">.</span><span class="n">model_template_path</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">template_file_path</span><span class="p">))</span>

        <span class="c1"># Hyperparameters.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_work_dir_is_temp</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_path</span> <span class="o">=</span> <span class="n">output_path</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="s2">&quot;train&quot;</span>
        <span class="k">if</span> <span class="n">task_environment</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">task_environment</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train_dataset</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="s2">&quot;export&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output_path</span> <span class="o">=</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">mkdtemp</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;otx-visual_prompting&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_work_dir_is_temp</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="s2">&quot;inference&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>

        <span class="c1"># Set default model attributes.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimization_methods</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">OptimizationMethod</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">precision</span> <span class="o">=</span> <span class="p">[</span><span class="n">ModelPrecision</span><span class="o">.</span><span class="n">FP32</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimization_type</span> <span class="o">=</span> <span class="n">ModelOptimizationType</span><span class="o">.</span><span class="n">MO</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="p">:</span> <span class="n">Trainer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model_ckpt</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">timestamp</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s2">&quot;%Y%m</span><span class="si">%d</span><span class="s2">_%H%M%S&quot;</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">localtime</span><span class="p">())</span>

<div class="viewcode-block" id="InferenceTask.set_seed">
<a class="viewcode-back" href="../../../../../guide/reference/_autosummary/otx.algorithms.visual_prompting.tasks.inference.html#otx.algorithms.visual_prompting.tasks.inference.InferenceTask.set_seed">[docs]</a>
    <span class="k">def</span> <span class="nf">set_seed</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set seed and deterministic.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># If the seed is not present via task.train, it will be found in the recipe.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;seed&quot;</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">deterministic</span><span class="p">:</span>
            <span class="c1"># deterministic is the same.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;deterministic&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;seed&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;deterministic&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">deterministic</span>
        <span class="n">set_random_seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span> <span class="n">logger</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">deterministic</span><span class="p">)</span></div>


<div class="viewcode-block" id="InferenceTask.get_config">
<a class="viewcode-back" href="../../../../../guide/reference/_autosummary/otx.algorithms.visual_prompting.tasks.inference.html#otx.algorithms.visual_prompting.tasks.inference.InferenceTask.get_config">[docs]</a>
    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">DictConfig</span><span class="p">,</span> <span class="n">ListConfig</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get Visual Prompting Config from task environment.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Union[DictConfig, ListConfig]: Visual Prompting config.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># set checkpoints</span>
        <span class="n">model_checkpoint</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">resume_from_checkpoint</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;train&quot;</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_environment</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># when args.load_weights or args.resume_from is set</span>
            <span class="n">checkpoint_path</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">task_environment</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">model_adapters</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;path&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_environment</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">model_adapters</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;resume&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
                <span class="n">resume_from_checkpoint</span> <span class="o">=</span> <span class="n">checkpoint_path</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">model_checkpoint</span> <span class="o">=</span> <span class="n">checkpoint_path</span>

        <span class="n">config</span> <span class="o">=</span> <span class="n">get_visual_promtping_config</span><span class="p">(</span>
            <span class="n">task_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">,</span>
            <span class="n">otx_config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">hyper_parameters</span><span class="p">,</span>
            <span class="n">config_dir</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">base_dir</span><span class="p">,</span>
            <span class="n">mode</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mode</span><span class="p">,</span>
            <span class="n">model_checkpoint</span><span class="o">=</span><span class="n">model_checkpoint</span><span class="p">,</span>
            <span class="n">resume_from_checkpoint</span><span class="o">=</span><span class="n">resume_from_checkpoint</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">task</span> <span class="o">=</span> <span class="s2">&quot;visual_prompting&quot;</span>

        <span class="k">return</span> <span class="n">config</span></div>


<div class="viewcode-block" id="InferenceTask.load_model">
<a class="viewcode-back" href="../../../../../guide/reference/_autosummary/otx.algorithms.visual_prompting.tasks.inference.html#otx.algorithms.visual_prompting.tasks.inference.InferenceTask.load_model">[docs]</a>
    <span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">otx_model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ModelEntity</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">LightningModule</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create and Load Visual Prompting Module.</span>

<span class="sd">        Currently, load model through `sam_model_registry` because there is only SAM.</span>
<span class="sd">        If other visual prompting model is added, loading model process must be changed.</span>

<span class="sd">        Args:</span>
<span class="sd">            otx_model (Optional[ModelEntity]): OTX Model from the task environment.</span>

<span class="sd">        Returns:</span>
<span class="sd">            LightningModule: Visual prompting model with/without weights.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">get_model</span><span class="p">(</span><span class="n">config</span><span class="p">:</span> <span class="n">DictConfig</span><span class="p">,</span> <span class="n">train_type</span><span class="p">:</span> <span class="n">TrainType</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">OrderedDict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;SAM&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">train_type</span> <span class="o">==</span> <span class="n">TrainType</span><span class="o">.</span><span class="n">Incremental</span><span class="p">:</span>
                    <span class="kn">from</span> <span class="nn">otx.algorithms.visual_prompting.adapters.pytorch_lightning.models</span> <span class="kn">import</span> <span class="p">(</span>
                        <span class="n">SegmentAnything</span> <span class="k">as</span> <span class="n">VisualPrompter</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="k">elif</span> <span class="n">train_type</span> <span class="o">==</span> <span class="n">TrainType</span><span class="o">.</span><span class="n">Zeroshot</span><span class="p">:</span>
                    <span class="kn">from</span> <span class="nn">otx.algorithms.visual_prompting.adapters.pytorch_lightning.models</span> <span class="kn">import</span> <span class="p">(</span>  <span class="c1"># type: ignore[assignment] # noqa: E501</span>
                        <span class="n">ZeroShotSegmentAnything</span> <span class="k">as</span> <span class="n">VisualPrompter</span><span class="p">,</span>
                    <span class="p">)</span>

                <span class="n">model</span> <span class="o">=</span> <span class="n">VisualPrompter</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span> <span class="n">state_dict</span><span class="o">=</span><span class="n">state_dict</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                    <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Current selected model </span><span class="si">{</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2"> is not implemented. &quot;</span> <span class="sa">f</span><span class="s2">&quot;Use SAM instead.&quot;</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="n">model</span>

        <span class="n">state_dict</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">otx_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="s2">&quot;No trained model in project yet. Created new model with &#39;</span><span class="si">%s</span><span class="s2">&#39;&quot;</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">otx_model</span><span class="o">.</span><span class="n">model_adapters</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;resume&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
            <span class="c1"># If resuming, pass this part to load checkpoint in Trainer</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;To resume </span><span class="si">{</span><span class="n">otx_model</span><span class="o">.</span><span class="n">model_adapters</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;path&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">, the checkpoint will be loaded in Trainer.&quot;</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Load state_dict</span>
            <span class="n">buffer</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">otx_model</span><span class="o">.</span><span class="n">get_data</span><span class="p">(</span><span class="s2">&quot;weights.pth&quot;</span><span class="p">))</span>
            <span class="n">model_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">model_data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;state_dict&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="n">model_data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;pytorch-lightning_version&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">):</span>
                <span class="c1"># Load state_dict from pytorch lightning checkpoint or weights.pth saved by visual prompting task</span>
                <span class="c1"># In pytorch lightning checkpoint, there are metas: epoch, global_step, pytorch-lightning_version,</span>
                <span class="c1"># state_dict, loops, callbacks, optimizer_states, lr_schedulers, hparams_name, hyper_parameters.</span>
                <span class="c1"># To confirm if it is from pytorch lightning, check if one or two of them is in model_data.</span>
                <span class="n">state_dict</span> <span class="o">=</span> <span class="n">model_data</span><span class="p">[</span><span class="s2">&quot;state_dict&quot;</span><span class="p">]</span>

            <span class="k">elif</span> <span class="n">model_data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;model&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="n">model_data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;config&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">):</span>
                <span class="c1"># Load state_dict from checkpoint saved by otx other tasks</span>
                <span class="k">if</span> <span class="n">model_data</span><span class="p">[</span><span class="s2">&quot;config&quot;</span><span class="p">][</span><span class="s2">&quot;model&quot;</span><span class="p">][</span><span class="s2">&quot;backbone&quot;</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">][</span><span class="s2">&quot;backbone&quot;</span><span class="p">]:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                        <span class="s2">&quot;Backbone of the model in the Task Environment is different from the one in the template. &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;creating model with backbone=</span><span class="si">{</span><span class="n">model_data</span><span class="p">[</span><span class="s1">&#39;config&#39;</span><span class="p">][</span><span class="s1">&#39;model&#39;</span><span class="p">][</span><span class="s1">&#39;backbone&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">][</span><span class="s2">&quot;backbone&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">model_data</span><span class="p">[</span><span class="s2">&quot;config&quot;</span><span class="p">][</span><span class="s2">&quot;model&quot;</span><span class="p">][</span><span class="s2">&quot;backbone&quot;</span><span class="p">]</span>
                <span class="n">state_dict</span> <span class="o">=</span> <span class="n">model_data</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">]</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Load state_dict from naive pytorch checkpoint</span>
                <span class="n">state_dict</span> <span class="o">=</span> <span class="n">model_data</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">get_model</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">train_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_type</span><span class="p">,</span> <span class="n">state_dict</span><span class="o">=</span><span class="n">state_dict</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Complete to load model.&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">BaseException</span> <span class="k">as</span> <span class="n">exception</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Could not load the saved model. The model file structure is invalid.&quot;</span><span class="p">)</span> <span class="kn">from</span> <span class="nn">exception</span>

        <span class="k">return</span> <span class="n">model</span></div>


    <span class="k">def</span> <span class="nf">cancel_training</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># noqa: D102</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

<div class="viewcode-block" id="InferenceTask.infer">
<a class="viewcode-back" href="../../../../../guide/reference/_autosummary/otx.algorithms.visual_prompting.tasks.inference.html#otx.algorithms.visual_prompting.tasks.inference.InferenceTask.infer">[docs]</a>
    <span class="k">def</span> <span class="nf">infer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">:</span> <span class="n">DatasetEntity</span><span class="p">,</span> <span class="n">inference_parameters</span><span class="p">:</span> <span class="n">InferenceParameters</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DatasetEntity</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Perform inference on a dataset.</span>

<span class="sd">        Args:</span>
<span class="sd">            dataset (DatasetEntity): Dataset to infer.</span>
<span class="sd">            inference_parameters (InferenceParameters): Inference parameters.</span>

<span class="sd">        Returns:</span>
<span class="sd">            DatasetEntity: Output dataset with predictions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Performing inference on the validation set using the base torch model.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">otx_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">task_environment</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
        <span class="n">datamodule</span> <span class="o">=</span> <span class="n">OTXVisualPromptingDataModule</span><span class="p">(</span>
            <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span> <span class="n">dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span> <span class="n">train_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_type</span>
        <span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Inference Configs &#39;</span><span class="si">%s</span><span class="s2">&#39;&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>

        <span class="c1"># Callbacks</span>
        <span class="n">inference_callback</span> <span class="o">=</span> <span class="n">InferenceCallback</span><span class="p">(</span><span class="n">otx_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">)</span>
        <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">TQDMProgressBar</span><span class="p">(),</span> <span class="n">inference_callback</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="p">,</span> <span class="n">logger</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">datamodule</span><span class="o">=</span><span class="n">datamodule</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">inference_callback</span><span class="o">.</span><span class="n">otx_dataset</span></div>


<div class="viewcode-block" id="InferenceTask.evaluate">
<a class="viewcode-back" href="../../../../../guide/reference/_autosummary/otx.algorithms.visual_prompting.tasks.inference.html#otx.algorithms.visual_prompting.tasks.inference.InferenceTask.evaluate">[docs]</a>
    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_resultset</span><span class="p">:</span> <span class="n">ResultSetEntity</span><span class="p">,</span> <span class="n">evaluation_metric</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Evaluate the performance on a result set.</span>

<span class="sd">        Args:</span>
<span class="sd">            output_resultset (ResultSetEntity): Result Set from which the performance is evaluated.</span>
<span class="sd">            evaluation_metric (Optional[str], optional): Evaluation metric. Defaults to None. Instead,</span>
<span class="sd">                metric is chosen depending on the task type.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">metric</span> <span class="o">=</span> <span class="n">MetricsHelper</span><span class="o">.</span><span class="n">compute_dice_averaged_over_pixels</span><span class="p">(</span><span class="n">output_resultset</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;mDice after evaluation: </span><span class="si">{</span><span class="n">metric</span><span class="o">.</span><span class="n">overall_dice</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">output_resultset</span><span class="o">.</span><span class="n">performance</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">get_performance</span><span class="p">()</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Evaluation completed&quot;</span><span class="p">)</span></div>


    <span class="k">def</span> <span class="nf">_export_to_onnx</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">onnx_path</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Export model to ONNX.</span>

<span class="sd">        Args:</span>
<span class="sd">             onnx_path (Dict[str, str]): Paths to save ONNX models.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">height</span> <span class="o">=</span> <span class="n">width</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">image_size</span>
        <span class="k">for</span> <span class="n">module</span><span class="p">,</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">onnx_path</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">module</span> <span class="o">==</span> <span class="s2">&quot;visual_prompting_image_encoder&quot;</span><span class="p">:</span>
                <span class="n">dummy_inputs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;images&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)}</span>
                <span class="n">output_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;image_embeddings&quot;</span><span class="p">]</span>
                <span class="n">dynamic_axes</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="n">model_to_export</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">image_encoder</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># sam without backbone</span>
                <span class="n">embed_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">prompt_encoder</span><span class="o">.</span><span class="n">embed_dim</span>
                <span class="n">embed_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">prompt_encoder</span><span class="o">.</span><span class="n">image_embedding_size</span>
                <span class="n">mask_input_size</span> <span class="o">=</span> <span class="p">[</span><span class="mi">4</span> <span class="o">*</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">embed_size</span><span class="p">]</span>
                <span class="n">dynamic_axes</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s2">&quot;point_coords&quot;</span><span class="p">:</span> <span class="p">{</span><span class="mi">1</span><span class="p">:</span> <span class="s2">&quot;num_points&quot;</span><span class="p">},</span>
                    <span class="s2">&quot;point_labels&quot;</span><span class="p">:</span> <span class="p">{</span><span class="mi">1</span><span class="p">:</span> <span class="s2">&quot;num_points&quot;</span><span class="p">},</span>
                <span class="p">}</span>
                <span class="n">dummy_inputs</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s2">&quot;image_embeddings&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="o">*</span><span class="n">embed_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
                    <span class="s2">&quot;point_coords&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
                    <span class="s2">&quot;point_labels&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
                    <span class="s2">&quot;mask_input&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">mask_input_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
                    <span class="s2">&quot;has_mask_input&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
                    <span class="s2">&quot;orig_size&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
                <span class="p">}</span>
                <span class="n">output_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;upscaled_masks&quot;</span><span class="p">,</span> <span class="s2">&quot;iou_predictions&quot;</span><span class="p">,</span> <span class="s2">&quot;low_res_masks&quot;</span><span class="p">]</span>
                <span class="n">model_to_export</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span>

            <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">TracerWarning</span><span class="p">)</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">UserWarning</span><span class="p">)</span>
                <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">export</span><span class="p">(</span>
                        <span class="n">model_to_export</span><span class="p">,</span>
                        <span class="nb">tuple</span><span class="p">(</span><span class="n">dummy_inputs</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span>
                        <span class="n">f</span><span class="p">,</span>
                        <span class="n">export_params</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">opset_version</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span>
                        <span class="n">do_constant_folding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">input_names</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">dummy_inputs</span><span class="o">.</span><span class="n">keys</span><span class="p">()),</span>
                        <span class="n">output_names</span><span class="o">=</span><span class="n">output_names</span><span class="p">,</span>
                        <span class="n">dynamic_axes</span><span class="o">=</span><span class="n">dynamic_axes</span><span class="p">,</span>
                    <span class="p">)</span>

<div class="viewcode-block" id="InferenceTask.export">
<a class="viewcode-back" href="../../../../../guide/reference/_autosummary/otx.algorithms.visual_prompting.tasks.inference.html#otx.algorithms.visual_prompting.tasks.inference.InferenceTask.export">[docs]</a>
    <span class="k">def</span> <span class="nf">export</span><span class="p">(</span>  <span class="c1"># noqa: D102</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">export_type</span><span class="p">:</span> <span class="n">ExportType</span><span class="p">,</span>
        <span class="n">output_model</span><span class="p">:</span> <span class="n">ModelEntity</span><span class="p">,</span>
        <span class="n">precision</span><span class="p">:</span> <span class="n">ModelPrecision</span> <span class="o">=</span> <span class="n">ModelPrecision</span><span class="o">.</span><span class="n">FP32</span><span class="p">,</span>
        <span class="n">dump_features</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Export model to OpenVINO IR.</span>

<span class="sd">        When SAM gets an image for inference, image encoder runs just once to get image embedding.</span>
<span class="sd">        After that, prompt encoder + mask decoder runs repeatedly to get mask prediction.</span>
<span class="sd">        For this case, SAM should be divided into two parts, image encoder and prompt encoder + mask decoder.</span>

<span class="sd">        Args:</span>
<span class="sd">            export_type (ExportType): Export type should be ExportType.OPENVINO</span>
<span class="sd">            output_model (ModelEntity): The model entity in which to write the OpenVINO IR data</span>
<span class="sd">            precision (bool): Output model weights and inference precision</span>
<span class="sd">            dump_features (bool): Flag to return &quot;feature_vector&quot; and &quot;saliency_map&quot;.</span>

<span class="sd">        Raises:</span>
<span class="sd">            Exception: If export_type is not ExportType.OPENVINO</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">dump_features</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;Feature dumping is not implemented for the visual prompting task.&quot;</span>
                <span class="s2">&quot;The saliency maps and representation vector outputs will not be dumped in the exported model.&quot;</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">otx_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">task_environment</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">export_type</span> <span class="o">==</span> <span class="n">ExportType</span><span class="o">.</span><span class="n">ONNX</span><span class="p">:</span>
            <span class="n">output_model</span><span class="o">.</span><span class="n">model_format</span> <span class="o">=</span> <span class="n">ModelFormat</span><span class="o">.</span><span class="n">ONNX</span>
            <span class="n">output_model</span><span class="o">.</span><span class="n">optimization_type</span> <span class="o">=</span> <span class="n">ModelOptimizationType</span><span class="o">.</span><span class="n">ONNX</span>
            <span class="k">if</span> <span class="n">precision</span> <span class="o">==</span> <span class="n">ModelPrecision</span><span class="o">.</span><span class="n">FP16</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Export to FP16 ONNX is not supported&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">export_type</span> <span class="o">==</span> <span class="n">ExportType</span><span class="o">.</span><span class="n">OPENVINO</span><span class="p">:</span>
            <span class="n">output_model</span><span class="o">.</span><span class="n">model_format</span> <span class="o">=</span> <span class="n">ModelFormat</span><span class="o">.</span><span class="n">OPENVINO</span>
            <span class="n">output_model</span><span class="o">.</span><span class="n">optimization_type</span> <span class="o">=</span> <span class="n">ModelOptimizationType</span><span class="o">.</span><span class="n">MO</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;not supported export type </span><span class="si">{</span><span class="n">export_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">precision</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">precision</span>
        <span class="n">output_model</span><span class="o">.</span><span class="n">has_xai</span> <span class="o">=</span> <span class="n">dump_features</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Exporting to the OpenVINO model.&quot;</span><span class="p">)</span>
        <span class="n">onnx_path</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;visual_prompting_image_encoder&quot;</span><span class="p">:</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_path</span><span class="p">,</span> <span class="s2">&quot;visual_prompting_image_encoder.onnx&quot;</span><span class="p">),</span>
            <span class="s2">&quot;visual_prompting_decoder&quot;</span><span class="p">:</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_path</span><span class="p">,</span> <span class="s2">&quot;visual_prompting_decoder.onnx&quot;</span><span class="p">),</span>
        <span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_export_to_onnx</span><span class="p">(</span><span class="n">onnx_path</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">export_type</span> <span class="o">==</span> <span class="n">ExportType</span><span class="o">.</span><span class="n">ONNX</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">module</span><span class="p">,</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">onnx_path</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
                    <span class="n">output_model</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">module</span><span class="si">}</span><span class="s2">.onnx&quot;</span><span class="p">,</span> <span class="n">file</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">module</span><span class="p">,</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">onnx_path</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">mo_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;input_model&quot;</span><span class="p">:</span> <span class="n">path</span><span class="p">}</span>
                <span class="k">if</span> <span class="n">module</span> <span class="o">==</span> <span class="s2">&quot;visual_prompting_image_encoder&quot;</span><span class="p">:</span>
                    <span class="n">mo_args</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                        <span class="p">{</span>
                            <span class="s2">&quot;mean_values&quot;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">normalize</span><span class="o">.</span><span class="n">mean</span><span class="p">),</span>
                            <span class="s2">&quot;scale_values&quot;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">normalize</span><span class="o">.</span><span class="n">std</span><span class="p">),</span>
                        <span class="p">}</span>
                    <span class="p">)</span>
                <span class="k">if</span> <span class="n">precision</span> <span class="o">==</span> <span class="n">ModelPrecision</span><span class="o">.</span><span class="n">FP16</span><span class="p">:</span>
                    <span class="n">mo_args</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;compress_to_fp16&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">})</span>

                <span class="n">ov_model</span> <span class="o">=</span> <span class="n">mo</span><span class="o">.</span><span class="n">convert_model</span><span class="p">(</span><span class="o">**</span><span class="n">mo_args</span><span class="p">)</span>
                <span class="n">ov</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">ov_model</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_path</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">module</span><span class="si">}</span><span class="s2">.xml&quot;</span><span class="p">))</span>
                <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;.onnx&quot;</span><span class="p">,</span> <span class="s2">&quot;.bin&quot;</span><span class="p">),</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
                    <span class="n">output_model</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">module</span><span class="si">}</span><span class="s2">.bin&quot;</span><span class="p">,</span> <span class="n">file</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
                <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;.onnx&quot;</span><span class="p">,</span> <span class="s2">&quot;.xml&quot;</span><span class="p">),</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
                    <span class="n">output_model</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">module</span><span class="si">}</span><span class="s2">.xml&quot;</span><span class="p">,</span> <span class="n">file</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>

        <span class="n">output_model</span><span class="o">.</span><span class="n">precision</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">precision</span>
        <span class="n">output_model</span><span class="o">.</span><span class="n">optimization_methods</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_methods</span>

        <span class="n">output_model</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="s2">&quot;label_schema.json&quot;</span><span class="p">,</span> <span class="n">label_schema_to_bytes</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">task_environment</span><span class="o">.</span><span class="n">label_schema</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_metadata</span><span class="p">(</span><span class="n">output_model</span><span class="p">)</span></div>


<div class="viewcode-block" id="InferenceTask.model_info">
<a class="viewcode-back" href="../../../../../guide/reference/_autosummary/otx.algorithms.visual_prompting.tasks.inference.html#otx.algorithms.visual_prompting.tasks.inference.InferenceTask.model_info">[docs]</a>
    <span class="k">def</span> <span class="nf">model_info</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return model info to save the model weights.</span>

<span class="sd">        Returns:</span>
<span class="sd">           Dict: Model info.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_ckpt</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;model checkpoint is not set, return empty dictionary.&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">{}</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_model_ckpt</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="InferenceTask.save_model">
<a class="viewcode-back" href="../../../../../guide/reference/_autosummary/otx.algorithms.visual_prompting.tasks.inference.html#otx.algorithms.visual_prompting.tasks.inference.InferenceTask.save_model">[docs]</a>
    <span class="k">def</span> <span class="nf">save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_model</span><span class="p">:</span> <span class="n">ModelEntity</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Save the model after training is completed.</span>

<span class="sd">        Args:</span>
<span class="sd">            output_model (ModelEntity): Output model onto which the weights are saved.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Saving the model weights.&quot;</span><span class="p">)</span>
        <span class="n">model_info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_info</span><span class="p">()</span>
        <span class="n">buffer</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">()</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model_info</span><span class="p">,</span> <span class="n">buffer</span><span class="p">)</span>
        <span class="n">output_model</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="s2">&quot;weights.pth&quot;</span><span class="p">,</span> <span class="n">buffer</span><span class="o">.</span><span class="n">getvalue</span><span class="p">())</span>
        <span class="n">output_model</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="s2">&quot;label_schema.json&quot;</span><span class="p">,</span> <span class="n">label_schema_to_bytes</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">task_environment</span><span class="o">.</span><span class="n">label_schema</span><span class="p">))</span>

        <span class="n">output_model</span><span class="o">.</span><span class="n">precision</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">precision</span>
        <span class="n">output_model</span><span class="o">.</span><span class="n">optimization_methods</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_methods</span></div>


    <span class="k">def</span> <span class="nf">_set_metadata</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_model</span><span class="p">:</span> <span class="n">ModelEntity</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set metadata to the output model.&quot;&quot;&quot;</span>
        <span class="n">metadata</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;image_size&quot;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">image_size</span><span class="p">)}</span>

        <span class="c1"># Set the task type for inferencer</span>
        <span class="n">metadata</span><span class="p">[</span><span class="s2">&quot;task&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># type: ignore</span>
        <span class="n">output_model</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="s2">&quot;metadata&quot;</span><span class="p">,</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">metadata</span><span class="p">)</span><span class="o">.</span><span class="n">encode</span><span class="p">())</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_is_docker</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

<div class="viewcode-block" id="InferenceTask.unload">
<a class="viewcode-back" href="../../../../../guide/reference/_autosummary/otx.algorithms.visual_prompting.tasks.inference.html#otx.algorithms.visual_prompting.tasks.inference.InferenceTask.unload">[docs]</a>
    <span class="k">def</span> <span class="nf">unload</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Unload the task.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cleanup</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_docker</span><span class="p">():</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Got unload request. Unloading models. Throwing Segmentation Fault on purpose&quot;</span><span class="p">)</span>
            <span class="n">ctypes</span><span class="o">.</span><span class="n">string_at</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Got unload request, but not on Docker. Only clearing CUDA cache&quot;</span><span class="p">)</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;Done unloading. Torch is still occupying </span><span class="si">%f</span><span class="s2"> bytes of GPU memory&quot;</span><span class="p">,</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">memory_allocated</span><span class="p">(),</span>
            <span class="p">)</span></div>


<div class="viewcode-block" id="InferenceTask.cleanup">
<a class="viewcode-back" href="../../../../../guide/reference/_autosummary/otx.algorithms.visual_prompting.tasks.inference.html#otx.algorithms.visual_prompting.tasks.inference.InferenceTask.cleanup">[docs]</a>
    <span class="k">def</span> <span class="nf">cleanup</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Clean up work directory.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_work_dir_is_temp</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_delete_scratch_space</span><span class="p">()</span></div>


    <span class="k">def</span> <span class="nf">_delete_scratch_space</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Remove model checkpoints and otx logs.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_path</span><span class="p">):</span>
            <span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_path</span><span class="p">,</span> <span class="n">ignore_errors</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></div>



<div class="viewcode-block" id="ZeroShotTask">
<a class="viewcode-back" href="../../../../../guide/reference/_autosummary/otx.algorithms.visual_prompting.tasks.inference.html#otx.algorithms.visual_prompting.tasks.inference.ZeroShotTask">[docs]</a>
<span class="k">class</span> <span class="nc">ZeroShotTask</span><span class="p">(</span><span class="n">InferenceTask</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Learn task for Zero-shot learning.</span>

<span class="sd">    **There are two ways to be decided:</span>
<span class="sd">    1. use it independently &lt;-- temporarily current setting</span>
<span class="sd">    2. use it depending on template</span>

<span class="sd">    The objective of this task is to get reference features and export it with decoder modules.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span>  <span class="c1"># noqa: D102</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dataset</span><span class="p">:</span> <span class="n">DatasetEntity</span><span class="p">,</span>
        <span class="n">output_model</span><span class="p">:</span> <span class="n">ModelEntity</span><span class="p">,</span>
        <span class="n">train_parameters</span><span class="p">:</span> <span class="n">TrainParameters</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">deterministic</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Training the model.&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="n">deterministic</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_seed</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="s2">&quot;warn&quot;</span> <span class="k">if</span> <span class="n">deterministic</span> <span class="k">else</span> <span class="n">deterministic</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training Configs </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">otx_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">task_environment</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>

        <span class="n">datamodule</span> <span class="o">=</span> <span class="n">OTXVisualPromptingDataModule</span><span class="p">(</span>
            <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span> <span class="n">dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span> <span class="n">train_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_type</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
            <span class="n">logger</span><span class="o">=</span><span class="n">CSVLogger</span><span class="p">(</span><span class="n">save_dir</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">output_path</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">timestamp</span><span class="p">),</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">datamodule</span><span class="o">=</span><span class="n">datamodule</span><span class="p">)</span>

        <span class="c1"># save resulting model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">output_model</span><span class="p">)</span>

<div class="viewcode-block" id="ZeroShotTask.infer">
<a class="viewcode-back" href="../../../../../guide/reference/_autosummary/otx.algorithms.visual_prompting.tasks.inference.html#otx.algorithms.visual_prompting.tasks.inference.ZeroShotTask.infer">[docs]</a>
    <span class="k">def</span> <span class="nf">infer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">:</span> <span class="n">DatasetEntity</span><span class="p">,</span> <span class="n">inference_parameters</span><span class="p">:</span> <span class="n">InferenceParameters</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DatasetEntity</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Perform inference on a dataset.</span>

<span class="sd">        Args:</span>
<span class="sd">            dataset (DatasetEntity): Dataset to infer.</span>
<span class="sd">            inference_parameters (InferenceParameters): Inference parameters.</span>

<span class="sd">        Returns:</span>
<span class="sd">            DatasetEntity: Output dataset with predictions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Performing inference on the validation set using the base torch model.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">otx_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">task_environment</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
        <span class="n">datamodule</span> <span class="o">=</span> <span class="n">OTXVisualPromptingDataModule</span><span class="p">(</span>
            <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span> <span class="n">dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span> <span class="n">train_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_type</span>
        <span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Inference Configs &#39;</span><span class="si">%s</span><span class="s2">&#39;&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>

        <span class="c1"># Callbacks</span>
        <span class="n">inference_callback</span> <span class="o">=</span> <span class="n">ZeroShotInferenceCallback</span><span class="p">(</span>
            <span class="n">otx_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span> <span class="n">label_schema</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">task_environment</span><span class="o">.</span><span class="n">label_schema</span>
        <span class="p">)</span>
        <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">TQDMProgressBar</span><span class="p">(),</span> <span class="n">inference_callback</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="p">,</span> <span class="n">logger</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">datamodule</span><span class="o">=</span><span class="n">datamodule</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">inference_callback</span><span class="o">.</span><span class="n">otx_dataset</span></div>


<div class="viewcode-block" id="ZeroShotTask.save_model">
<a class="viewcode-back" href="../../../../../guide/reference/_autosummary/otx.algorithms.visual_prompting.tasks.inference.html#otx.algorithms.visual_prompting.tasks.inference.ZeroShotTask.save_model">[docs]</a>
    <span class="k">def</span> <span class="nf">save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_model</span><span class="p">:</span> <span class="n">ModelEntity</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Save the model after training is completed.</span>

<span class="sd">        Args:</span>
<span class="sd">            output_model (ModelEntity): Output model onto which the weights are saved.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Saving the model weights and reference features.&quot;</span><span class="p">)</span>

        <span class="n">model_info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
        <span class="n">model_info</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;reference_info.reference_feats&quot;</span><span class="p">)</span>
        <span class="n">model_info</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;reference_info.used_indices&quot;</span><span class="p">)</span>

        <span class="n">buffer</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">()</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model_info</span><span class="p">,</span> <span class="n">buffer</span><span class="p">)</span>
        <span class="n">output_model</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="s2">&quot;weights.pth&quot;</span><span class="p">,</span> <span class="n">buffer</span><span class="o">.</span><span class="n">getvalue</span><span class="p">())</span>
        <span class="n">output_model</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="s2">&quot;label_schema.json&quot;</span><span class="p">,</span> <span class="n">label_schema_to_bytes</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">task_environment</span><span class="o">.</span><span class="n">label_schema</span><span class="p">))</span>

        <span class="n">output_model</span><span class="o">.</span><span class="n">precision</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">precision</span>
        <span class="n">output_model</span><span class="o">.</span><span class="n">optimization_methods</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_methods</span></div>
</div>

</pre></div>

            </article>
            
            
            
            <footer class="bd-footer-article">
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            </footer>
            
          </div>
          
          
          
            <div class="bd-sidebar-secondary bd-toc">
              
<div class="toc-item">
  
<div id="searchbox"></div>
</div>

<div class="toc-item">
  
</div>

<div class="toc-item">
  
</div>

            </div>
          
          
        </div>
        <footer class="bd-footer-content">
          <div class="bd-footer-content__inner">
            
          </div>
        </footer>
        
      </main>
    </div>
  </div>

  
    
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../../../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94"></script>
<script src="../../../../../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94"></script>

  <footer class="bd-footer"><div class="bd-footer__inner container">
  
  <div class="footer-item">
    
<p class="copyright">

    &copy; Copyright 2024, OpenVINOâ„¢ Training Extensions Contributors.<br>

</p>

  </div>
  
  <div class="footer-item">
    <p class="theme-version">
    Built with the
    <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">
        PyData Sphinx Theme
    </a>
    0.12.0.
</p>
  </div>
  
  <div class="footer-item">
    
<p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 7.2.6.<br>
</p>

  </div>
  
</div>
  </footer>
  </body>
</html>