{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "engine:\n",
      "  max_epochs: 10\n",
      "  deterministic: false\n",
      "  precision: 32\n",
      "  val_check_interval: 1\n",
      "  callbacks:\n",
      "  - class_path: lightning.pytorch.callbacks.EarlyStopping\n",
      "    init_args:\n",
      "      monitor: val/accuracy\n",
      "      min_delta: 0.0\n",
      "      patience: 100\n",
      "      verbose: false\n",
      "      mode: max\n",
      "      strict: true\n",
      "      check_finite: true\n",
      "      log_rank_zero_only: false\n",
      "  - class_path: lightning.pytorch.callbacks.RichProgressBar\n",
      "    init_args:\n",
      "      refresh_rate: 1\n",
      "      leave: false\n",
      "      theme:\n",
      "        description: white\n",
      "        progress_bar: '#6206E0'\n",
      "        progress_bar_finished: '#6206E0'\n",
      "        progress_bar_pulse: '#6206E0'\n",
      "        batch_progress: white\n",
      "        time: grey54\n",
      "        processing_speed: grey70\n",
      "        metrics: white\n",
      "        metrics_text_delimiter: ' '\n",
      "        metrics_format: .3f\n",
      "  accelerator: auto\n",
      "  devices: auto\n",
      "  strategy: auto\n",
      "  num_nodes: 1\n",
      "  fast_dev_run: false\n",
      "  max_steps: -1\n",
      "  overfit_batches: 0.0\n",
      "  check_val_every_n_epoch: 1\n",
      "  accumulate_grad_batches: 1\n",
      "  inference_mode: true\n",
      "  use_distributed_sampler: true\n",
      "  detect_anomaly: false\n",
      "  barebones: false\n",
      "  sync_batchnorm: false\n",
      "  reload_dataloaders_every_n_epochs: 0\n",
      "data:\n",
      "  task: MULTI_CLASS_CLS\n",
      "  config:\n",
      "    data_format: imagenet_with_subset_dirs\n",
      "    data_root: tests/assets/classification_dataset\n",
      "    train_subset:\n",
      "      batch_size: 64\n",
      "      subset_name: train\n",
      "      transform_lib_type: MMPRETRAIN\n",
      "      transforms:\n",
      "      - type: LoadImageFromFile\n",
      "      - backend: cv2\n",
      "        scale: 224\n",
      "        type: RandomResizedCrop\n",
      "      - direction: horizontal\n",
      "        prob: 0.5\n",
      "        type: RandomFlip\n",
      "      - type: PackInputs\n",
      "      num_workers: 2\n",
      "    val_subset:\n",
      "      batch_size: 64\n",
      "      subset_name: val\n",
      "      transform_lib_type: MMPRETRAIN\n",
      "      transforms:\n",
      "      - type: LoadImageFromFile\n",
      "      - backend: cv2\n",
      "        edge: short\n",
      "        scale: 256\n",
      "        type: ResizeEdge\n",
      "      - crop_size: 224\n",
      "        type: CenterCrop\n",
      "      - type: PackInputs\n",
      "      num_workers: 2\n",
      "    test_subset:\n",
      "      batch_size: 64\n",
      "      subset_name: test\n",
      "      transform_lib_type: MMPRETRAIN\n",
      "      transforms:\n",
      "      - type: LoadImageFromFile\n",
      "      - backend: cv2\n",
      "        edge: short\n",
      "        scale: 256\n",
      "        type: ResizeEdge\n",
      "      - crop_size: 224\n",
      "        type: CenterCrop\n",
      "      - type: PackInputs\n",
      "      num_workers: 2\n",
      "    mem_cache_size: 1GB\n",
      "    mem_cache_img_max_size:\n",
      "    - 500\n",
      "    - 500\n",
      "model:\n",
      "  class_path: otx.core.model.module.classification.OTXClassificationLitModule\n",
      "  init_args:\n",
      "    otx_model:\n",
      "      class_path: otx.core.model.entity.classification.MMPretrainCompatibleModel\n",
      "      init_args:\n",
      "        config:\n",
      "          backbone:\n",
      "            type: OTXMobileNetV3\n",
      "          head:\n",
      "            act_cfg:\n",
      "              type: HSwish\n",
      "            dropout_rate: 0.2\n",
      "            in_channels: 960\n",
      "            init_cfg:\n",
      "              bias: 0.0\n",
      "              layer: Linear\n",
      "              mean: 0.0\n",
      "              std: 0.01\n",
      "              type: Normal\n",
      "            loss:\n",
      "              loss_weight: 1.0\n",
      "              type: CrossEntropyLoss\n",
      "            mid_channels:\n",
      "            - 1280\n",
      "            num_classes: 2\n",
      "            topk:\n",
      "            - 1\n",
      "            - 5\n",
      "            type: StackedLinearClsHead\n",
      "          neck:\n",
      "            type: GlobalAveragePooling\n",
      "          data_preprocessor:\n",
      "            mean:\n",
      "            - 123.675\n",
      "            - 116.28\n",
      "            - 103.53\n",
      "            std:\n",
      "            - 58.395\n",
      "            - 57.12\n",
      "            - 57.375\n",
      "            to_rgb: true\n",
      "            type: ClsDataPreprocessor\n",
      "          type: ImageClassifier\n",
      "    torch_compile: false\n",
      "    optimizer:\n",
      "      class_path: torch.optim.SGD\n",
      "      init_args:\n",
      "        lr: 0.0058\n",
      "        momentum: 0.9\n",
      "        dampening: 0\n",
      "        weight_decay: 0.0001\n",
      "        nesterov: false\n",
      "        maximize: false\n",
      "        differentiable: false\n",
      "    scheduler:\n",
      "      class_path: lightning.pytorch.cli.ReduceLROnPlateau\n",
      "      init_args:\n",
      "        monitor: train/loss\n",
      "        mode: min\n",
      "        factor: 0.5\n",
      "        patience: 1\n",
      "        threshold: 0.0001\n",
      "        threshold_mode: rel\n",
      "        cooldown: 0\n",
      "        min_lr: 0\n",
      "        eps: 1.0e-08\n",
      "        verbose: false\n"
     ]
    }
   ],
   "source": [
    "\"\"\"CLI Example\"\"\"\n",
    "\n",
    "! otx train --config src/configs/classification_default.yaml --data.config.data_root tests/assets/classification_dataset --model.otx_model.config.head.num_classes 2 --print_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! otx train --config src/configs/classification_default.yaml --data.config.data_root tests/assets/classification_dataset --model.otx_model.config.head.num_classes 2 --print_config > test_config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/repo/otx-fork/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: https://github.com/d-li14/mobilenetv3.pytorch/blob/master/pretrained/mobilenetv3-large-1cd25616.pth?raw=true\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: classifier.0.weight, classifier.0.bias, classifier.3.weight, classifier.3.bias\n",
      "\n",
      "init weight - https://github.com/d-li14/mobilenetv3.pytorch/blob/master/pretrained/mobilenetv3-large-1cd25616.pth?raw=true\n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.0.0.weight - torch.Size([16, 3, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.0.1.weight - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.0.1.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.1.conv.0.weight - torch.Size([16, 1, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.1.conv.1.weight - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.1.conv.1.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.1.conv.4.weight - torch.Size([16, 16, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.1.conv.5.weight - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.1.conv.5.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.2.conv.0.weight - torch.Size([64, 16, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.2.conv.1.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.2.conv.1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.2.conv.3.weight - torch.Size([64, 1, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.2.conv.4.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.2.conv.4.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.2.conv.7.weight - torch.Size([24, 64, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.2.conv.8.weight - torch.Size([24]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.2.conv.8.bias - torch.Size([24]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.3.conv.0.weight - torch.Size([72, 24, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.3.conv.1.weight - torch.Size([72]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.3.conv.1.bias - torch.Size([72]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.3.conv.3.weight - torch.Size([72, 1, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.3.conv.4.weight - torch.Size([72]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.3.conv.4.bias - torch.Size([72]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.3.conv.7.weight - torch.Size([24, 72, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.3.conv.8.weight - torch.Size([24]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.3.conv.8.bias - torch.Size([24]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.4.conv.0.weight - torch.Size([72, 24, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.4.conv.1.weight - torch.Size([72]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.4.conv.1.bias - torch.Size([72]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.4.conv.3.weight - torch.Size([72, 1, 5, 5]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.4.conv.4.weight - torch.Size([72]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.4.conv.4.bias - torch.Size([72]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.4.conv.5.fc.0.weight - torch.Size([24, 72]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.4.conv.5.fc.0.bias - torch.Size([24]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.4.conv.5.fc.2.weight - torch.Size([72, 24]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.4.conv.5.fc.2.bias - torch.Size([72]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.4.conv.7.weight - torch.Size([40, 72, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.4.conv.8.weight - torch.Size([40]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.4.conv.8.bias - torch.Size([40]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.5.conv.0.weight - torch.Size([120, 40, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.5.conv.1.weight - torch.Size([120]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.5.conv.1.bias - torch.Size([120]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.5.conv.3.weight - torch.Size([120, 1, 5, 5]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.5.conv.4.weight - torch.Size([120]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.5.conv.4.bias - torch.Size([120]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.5.conv.5.fc.0.weight - torch.Size([32, 120]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.5.conv.5.fc.0.bias - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.5.conv.5.fc.2.weight - torch.Size([120, 32]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.5.conv.5.fc.2.bias - torch.Size([120]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.5.conv.7.weight - torch.Size([40, 120, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.5.conv.8.weight - torch.Size([40]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.5.conv.8.bias - torch.Size([40]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.6.conv.0.weight - torch.Size([120, 40, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.6.conv.1.weight - torch.Size([120]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.6.conv.1.bias - torch.Size([120]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.6.conv.3.weight - torch.Size([120, 1, 5, 5]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.6.conv.4.weight - torch.Size([120]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.6.conv.4.bias - torch.Size([120]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.6.conv.5.fc.0.weight - torch.Size([32, 120]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.6.conv.5.fc.0.bias - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.6.conv.5.fc.2.weight - torch.Size([120, 32]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.6.conv.5.fc.2.bias - torch.Size([120]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.6.conv.7.weight - torch.Size([40, 120, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.6.conv.8.weight - torch.Size([40]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.6.conv.8.bias - torch.Size([40]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.7.conv.0.weight - torch.Size([240, 40, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.7.conv.1.weight - torch.Size([240]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.7.conv.1.bias - torch.Size([240]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.7.conv.3.weight - torch.Size([240, 1, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.7.conv.4.weight - torch.Size([240]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.7.conv.4.bias - torch.Size([240]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.7.conv.7.weight - torch.Size([80, 240, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.7.conv.8.weight - torch.Size([80]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.7.conv.8.bias - torch.Size([80]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.8.conv.0.weight - torch.Size([200, 80, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.8.conv.1.weight - torch.Size([200]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.8.conv.1.bias - torch.Size([200]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.8.conv.3.weight - torch.Size([200, 1, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.8.conv.4.weight - torch.Size([200]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.8.conv.4.bias - torch.Size([200]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.8.conv.7.weight - torch.Size([80, 200, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.8.conv.8.weight - torch.Size([80]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.8.conv.8.bias - torch.Size([80]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.9.conv.0.weight - torch.Size([184, 80, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.9.conv.1.weight - torch.Size([184]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.9.conv.1.bias - torch.Size([184]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.9.conv.3.weight - torch.Size([184, 1, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.9.conv.4.weight - torch.Size([184]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.9.conv.4.bias - torch.Size([184]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.9.conv.7.weight - torch.Size([80, 184, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.9.conv.8.weight - torch.Size([80]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.9.conv.8.bias - torch.Size([80]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.10.conv.0.weight - torch.Size([184, 80, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.10.conv.1.weight - torch.Size([184]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.10.conv.1.bias - torch.Size([184]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.10.conv.3.weight - torch.Size([184, 1, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.10.conv.4.weight - torch.Size([184]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.10.conv.4.bias - torch.Size([184]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.10.conv.7.weight - torch.Size([80, 184, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.10.conv.8.weight - torch.Size([80]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.10.conv.8.bias - torch.Size([80]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.11.conv.0.weight - torch.Size([480, 80, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.11.conv.1.weight - torch.Size([480]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.11.conv.1.bias - torch.Size([480]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.11.conv.3.weight - torch.Size([480, 1, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.11.conv.4.weight - torch.Size([480]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.11.conv.4.bias - torch.Size([480]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.11.conv.5.fc.0.weight - torch.Size([120, 480]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.11.conv.5.fc.0.bias - torch.Size([120]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.11.conv.5.fc.2.weight - torch.Size([480, 120]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.11.conv.5.fc.2.bias - torch.Size([480]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.11.conv.7.weight - torch.Size([112, 480, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.11.conv.8.weight - torch.Size([112]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.11.conv.8.bias - torch.Size([112]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.12.conv.0.weight - torch.Size([672, 112, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.12.conv.1.weight - torch.Size([672]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.12.conv.1.bias - torch.Size([672]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.12.conv.3.weight - torch.Size([672, 1, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.12.conv.4.weight - torch.Size([672]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.12.conv.4.bias - torch.Size([672]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.12.conv.5.fc.0.weight - torch.Size([168, 672]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.12.conv.5.fc.0.bias - torch.Size([168]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.12.conv.5.fc.2.weight - torch.Size([672, 168]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.12.conv.5.fc.2.bias - torch.Size([672]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.12.conv.7.weight - torch.Size([112, 672, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.12.conv.8.weight - torch.Size([112]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.12.conv.8.bias - torch.Size([112]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.13.conv.0.weight - torch.Size([672, 112, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.13.conv.1.weight - torch.Size([672]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.13.conv.1.bias - torch.Size([672]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.13.conv.3.weight - torch.Size([672, 1, 5, 5]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.13.conv.4.weight - torch.Size([672]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.13.conv.4.bias - torch.Size([672]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.13.conv.5.fc.0.weight - torch.Size([168, 672]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.13.conv.5.fc.0.bias - torch.Size([168]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.13.conv.5.fc.2.weight - torch.Size([672, 168]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.13.conv.5.fc.2.bias - torch.Size([672]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.13.conv.7.weight - torch.Size([160, 672, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.13.conv.8.weight - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.13.conv.8.bias - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.14.conv.0.weight - torch.Size([960, 160, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.14.conv.1.weight - torch.Size([960]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.14.conv.1.bias - torch.Size([960]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.14.conv.3.weight - torch.Size([960, 1, 5, 5]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.14.conv.4.weight - torch.Size([960]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.14.conv.4.bias - torch.Size([960]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.14.conv.5.fc.0.weight - torch.Size([240, 960]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.14.conv.5.fc.0.bias - torch.Size([240]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.14.conv.5.fc.2.weight - torch.Size([960, 240]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.14.conv.5.fc.2.bias - torch.Size([960]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.14.conv.7.weight - torch.Size([160, 960, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.14.conv.8.weight - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.14.conv.8.bias - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.15.conv.0.weight - torch.Size([960, 160, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.15.conv.1.weight - torch.Size([960]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.15.conv.1.bias - torch.Size([960]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.15.conv.3.weight - torch.Size([960, 1, 5, 5]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.15.conv.4.weight - torch.Size([960]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.15.conv.4.bias - torch.Size([960]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.15.conv.5.fc.0.weight - torch.Size([240, 960]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.15.conv.5.fc.0.bias - torch.Size([240]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.15.conv.5.fc.2.weight - torch.Size([960, 240]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.15.conv.5.fc.2.bias - torch.Size([960]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.15.conv.7.weight - torch.Size([160, 960, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.15.conv.8.weight - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.15.conv.8.bias - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.conv.0.weight - torch.Size([960, 160, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.conv.1.weight - torch.Size([960]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.conv.1.bias - torch.Size([960]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "head.layers.0.fc.weight - torch.Size([1280, 960]): \n",
      "NormalInit: mean=0.0, std=0.01, bias=0.0 \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "head.layers.0.fc.bias - torch.Size([1280]): \n",
      "NormalInit: mean=0.0, std=0.01, bias=0.0 \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "head.layers.1.fc.weight - torch.Size([2, 1280]): \n",
      "NormalInit: mean=0.0, std=0.01, bias=0.0 \n",
      " \n",
      "12/15 16:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "head.layers.1.fc.bias - torch.Size([2]): \n",
      "NormalInit: mean=0.0, std=0.01, bias=0.0 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:otx.core.engine.utils.instantiators:No logger configs found! Skipping...\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1)` was configured so validation will run after every batch.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/harimkan/workspace/repo/otx-fork/venv/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:639: Checkpoint directory /home/harimkan/workspace/repo/otx-fork/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name        </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>\n",
       "\n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span> model        MMPretrainCompatibleModel   4.2 M \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span> val_metric   MulticlassAccuracy              0 \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span> test_metric  MulticlassAccuracy              0 \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mName       \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m\n",
       "\n",
       "\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m model        MMPretrainCompatibleModel   4.2 M \n",
       "\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m val_metric   MulticlassAccuracy              0 \n",
       "\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m test_metric  MulticlassAccuracy              0 \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 4.2 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 4.2 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 16                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 4.2 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 4.2 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 16                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/harimkan/workspace/repo/otx-fork/venv/lib/python3.10/site-packages/rich/live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/harimkan/workspace/repo/otx-fork/venv/lib/python3.10/site-packages/rich/live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'train/loss': tensor(0.5327), 'val/accuracy': tensor(0.9200)}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"API Example with Config file.\"\"\"\n",
    "\n",
    "from otx.core.data.module import OTXDataModule\n",
    "from otx.core.engine.engine import Engine\n",
    "from otx.core.model.module.classification import OTXClassificationLitModule\n",
    "\n",
    "config_file = \"test_config.yaml\"\n",
    "\n",
    "model = OTXClassificationLitModule.from_config(config=config_file)\n",
    "datamodule = OTXDataModule.from_config(task=\"MULTI_CLASS_CLS\", config=config_file)\n",
    "\n",
    "engine = Engine.from_config(config=config_file)\n",
    "engine.train(model=model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "import torch\n",
    "from otx.core.data.entity.base import OTXBatchLossEntity\n",
    "from otx.core.data.entity.classification import (\n",
    "    MulticlassClsBatchDataEntity,\n",
    "    MulticlassClsBatchPredEntity,\n",
    ")\n",
    "from otx.core.model.entity.classification import OTXClassificationModel\n",
    "from torch import nn\n",
    "from torchvision.models.resnet import ResNet50_Weights, resnet50\n",
    "\n",
    "\n",
    "class ResNet50WithLossComputation(nn.Module):\n",
    "    def __init__(self, num_classes: int) -> None:\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        net = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "        net.fc = nn.Linear(\n",
    "            in_features=net.fc.in_features, out_features=self.num_classes\n",
    "        )\n",
    "        self.net = net\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, images: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "        logits = self.net(images)\n",
    "\n",
    "        if self.training:\n",
    "            return self.criterion(logits, labels)\n",
    "\n",
    "        return self.softmax(logits)\n",
    "\n",
    "\n",
    "class OTXResNet50(OTXClassificationModel):\n",
    "    def __init__(self, num_classes: int) -> None:\n",
    "        self.num_classes = num_classes\n",
    "        super().__init__()\n",
    "        self.register_buffer(\n",
    "            \"mean\",\n",
    "            torch.FloatTensor([123.675, 116.28, 103.53]).view(-1, 1, 1),\n",
    "            False,\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"std\",\n",
    "            torch.FloatTensor([58.395, 57.12, 57.375]).view(-1, 1, 1),\n",
    "            False,\n",
    "        )\n",
    "\n",
    "    def _create_model(self) -> nn.Module:\n",
    "        # ResNet50_Weights.IMAGENET1K_V2 is a really powerful pretrained model equipped with the modern training scheme:\n",
    "        # ImageNet-1K acc@1: 80.858, acc@5\": 95.434.\n",
    "        return ResNet50WithLossComputation(num_classes=self.num_classes)\n",
    "\n",
    "    def _customize_inputs(self, inputs: MulticlassClsBatchDataEntity) -> dict[str, Any]:\n",
    "        images = torch.stack(inputs.images, dim=0).to(dtype=torch.float32)\n",
    "        images = (images - self.mean) / self.std\n",
    "        return {\n",
    "            \"images\": images,\n",
    "            \"labels\": torch.cat(inputs.labels, dim=0),\n",
    "        }\n",
    "\n",
    "    def _customize_outputs(\n",
    "        self, outputs: Any, inputs: MulticlassClsBatchDataEntity\n",
    "    ) -> MulticlassClsBatchPredEntity | OTXBatchLossEntity:\n",
    "        if self.training:\n",
    "            return {\"loss\": outputs}\n",
    "\n",
    "        # To list, batch-wise\n",
    "        scores = torch.unbind(outputs, 0)\n",
    "\n",
    "        return MulticlassClsBatchPredEntity(\n",
    "            batch_size=inputs.batch_size,\n",
    "            images=inputs.images,\n",
    "            imgs_info=inputs.imgs_info,\n",
    "            scores=scores,\n",
    "            labels=inputs.labels,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1)` was configured so validation will run after every batch.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type               | Params\n",
      "---------------------------------------------------\n",
      "0 | model       | OTXResNet50        | 23.5 M\n",
      "1 | val_metric  | MulticlassAccuracy | 0     \n",
      "2 | test_metric | MulticlassAccuracy | 0     \n",
      "---------------------------------------------------\n",
      "23.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/repo/otx-fork/venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|| 1/1 [00:00<00:00,  8.17it/s, v_num=56, train/loss=0.595, val/accuracy=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|| 1/1 [00:00<00:00,  2.89it/s, v_num=56, train/loss=0.595, val/accuracy=1.000]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train/loss': tensor(0.5950), 'val/accuracy': tensor(1.)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from otx.core.engine.engine import Engine\n",
    "\n",
    "engine = Engine(max_epochs=5)\n",
    "\n",
    "model.model=OTXResNet50(num_classes=2)\n",
    "engine.train(model=model, datamodule=datamodule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-test-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
