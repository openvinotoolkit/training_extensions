{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"/home/harimkan/workspace/repo/otx-regression/data/CVPR_demo_datumaro_seed0\"\n",
    "work_dir = \"./otx-workspace-ins_seg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with OTX Recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/repo/otx-regression/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                    OTX Recipes                                                    </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Task                  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Model Name                    </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Recipe Path                                             </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ INSTANCE_SEGMENTATION │ openvino_model                │ /home/harimkan/workspace/repo/otx-regression/src/otx/r… │\n",
       "│                       │                               │ pe/instance_segmentation/openvino_model.yaml            │\n",
       "│ INSTANCE_SEGMENTATION │ maskrcnn_r50                  │ /home/harimkan/workspace/repo/otx-regression/src/otx/r… │\n",
       "│                       │                               │ pe/instance_segmentation/maskrcnn_r50.yaml              │\n",
       "│ INSTANCE_SEGMENTATION │ maskrcnn_r50_tile             │ /home/harimkan/workspace/repo/otx-regression/src/otx/r… │\n",
       "│                       │                               │ pe/instance_segmentation/maskrcnn_r50_tile.yaml         │\n",
       "│ INSTANCE_SEGMENTATION │ maskrcnn_swint                │ /home/harimkan/workspace/repo/otx-regression/src/otx/r… │\n",
       "│                       │                               │ pe/instance_segmentation/maskrcnn_swint.yaml            │\n",
       "│ INSTANCE_SEGMENTATION │ maskrcnn_efficientnetb2b      │ /home/harimkan/workspace/repo/otx-regression/src/otx/r… │\n",
       "│                       │                               │ pe/instance_segmentation/maskrcnn_efficientnetb2b.yaml  │\n",
       "│ INSTANCE_SEGMENTATION │ rtmdet_inst_tiny              │ /home/harimkan/workspace/repo/otx-regression/src/otx/r… │\n",
       "│                       │                               │ pe/instance_segmentation/rtmdet_inst_tiny.yaml          │\n",
       "│ INSTANCE_SEGMENTATION │ maskrcnn_efficientnetb2b_tile │ /home/harimkan/workspace/repo/otx-regression/src/otx/r… │\n",
       "│                       │                               │ pe/instance_segmentation/maskrcnn_efficientnetb2b_tile… │\n",
       "│                       │                               │ ml                                                      │\n",
       "│ INSTANCE_SEGMENTATION │ rtmdet_inst_tiny_tile         │ /home/harimkan/workspace/repo/otx-regression/src/otx/r… │\n",
       "│                       │                               │ pe/instance_segmentation/rtmdet_inst_tiny_tile.yaml     │\n",
       "│ INSTANCE_SEGMENTATION │ maskrcnn_swint_tile           │ /home/harimkan/workspace/repo/otx-regression/src/otx/r… │\n",
       "│                       │                               │ pe/instance_segmentation/maskrcnn_swint_tile.yaml       │\n",
       "└───────────────────────┴───────────────────────────────┴─────────────────────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                    OTX Recipes                                                    \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35mTask                 \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mModel Name                   \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mRecipe Path                                            \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ INSTANCE_SEGMENTATION │ openvino_model                │ /home/harimkan/workspace/repo/otx-regression/src/otx/r… │\n",
       "│                       │                               │ pe/instance_segmentation/openvino_model.yaml            │\n",
       "│ INSTANCE_SEGMENTATION │ maskrcnn_r50                  │ /home/harimkan/workspace/repo/otx-regression/src/otx/r… │\n",
       "│                       │                               │ pe/instance_segmentation/maskrcnn_r50.yaml              │\n",
       "│ INSTANCE_SEGMENTATION │ maskrcnn_r50_tile             │ /home/harimkan/workspace/repo/otx-regression/src/otx/r… │\n",
       "│                       │                               │ pe/instance_segmentation/maskrcnn_r50_tile.yaml         │\n",
       "│ INSTANCE_SEGMENTATION │ maskrcnn_swint                │ /home/harimkan/workspace/repo/otx-regression/src/otx/r… │\n",
       "│                       │                               │ pe/instance_segmentation/maskrcnn_swint.yaml            │\n",
       "│ INSTANCE_SEGMENTATION │ maskrcnn_efficientnetb2b      │ /home/harimkan/workspace/repo/otx-regression/src/otx/r… │\n",
       "│                       │                               │ pe/instance_segmentation/maskrcnn_efficientnetb2b.yaml  │\n",
       "│ INSTANCE_SEGMENTATION │ rtmdet_inst_tiny              │ /home/harimkan/workspace/repo/otx-regression/src/otx/r… │\n",
       "│                       │                               │ pe/instance_segmentation/rtmdet_inst_tiny.yaml          │\n",
       "│ INSTANCE_SEGMENTATION │ maskrcnn_efficientnetb2b_tile │ /home/harimkan/workspace/repo/otx-regression/src/otx/r… │\n",
       "│                       │                               │ pe/instance_segmentation/maskrcnn_efficientnetb2b_tile… │\n",
       "│                       │                               │ ml                                                      │\n",
       "│ INSTANCE_SEGMENTATION │ rtmdet_inst_tiny_tile         │ /home/harimkan/workspace/repo/otx-regression/src/otx/r… │\n",
       "│                       │                               │ pe/instance_segmentation/rtmdet_inst_tiny_tile.yaml     │\n",
       "│ INSTANCE_SEGMENTATION │ maskrcnn_swint_tile           │ /home/harimkan/workspace/repo/otx-regression/src/otx/r… │\n",
       "│                       │                               │ pe/instance_segmentation/maskrcnn_swint_tile.yaml       │\n",
       "└───────────────────────┴───────────────────────────────┴─────────────────────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['maskrcnn_r50_tile',\n",
       " 'maskrcnn_efficientnetb2b_tile',\n",
       " 'rtmdet_inst_tiny_tile',\n",
       " 'maskrcnn_swint_tile',\n",
       " 'maskrcnn_efficientnetb2b',\n",
       " 'openvino_model',\n",
       " 'rtmdet_inst_tiny',\n",
       " 'maskrcnn_swint',\n",
       " 'maskrcnn_r50']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from otx.engine.utils.api import list_models\n",
    "\n",
    "list_models(task=\"INSTANCE_SEGMENTATION\", print_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/repo/otx-regression/src/otx/core/data/module.py:62: UserWarning: There are empty annotation items in train set, Of these, only 0.0% are used.\n",
      "  dataset = pre_filtering(dataset, self.config.data_format, self.config.unannotated_items_ratio)\n",
      "/home/harimkan/workspace/repo/otx-regression/src/otx/cli/cli.py:389: UserWarning: Automatically infer label_info from the given dataset. Then, giving it to the OTXModel.__init__() argument. If you don't want this behavior, please use `--disable-infer-num-classes` option.\n",
      "  warn(warning_msg, stacklevel=0)\n",
      "/home/harimkan/workspace/repo/otx-regression/src/otx/algo/utils/mmengine_utils.py:183: UserWarning: The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for roi_head.bbox_head.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([11, 1024]).\n",
      "size mismatch for roi_head.bbox_head.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([11]).\n",
      "size mismatch for roi_head.bbox_head.fc_reg.weight: copying a param with shape torch.Size([320, 1024]) from checkpoint, the shape in current model is torch.Size([40, 1024]).\n",
      "size mismatch for roi_head.bbox_head.fc_reg.bias: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([40]).\n",
      "size mismatch for roi_head.mask_head.conv_logits.weight: copying a param with shape torch.Size([80, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([10, 256, 1, 1]).\n",
      "size mismatch for roi_head.mask_head.conv_logits.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([10]).\n",
      "  warn(\"\\n\".join(err_msg), stacklevel=1)\n",
      "/home/harimkan/workspace/repo/otx-regression/src/otx/engine/engine.py:767: UserWarning: Warning: ['resume', 'run_hpo', 'hpo_config', 'adaptive_bs'] -> not available in Engine constructor. It will be ignored. Use what need in the right places.\n",
      "  warn(msg, stacklevel=1)\n",
      "WARNING:root:Assign new label_info to the model. It is usually not recommended. Please create a new model instance by giving label_info to its initializer such as `OTXModel(label_info=label_info, ...)`.\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: /home/harimkan/workspace/repo/otx-regression/notebooks/otx-workspace-ins_seg/csv/\n",
      "/home/harimkan/workspace/repo/otx-regression/venv/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:639: Checkpoint directory /home/harimkan/workspace/repo/otx-regression/notebooks/otx-workspace-ins_seg exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━┳━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type     </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━╇━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ model │ MaskRCNN │ 44.0 M │\n",
       "└───┴───────┴──────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━┳━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType    \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━╇━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ model │ MaskRCNN │ 44.0 M │\n",
       "└───┴───────┴──────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 43.8 M                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 225 K                                                                                        \n",
       "<span style=\"font-weight: bold\">Total params</span>: 44.0 M                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 176                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 43.8 M                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 225 K                                                                                        \n",
       "\u001b[1mTotal params\u001b[0m: 44.0 M                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 176                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/harimkan/workspace/repo/otx-regression/venv/lib/python3.10/site-packages/rich/live.py:231: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/harimkan/workspace/repo/otx-regression/venv/lib/python3.10/site-packages/rich/live.py:231: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/repo/otx-regression/venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:294: The number of training batches (25) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "WARNING:root:You are using AdaptiveTrainScheduling hook. This hook will temporarily update Trainer.check_val_every_n_epoch adaptively: 1 => 3\n",
      "WARNING:root:The patience of early stopping will be changed due to the effect of adaptive interval: 10 --> 3.\n",
      "WARNING:root:The frequency of LRscheduler will be changed due to the effect of adaptive interval: 1 --> 3.\n",
      "WARNING:root:The patience of LRscheduler will be changed due to the effect of adaptive interval: 4 --> 1.\n",
      "WARNING:root:Trainer.log_every_n_steps is higher than the number of iterations in a training epoch. To ensure logging at the last batch, temporarily update Trainer.log_every_n_steps: 50 => 25\n",
      "/home/harimkan/workspace/repo/otx-regression/src/otx/core/data/entity/base.py:591: UserWarning: You set stack_images as True, but not all images in the batch has same shape. In this case, we cannot stack images. Some tasks, e.g., detection, can have different image shapes among samples in the batch. However, if it is not your intention, consider setting stack_images as False in the config.\n",
      "  warnings.warn(msg, stacklevel=1)\n",
      "/home/harimkan/workspace/repo/otx-regression/src/otx/core/data/entity/base.py:591: UserWarning: You set stack_images as True, but not all images in the batch has same shape. In this case, we cannot stack images. Some tasks, e.g., detection, can have different image shapes among samples in the batch. However, if it is not your intention, consider setting stack_images as False in the config.\n",
      "  warnings.warn(msg, stacklevel=1)\n",
      "/home/harimkan/workspace/repo/otx-regression/src/otx/core/data/entity/base.py:591: UserWarning: You set stack_images as True, but not all images in the batch has same shape. In this case, we cannot stack images. Some tasks, e.g., detection, can have different image shapes among samples in the batch. However, if it is not your intention, consider setting stack_images as False in the config.\n",
      "  warnings.warn(msg, stacklevel=1)\n",
      "/home/harimkan/workspace/repo/otx-regression/src/otx/core/data/entity/base.py:591: UserWarning: You set stack_images as True, but not all images in the batch has same shape. In this case, we cannot stack images. Some tasks, e.g., detection, can have different image shapes among samples in the batch. However, if it is not your intention, consider setting stack_images as False in the config.\n",
      "  warnings.warn(msg, stacklevel=1)\n",
      "/home/harimkan/workspace/repo/otx-regression/src/otx/core/data/entity/base.py:591: UserWarning: You set stack_images as True, but not all images in the batch has same shape. In this case, we cannot stack images. Some tasks, e.g., detection, can have different image shapes among samples in the batch. However, if it is not your intention, consider setting stack_images as False in the config.\n",
      "  warnings.warn(msg, stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/harimkan/workspace/repo/otx-regression/src/otx/core/model/base.py:348: UserWarning: Log metric \n",
       "name=val/classes is not a scalar tensor. Skip logging it.\n",
       "  warnings.warn(msg, stacklevel=1)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/harimkan/workspace/repo/otx-regression/src/otx/core/model/base.py:348: UserWarning: Log metric \n",
       "name=val/classes is not a scalar tensor. Skip logging it.\n",
       "  warnings.warn(msg, stacklevel=1)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/repo/otx-regression/src/otx/core/data/entity/base.py:591: UserWarning: You set stack_images as True, but not all images in the batch has same shape. In this case, we cannot stack images. Some tasks, e.g., detection, can have different image shapes among samples in the batch. However, if it is not your intention, consider setting stack_images as False in the config.\n",
      "  warnings.warn(msg, stacklevel=1)\n",
      "/home/harimkan/workspace/repo/otx-regression/src/otx/core/data/entity/base.py:591: UserWarning: You set stack_images as True, but not all images in the batch has same shape. In this case, we cannot stack images. Some tasks, e.g., detection, can have different image shapes among samples in the batch. However, if it is not your intention, consider setting stack_images as False in the config.\n",
      "  warnings.warn(msg, stacklevel=1)\n",
      "/home/harimkan/workspace/repo/otx-regression/src/otx/core/data/entity/base.py:591: UserWarning: You set stack_images as True, but not all images in the batch has same shape. In this case, we cannot stack images. Some tasks, e.g., detection, can have different image shapes among samples in the batch. However, if it is not your intention, consider setting stack_images as False in the config.\n",
      "  warnings.warn(msg, stacklevel=1)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'lr-SGD': tensor(0.0070),\n",
       " 'lr-SGD-momentum': tensor(0.9000),\n",
       " 'lr-SGD-1': tensor(0.0070),\n",
       " 'lr-SGD-1-momentum': tensor(0.9000),\n",
       " 'train/loss_rpn_cls': tensor(0.0010),\n",
       " 'train/loss_rpn_bbox': tensor(0.0157),\n",
       " 'train/loss_cls': tensor(0.0217),\n",
       " 'train/loss_bbox': tensor(0.0853),\n",
       " 'train/loss_mask': tensor(0.0377),\n",
       " 'train/loss': tensor(0.1615),\n",
       " 'train/data_time': tensor(0.0062),\n",
       " 'train/iter_time': tensor(0.3375),\n",
       " 'validation/data_time': tensor(0.0016),\n",
       " 'validation/iter_time': tensor(0.0397),\n",
       " 'val/map': tensor(0.9810),\n",
       " 'val/map_50': tensor(0.9987),\n",
       " 'val/map_75': tensor(0.9987),\n",
       " 'val/map_small': tensor(-1.),\n",
       " 'val/map_medium': tensor(0.9860),\n",
       " 'val/map_large': tensor(0.9786),\n",
       " 'val/mar_1': tensor(0.5892),\n",
       " 'val/mar_10': tensor(0.9866),\n",
       " 'val/mar_100': tensor(0.9876),\n",
       " 'val/mar_small': tensor(-1.),\n",
       " 'val/mar_medium': tensor(0.9923),\n",
       " 'val/mar_large': tensor(0.9856),\n",
       " 'val/map_per_class': tensor(-1.),\n",
       " 'val/mar_100_per_class': tensor(-1.)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from otx.engine import Engine\n",
    "\n",
    "recipe = \"/home/harimkan/workspace/repo/otx-regression/src/otx/recipe/instance_segmentation/maskrcnn_r50.yaml\"\n",
    "override_dataset_format = {\"data.config.data_format\": \"datumaro\"}\n",
    "\n",
    "engine = Engine.from_config(config_path=recipe, data_root=data_root, work_dir=work_dir, **override_dataset_format)\n",
    "engine.train(max_epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate torch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Assign new tile_config to the model. It is usually not recommended. Please create a new model instance by giving tile_config to its initializer such as `OTXModel(..., tile_config=tile_config)`.\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/harimkan/workspace/repo/otx-regression/src/otx/core/model/base.py:348: UserWarning: Log metric \n",
       "name=test/classes is not a scalar tensor. Skip logging it.\n",
       "  warnings.warn(msg, stacklevel=1)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/harimkan/workspace/repo/otx-regression/src/otx/core/model/base.py:348: UserWarning: Log metric \n",
       "name=test/classes is not a scalar tensor. Skip logging it.\n",
       "  warnings.warn(msg, stacklevel=1)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test/data_time       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.0016520064091309905   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test/iter_time       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04141007363796234    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/map          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.921884298324585     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test/map_50        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9759804606437683     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test/map_75        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.967104434967041     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test/map_large       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9041756987571716     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test/map_medium      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9886666536331177     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    test/map_per_class     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           -1.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test/map_small       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test/mar_1         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5272409915924072     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test/mar_10        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9404076933860779     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test/mar_100        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9418891668319702     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test/mar_100_per_class   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           -1.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test/mar_large       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9313591122627258     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test/mar_medium      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9946836233139038     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test/mar_small       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test/data_time      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0016520064091309905  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test/iter_time      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04141007363796234   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test/map         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.921884298324585    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test/map_50       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9759804606437683    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test/map_75       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.967104434967041    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test/map_large      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9041756987571716    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test/map_medium     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9886666536331177    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   test/map_per_class    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          -1.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test/map_small      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test/mar_1        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5272409915924072    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test/mar_10       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9404076933860779    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test/mar_100       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9418891668319702    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test/mar_100_per_class  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          -1.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test/mar_large      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9313591122627258    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test/mar_medium     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9946836233139038    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test/mar_small      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test/data_time': tensor(0.0017),\n",
       " 'test/iter_time': tensor(0.0414),\n",
       " 'test/map': tensor(0.9219),\n",
       " 'test/map_50': tensor(0.9760),\n",
       " 'test/map_75': tensor(0.9671),\n",
       " 'test/map_small': tensor(0.),\n",
       " 'test/map_medium': tensor(0.9887),\n",
       " 'test/map_large': tensor(0.9042),\n",
       " 'test/mar_1': tensor(0.5272),\n",
       " 'test/mar_10': tensor(0.9404),\n",
       " 'test/mar_100': tensor(0.9419),\n",
       " 'test/mar_small': tensor(0.),\n",
       " 'test/mar_medium': tensor(0.9947),\n",
       " 'test/mar_large': tensor(0.9314),\n",
       " 'test/map_per_class': tensor(-1.),\n",
       " 'test/mar_100_per_class': tensor(-1.)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to IR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Assign new tile_config to the model. It is usually not recommended. Please create a new model instance by giving tile_config to its initializer such as `OTXModel(..., tile_config=tile_config)`.\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/harimkan/workspace/repo/otx-regression/src/otx/algo/instance_segmentation/maskrcnn.py:244: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  shape = (int(inputs.shape[2]), int(inputs.shape[3]))\n",
      "/home/harimkan/workspace/repo/otx-regression/src/otx/algo/instance_segmentation/maskrcnn.py:251: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.\n",
      "  meta_info_list = [meta_info] * len(inputs)\n",
      "/home/harimkan/workspace/repo/otx-regression/src/otx/algo/detection/heads/base_head.py:461: UserWarning: score_factors: None is not used in RPNHead.export\n",
      "  return self.export_by_feat(*outs, batch_img_metas=batch_img_metas, rescale=rescale)  # type: ignore[misc]\n",
      "/home/harimkan/workspace/repo/otx-regression/src/otx/algo/detection/heads/base_head.py:461: UserWarning: rescale: False is not used in RPNHead.export\n",
      "  return self.export_by_feat(*outs, batch_img_metas=batch_img_metas, rescale=rescale)  # type: ignore[misc]\n",
      "/home/harimkan/workspace/repo/otx-regression/src/otx/algo/instance_segmentation/mmdet/models/dense_heads/rpn_head.py:405: UserWarning: DeprecationWarning: anchor_generator is deprecated, please use `prior_generator` instead\n",
      "  mlvl_anchors = self.anchor_generator.grid_anchors(featmap_sizes, device=device)\n",
      "/home/harimkan/workspace/repo/otx-regression/src/otx/algo/instance_segmentation/mmdet/models/dense_heads/rpn_head.py:405: UserWarning: ``grid_anchors`` would be deprecated soon. Please use ``grid_priors`` \n",
      "  mlvl_anchors = self.anchor_generator.grid_anchors(featmap_sizes, device=device)\n",
      "/home/harimkan/workspace/repo/otx-regression/src/otx/algo/detection/heads/anchor_generator.py:337: UserWarning: ``single_level_grid_anchors`` would be deprecated soon. Please use ``single_level_grid_priors`` \n",
      "  anchors = self.single_level_grid_anchors(\n",
      "/home/harimkan/workspace/repo/otx-regression/src/otx/algo/instance_segmentation/mmdet/models/dense_heads/rpn_head.py:435: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if cls_score.size()[-2:] != bbox_pred.size()[-2:]:\n",
      "/home/harimkan/workspace/repo/otx-regression/src/otx/algo/detection/utils/utils.py:350: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  k = torch.tensor(k, device=input.device, dtype=torch.long)\n",
      "/home/harimkan/workspace/repo/otx-regression/src/otx/algo/detection/ops/nms.py:246: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  iou_threshold = torch.tensor([iou_threshold], dtype=torch.float32)\n",
      "/home/harimkan/workspace/repo/otx-regression/src/otx/algo/detection/ops/nms.py:247: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  score_threshold = torch.tensor([score_threshold], dtype=torch.float32)\n",
      "/home/harimkan/workspace/repo/otx-regression/src/otx/algo/detection/ops/nms.py:381: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  score_threshold = float(score_threshold)\n",
      "/home/harimkan/workspace/repo/otx-regression/src/otx/algo/detection/ops/nms.py:382: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  iou_threshold = float(iou_threshold)\n",
      "/home/harimkan/workspace/repo/otx-regression/src/otx/algo/instance_segmentation/mmdet/models/custom_roi_head.py:391: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  rois_dims = int(rois.shape[-1])\n",
      "/home/harimkan/workspace/repo/otx-regression/src/otx/algo/instance_segmentation/mmdet/models/roi_extractors/single_level_roi_extractor.py:165: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if inds.numel() > 0:\n",
      "/home/harimkan/workspace/repo/otx-regression/venv/lib/python3.10/site-packages/torch/__init__.py:1404: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert condition, message\n",
      "/home/harimkan/workspace/repo/otx-regression/src/otx/algo/instance_segmentation/mmdet/models/custom_roi_head.py:410: UserWarning: rescale: False is not supported in ONNX export. Ignored.\n",
      "  return self.bbox_head.export_by_feat(\n",
      "/home/harimkan/workspace/repo/otx-regression/src/otx/algo/instance_segmentation/mmdet/models/custom_roi_head.py:463: UserWarning: rescale: False is not supported in deploy mode\n",
      "  segm_results: Tensor = self.mask_head.export_by_feat(\n",
      "/home/harimkan/workspace/repo/otx-regression/src/otx/algo/instance_segmentation/mmdet/models/custom_roi_head.py:463: UserWarning: activate_map: False is not supported in deploy mode\n",
      "  segm_results: Tensor = self.mask_head.export_by_feat(\n",
      "/home/harimkan/workspace/repo/otx-regression/venv/lib/python3.10/site-packages/torch/onnx/symbolic_opset9.py:5857: UserWarning: Exporting aten::index operator of advanced indexing in opset 11 is achieved by combination of multiple ONNX operators, including Reshape, Transpose, Concat, and Gather. If indices include negative values, the exported graph will produce incorrect results.\n",
      "  warnings.warn(\n",
      "[W shape_type_inference.cpp:1974] Warning: The shape inference of org.openvinotoolkit::ExperimentalDetectronROIFeatureExtractor type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1974] Warning: The shape inference of org.openvinotoolkit::ExperimentalDetectronROIFeatureExtractor type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/harimkan/workspace/repo/otx-regression/notebooks/otx-workspace-ins_seg/exported_model.xml')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exported_ir_model_path = engine.export()\n",
    "exported_ir_model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate IR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/repo/otx-regression/src/otx/core/utils/build.py:52: UserWarning: Set the default number of OpenVINO inference requests to 8.\n",
      "            You can specify the value in config.\n",
      "  warnings.warn(msg, stacklevel=1)\n",
      "/home/harimkan/workspace/repo/otx-regression/src/otx/engine/engine.py:346: UserWarning: IR model supports inference only on CPU device. The device is changed automatic.\n",
      "  warn(msg, stacklevel=1)\n",
      "WARNING:root:The corresponding keys in config are not used.: ['verbose', 'data_root', 'task', 'seed', 'callback_monitor', 'resume', 'disable_infer_num_classes', 'workspace']\n",
      "/home/harimkan/workspace/repo/otx-regression/src/otx/engine/utils/auto_configurator.py:395: UserWarning: For OpenVINO IR models, Update the following test \n",
      "\t transforms: [{'class_path': 'torchvision.transforms.v2.ToImage'}] \n",
      "\t transform_lib_type: TORCHVISION \n",
      "\t batch_size: 64 \n",
      "And the tiler is disabled.\n",
      "  warn(msg, stacklevel=1)\n",
      "/home/harimkan/workspace/repo/otx-regression/src/otx/core/data/module.py:62: UserWarning: There are empty annotation items in train set, Of these, only 0.0% are used.\n",
      "  dataset = pre_filtering(dataset, self.config.data_format, self.config.unannotated_items_ratio)\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/harimkan/workspace/repo/otx-regression/venv/lib/python3.10/site-packages/lightning/pytorch/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/harimkan/workspace/repo/otx-regression/venv/lib/python3.10/site-packages/rich/live.py:231: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/harimkan/workspace/repo/otx-regression/venv/lib/python3.10/site-packages/rich/live.py:231: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/repo/otx-regression/src/otx/core/data/entity/base.py:591: UserWarning: You set stack_images as True, but not all images in the batch has same shape. In this case, we cannot stack images. Some tasks, e.g., detection, can have different image shapes among samples in the batch. However, if it is not your intention, consider setting stack_images as False in the config.\n",
      "  warnings.warn(msg, stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/harimkan/workspace/repo/otx-regression/src/otx/core/model/base.py:348: UserWarning: Log metric \n",
       "name=test/classes is not a scalar tensor. Skip logging it.\n",
       "  warnings.warn(msg, stacklevel=1)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/harimkan/workspace/repo/otx-regression/src/otx/core/model/base.py:348: UserWarning: Log metric \n",
       "name=test/classes is not a scalar tensor. Skip logging it.\n",
       "  warnings.warn(msg, stacklevel=1)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/map          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9128646850585938     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test/map_50        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9745602607727051     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test/map_75        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.956260621547699     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test/map_large       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8943761587142944     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test/map_medium      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9731736183166504     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    test/map_per_class     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           -1.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test/map_small       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test/mar_1         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5201557278633118     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test/mar_10        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9322426915168762     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test/mar_100        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9337241649627686     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test/mar_100_per_class   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           -1.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test/mar_large       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9246577620506287     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test/mar_medium      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9835118651390076     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test/mar_small       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test/map         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9128646850585938    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test/map_50       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9745602607727051    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test/map_75       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.956260621547699    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test/map_large      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8943761587142944    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test/map_medium     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9731736183166504    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   test/map_per_class    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          -1.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test/map_small      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test/mar_1        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5201557278633118    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test/mar_10       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9322426915168762    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test/mar_100       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9337241649627686    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test/mar_100_per_class  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          -1.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test/mar_large      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9246577620506287    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test/mar_medium     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9835118651390076    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test/mar_small      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test/map': tensor(0.9129),\n",
       " 'test/map_50': tensor(0.9746),\n",
       " 'test/map_75': tensor(0.9563),\n",
       " 'test/map_small': tensor(0.),\n",
       " 'test/map_medium': tensor(0.9732),\n",
       " 'test/map_large': tensor(0.8944),\n",
       " 'test/mar_1': tensor(0.5202),\n",
       " 'test/mar_10': tensor(0.9322),\n",
       " 'test/mar_100': tensor(0.9337),\n",
       " 'test/mar_small': tensor(0.),\n",
       " 'test/mar_medium': tensor(0.9835),\n",
       " 'test/mar_large': tensor(0.9247),\n",
       " 'test/map_per_class': tensor(-1.),\n",
       " 'test/mar_100_per_class': tensor(-1.)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.test(checkpoint=exported_ir_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain torch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Assign new tile_config to the model. It is usually not recommended. Please create a new model instance by giving tile_config to its initializer such as `OTXModel(..., tile_config=tile_config)`.\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/harimkan/workspace/repo/otx-regression/venv/lib/python3.10/site-packages/rich/live.py:231: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/harimkan/workspace/repo/otx-regression/venv/lib/python3.10/site-packages/rich/live.py:231: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/repo/otx-regression/src/otx/core/data/entity/base.py:591: UserWarning: You set stack_images as True, but not all images in the batch has same shape. In this case, we cannot stack images. Some tasks, e.g., detection, can have different image shapes among samples in the batch. However, if it is not your intention, consider setting stack_images as False in the config.\n",
      "  warnings.warn(msg, stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [10, 480, 640] at entry 0 and [10, 792, 1130] at entry 10",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# engine.explain(explain_config=ExplainConfig(postprocess=True), dump=True)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m engine\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdump\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/repo/otx-regression/src/otx/engine/engine.py:693\u001b[0m, in \u001b[0;36mEngine.explain\u001b[0;34m(self, checkpoint, datamodule, explain_config, dump, **kwargs)\u001b[0m\n\u001b[1;32m    689\u001b[0m model\u001b[38;5;241m.\u001b[39mexplain_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_trainer(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 693\u001b[0m predict_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m explain_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     explain_config \u001b[38;5;241m=\u001b[39m ExplainConfig()\n",
      "File \u001b[0;32m~/workspace/repo/otx-regression/venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:864\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[0;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 864\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/repo/otx-regression/venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/workspace/repo/otx-regression/venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:903\u001b[0m, in \u001b[0;36mTrainer._predict_impl\u001b[0;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    900\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn, ckpt_path, model_provided\u001b[38;5;241m=\u001b[39mmodel_provided, model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    902\u001b[0m )\n\u001b[0;32m--> 903\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/repo/otx-regression/venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:989\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 989\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    994\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/workspace/repo/otx-regression/venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1030\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluation_loop\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:\n\u001b[0;32m-> 1030\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m   1032\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n",
      "File \u001b[0;32m~/workspace/repo/otx-regression/venv/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py:182\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/repo/otx-regression/venv/lib/python3.10/site-packages/lightning/pytorch/loops/prediction_loop.py:122\u001b[0m, in \u001b[0;36m_PredictionLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mis_last_batch \u001b[38;5;241m=\u001b[39m data_fetcher\u001b[38;5;241m.\u001b[39mdone\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/repo/otx-regression/venv/lib/python3.10/site-packages/lightning/pytorch/loops/prediction_loop.py:250\u001b[0m, in \u001b[0;36m_PredictionLoop._predict_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;66;03m# configure step_kwargs\u001b[39;00m\n\u001b[1;32m    245\u001b[0m step_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_step\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[1;32m    249\u001b[0m )\n\u001b[0;32m--> 250\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpredict_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m predictions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warning_cache\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict returned None if it was on purpose, ignore this warning...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/workspace/repo/otx-regression/venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:309\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 309\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    312\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/workspace/repo/otx-regression/venv/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py:429\u001b[0m, in \u001b[0;36mStrategy.predict_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 429\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/repo/otx-regression/src/otx/core/model/base.py:227\u001b[0m, in \u001b[0;36mOTXModel.predict_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Step function called during PyTorch Lightning Trainer's predict.\"\"\"\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplain_mode:\n\u001b[0;32m--> 227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_explain\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(inputs\u001b[38;5;241m=\u001b[39mbatch)\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, OTXBatchLossEntity):\n",
      "File \u001b[0;32m~/workspace/repo/otx-regression/src/otx/core/model/instance_segmentation.py:245\u001b[0m, in \u001b[0;36mExplainableOTXInstanceSegModel.forward_explain\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mexplain_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_explain_fn()\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# If customize_inputs is overridden\u001b[39;00m\n\u001b[1;32m    244\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 245\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_explain_inst_seg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_customize_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_customize_inputs \u001b[38;5;241m!=\u001b[39m ExplainableOTXInstanceSegModel\u001b[38;5;241m.\u001b[39m_customize_inputs\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_explain_inst_seg(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, inputs)\n\u001b[1;32m    248\u001b[0m )\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_customize_outputs(outputs, inputs)\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_customize_outputs \u001b[38;5;241m!=\u001b[39m ExplainableOTXInstanceSegModel\u001b[38;5;241m.\u001b[39m_customize_outputs\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    254\u001b[0m )\n",
      "File \u001b[0;32m~/workspace/repo/otx-regression/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/repo/otx-regression/src/otx/core/model/instance_segmentation.py:280\u001b[0m, in \u001b[0;36mExplainableOTXInstanceSegModel._forward_explain_inst_seg\u001b[0;34m(self, entity, mode)\u001b[0m\n\u001b[1;32m    277\u001b[0m     saliency_map \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39muint8)\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(predictions, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(predictions[\u001b[38;5;241m0\u001b[39m], InstanceData):\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;66;03m# Predict case, consists of InstanceData\u001b[39;00m\n\u001b[0;32m--> 280\u001b[0m     saliency_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected predictions type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(predictions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/workspace/repo/otx-regression/src/otx/algo/explain/explain_algo.py:343\u001b[0m, in \u001b[0;36mInstSegExplainAlgo.func\u001b[0;34m(self, predictions, _)\u001b[0m\n\u001b[1;32m    341\u001b[0m     class_averaged_masks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage_and_normalize(prediction, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes)\n\u001b[1;32m    342\u001b[0m     batch_saliency_maps\u001b[38;5;241m.\u001b[39mappend(class_averaged_masks)\n\u001b[0;32m--> 343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_saliency_maps\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [10, 480, 640] at entry 0 and [10, 792, 1130] at entry 10"
     ]
    }
   ],
   "source": [
    "from otx.core.config.explain import ExplainConfig\n",
    "\n",
    "engine.explain(explain_config=ExplainConfig(postprocess=True), dump=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "origin_img = Image.open('/home/harimkan/workspace/repo/otx-regression/data/CVPR_demo_datumaro_seed0/images/test/my_photo-1 - Copy - Copy - Copy.jpg')\n",
    "saliency_map_img = Image.open('/home/harimkan/workspace/repo/otx-regression/notebooks/otx-workspace-ins_seg/saliency_map/my_photo_1___Copy___Copy___Copy_class_0_saliency_map.png')\n",
    "overlay_img = Image.open('/home/harimkan/workspace/repo/otx-regression/notebooks/otx-workspace-ins_seg/saliency_map/my_photo_1___Copy___Copy___Copy_class_0_overlay.png')\n",
    "\n",
    "display(origin_img)\n",
    "display(saliency_map_img)\n",
    "display(overlay_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
