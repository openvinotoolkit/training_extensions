lr_finder:
  enable: False
  mode: TPE
  stop_after: False
  num_epochs: 6
  step: 1e-5
  epochs_warmup: 1
  path_to_savefig: "lr_finder.jpg"
  max_lr: 1e-3
  min_lr: 1e-5
  n_trials: 15

model:
  name: "efficientnetv2_s_21k"
  type: "multihead"
  pretrained: True
  save_all_chkpts: False
  dropout_cls:
    p: 0.15
  export_onnx_opset: 11

custom_datasets:
  roots: ["datasets/coco/train.json", "datasets/coco/val.json"]
  types: ["multihead_classification", "multihead_classification"]

data:
  root: "./"
  height: 224
  width: 224
  norm_mean: [0.5, 0.5, 0.5]
  norm_std: [0.5, 0.5, 0.5]
  save_dir: "experiments/efficientv2"
  workers: 6
  transforms:
    random_flip:
      enable: True
      p: 0.5
    randaugment:
      enable: True
    cutout:
      enable: True
      cutout_factor: 0.3
      p: 0.35

loss:
  name: "softmax,asl"
  softmax:
    s: 1.0
    compute_s: False
  asl:
    gamma_pos: 0.
    gamma_neg: 4.

sampler:
  train_sampler: "RandomSampler"

train:
  optim: "sgd"
  lr: 0.007
  nbd: True
  max_epoch: 60
  weight_decay: 1e-4
  batch_size: 48
  lr_scheduler: "onecycle"
  pct_start: 0.1
  early_stopping: True
  lr_decay_factor: 1000
  deterministic: True
  train_patience: 5
  target_metric: test_acc
  gamma: 0.1
  ema:
    enable: True
    ema_decay: 0.9997
  sam:
    rho: 0.05
    adaptive: False
  mix_precision: False

test:
  batch_size: 64
  evaluate: False
  eval_freq: 1

sc_integration:
  epoch_scale: 3.
  lr_scale: 1.5
