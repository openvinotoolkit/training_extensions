{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTX API Usage for Advanced-API User\n",
    "\n",
    "### Requirements\n",
    "R3. Advanced-level Python API users provide a Dataset, and a model type (str) as input, and OTX provides a workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"../../tests/assets/classification_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/repo/otx-fork/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from otx.engine import Engine\n",
    "\n",
    "engine = Engine(data_root=data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['efficientnet_v2_light',\n",
       " 'efficientnet_b0_light',\n",
       " 'otx_mobilenet_v3_large',\n",
       " 'otx_deit_tiny',\n",
       " 'otx_efficientnet_v2',\n",
       " 'mobilenet_v3_large_light',\n",
       " 'otx_efficientnet_b0',\n",
       " 'otx_dino_v2',\n",
       " 'otx_dino_v2_linear_probe']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init weight - https://github.com/osmr/imgclsmob/releases/download/v0.0.364/efficientnet_b0-0752-0e386130.pth.zip\n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.init_block.conv.conv.weight - torch.Size([32, 3, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.init_block.conv.bn.weight - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.init_block.conv.bn.bias - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage1.unit1.dw_conv.conv.weight - torch.Size([32, 1, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage1.unit1.dw_conv.bn.weight - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage1.unit1.dw_conv.bn.bias - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage1.unit1.se.conv1.weight - torch.Size([8, 32, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage1.unit1.se.conv1.bias - torch.Size([8]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage1.unit1.se.conv2.weight - torch.Size([32, 8, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage1.unit1.se.conv2.bias - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage1.unit1.pw_conv.conv.weight - torch.Size([16, 32, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage1.unit1.pw_conv.bn.weight - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage1.unit1.pw_conv.bn.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage2.unit1.conv1.conv.weight - torch.Size([96, 16, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage2.unit1.conv1.bn.weight - torch.Size([96]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage2.unit1.conv1.bn.bias - torch.Size([96]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage2.unit1.conv2.conv.weight - torch.Size([96, 1, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage2.unit1.conv2.bn.weight - torch.Size([96]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage2.unit1.conv2.bn.bias - torch.Size([96]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage2.unit1.se.conv1.weight - torch.Size([4, 96, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage2.unit1.se.conv1.bias - torch.Size([4]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage2.unit1.se.conv2.weight - torch.Size([96, 4, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage2.unit1.se.conv2.bias - torch.Size([96]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage2.unit1.conv3.conv.weight - torch.Size([24, 96, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage2.unit1.conv3.bn.weight - torch.Size([24]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage2.unit1.conv3.bn.bias - torch.Size([24]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage2.unit2.conv1.conv.weight - torch.Size([144, 24, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage2.unit2.conv1.bn.weight - torch.Size([144]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage2.unit2.conv1.bn.bias - torch.Size([144]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage2.unit2.conv2.conv.weight - torch.Size([144, 1, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage2.unit2.conv2.bn.weight - torch.Size([144]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage2.unit2.conv2.bn.bias - torch.Size([144]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage2.unit2.se.conv1.weight - torch.Size([6, 144, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage2.unit2.se.conv1.bias - torch.Size([6]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage2.unit2.se.conv2.weight - torch.Size([144, 6, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage2.unit2.se.conv2.bias - torch.Size([144]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage2.unit2.conv3.conv.weight - torch.Size([24, 144, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage2.unit2.conv3.bn.weight - torch.Size([24]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage2.unit2.conv3.bn.bias - torch.Size([24]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage3.unit1.conv1.conv.weight - torch.Size([144, 24, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage3.unit1.conv1.bn.weight - torch.Size([144]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage3.unit1.conv1.bn.bias - torch.Size([144]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage3.unit1.conv2.conv.weight - torch.Size([144, 1, 5, 5]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage3.unit1.conv2.bn.weight - torch.Size([144]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage3.unit1.conv2.bn.bias - torch.Size([144]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage3.unit1.se.conv1.weight - torch.Size([6, 144, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage3.unit1.se.conv1.bias - torch.Size([6]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage3.unit1.se.conv2.weight - torch.Size([144, 6, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage3.unit1.se.conv2.bias - torch.Size([144]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage3.unit1.conv3.conv.weight - torch.Size([40, 144, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage3.unit1.conv3.bn.weight - torch.Size([40]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage3.unit1.conv3.bn.bias - torch.Size([40]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage3.unit2.conv1.conv.weight - torch.Size([240, 40, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage3.unit2.conv1.bn.weight - torch.Size([240]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage3.unit2.conv1.bn.bias - torch.Size([240]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage3.unit2.conv2.conv.weight - torch.Size([240, 1, 5, 5]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage3.unit2.conv2.bn.weight - torch.Size([240]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage3.unit2.conv2.bn.bias - torch.Size([240]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage3.unit2.se.conv1.weight - torch.Size([10, 240, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage3.unit2.se.conv1.bias - torch.Size([10]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage3.unit2.se.conv2.weight - torch.Size([240, 10, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage3.unit2.se.conv2.bias - torch.Size([240]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage3.unit2.conv3.conv.weight - torch.Size([40, 240, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage3.unit2.conv3.bn.weight - torch.Size([40]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage3.unit2.conv3.bn.bias - torch.Size([40]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit1.conv1.conv.weight - torch.Size([240, 40, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit1.conv1.bn.weight - torch.Size([240]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit1.conv1.bn.bias - torch.Size([240]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit1.conv2.conv.weight - torch.Size([240, 1, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit1.conv2.bn.weight - torch.Size([240]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit1.conv2.bn.bias - torch.Size([240]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit1.se.conv1.weight - torch.Size([10, 240, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit1.se.conv1.bias - torch.Size([10]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit1.se.conv2.weight - torch.Size([240, 10, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit1.se.conv2.bias - torch.Size([240]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit1.conv3.conv.weight - torch.Size([80, 240, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit1.conv3.bn.weight - torch.Size([80]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit1.conv3.bn.bias - torch.Size([80]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit2.conv1.conv.weight - torch.Size([480, 80, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit2.conv1.bn.weight - torch.Size([480]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit2.conv1.bn.bias - torch.Size([480]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit2.conv2.conv.weight - torch.Size([480, 1, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit2.conv2.bn.weight - torch.Size([480]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit2.conv2.bn.bias - torch.Size([480]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit2.se.conv1.weight - torch.Size([20, 480, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit2.se.conv1.bias - torch.Size([20]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit2.se.conv2.weight - torch.Size([480, 20, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit2.se.conv2.bias - torch.Size([480]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit2.conv3.conv.weight - torch.Size([80, 480, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit2.conv3.bn.weight - torch.Size([80]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit2.conv3.bn.bias - torch.Size([80]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit3.conv1.conv.weight - torch.Size([480, 80, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit3.conv1.bn.weight - torch.Size([480]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit3.conv1.bn.bias - torch.Size([480]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit3.conv2.conv.weight - torch.Size([480, 1, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit3.conv2.bn.weight - torch.Size([480]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit3.conv2.bn.bias - torch.Size([480]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit3.se.conv1.weight - torch.Size([20, 480, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit3.se.conv1.bias - torch.Size([20]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit3.se.conv2.weight - torch.Size([480, 20, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit3.se.conv2.bias - torch.Size([480]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit3.conv3.conv.weight - torch.Size([80, 480, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit3.conv3.bn.weight - torch.Size([80]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit3.conv3.bn.bias - torch.Size([80]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit4.conv1.conv.weight - torch.Size([480, 80, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit4.conv1.bn.weight - torch.Size([480]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit4.conv1.bn.bias - torch.Size([480]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit4.conv2.conv.weight - torch.Size([480, 1, 5, 5]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit4.conv2.bn.weight - torch.Size([480]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit4.conv2.bn.bias - torch.Size([480]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit4.se.conv1.weight - torch.Size([20, 480, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit4.se.conv1.bias - torch.Size([20]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit4.se.conv2.weight - torch.Size([480, 20, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit4.se.conv2.bias - torch.Size([480]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit4.conv3.conv.weight - torch.Size([112, 480, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit4.conv3.bn.weight - torch.Size([112]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit4.conv3.bn.bias - torch.Size([112]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit5.conv1.conv.weight - torch.Size([672, 112, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit5.conv1.bn.weight - torch.Size([672]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit5.conv1.bn.bias - torch.Size([672]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit5.conv2.conv.weight - torch.Size([672, 1, 5, 5]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit5.conv2.bn.weight - torch.Size([672]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit5.conv2.bn.bias - torch.Size([672]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit5.se.conv1.weight - torch.Size([28, 672, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit5.se.conv1.bias - torch.Size([28]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit5.se.conv2.weight - torch.Size([672, 28, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit5.se.conv2.bias - torch.Size([672]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit5.conv3.conv.weight - torch.Size([112, 672, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit5.conv3.bn.weight - torch.Size([112]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit5.conv3.bn.bias - torch.Size([112]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit6.conv1.conv.weight - torch.Size([672, 112, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit6.conv1.bn.weight - torch.Size([672]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit6.conv1.bn.bias - torch.Size([672]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit6.conv2.conv.weight - torch.Size([672, 1, 5, 5]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit6.conv2.bn.weight - torch.Size([672]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit6.conv2.bn.bias - torch.Size([672]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit6.se.conv1.weight - torch.Size([28, 672, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit6.se.conv1.bias - torch.Size([28]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit6.se.conv2.weight - torch.Size([672, 28, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit6.se.conv2.bias - torch.Size([672]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit6.conv3.conv.weight - torch.Size([112, 672, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit6.conv3.bn.weight - torch.Size([112]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage4.unit6.conv3.bn.bias - torch.Size([112]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit1.conv1.conv.weight - torch.Size([672, 112, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit1.conv1.bn.weight - torch.Size([672]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit1.conv1.bn.bias - torch.Size([672]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit1.conv2.conv.weight - torch.Size([672, 1, 5, 5]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit1.conv2.bn.weight - torch.Size([672]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit1.conv2.bn.bias - torch.Size([672]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit1.se.conv1.weight - torch.Size([28, 672, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit1.se.conv1.bias - torch.Size([28]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit1.se.conv2.weight - torch.Size([672, 28, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit1.se.conv2.bias - torch.Size([672]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit1.conv3.conv.weight - torch.Size([192, 672, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit1.conv3.bn.weight - torch.Size([192]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit1.conv3.bn.bias - torch.Size([192]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit2.conv1.conv.weight - torch.Size([1152, 192, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit2.conv1.bn.weight - torch.Size([1152]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit2.conv1.bn.bias - torch.Size([1152]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit2.conv2.conv.weight - torch.Size([1152, 1, 5, 5]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit2.conv2.bn.weight - torch.Size([1152]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit2.conv2.bn.bias - torch.Size([1152]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit2.se.conv1.weight - torch.Size([48, 1152, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit2.se.conv1.bias - torch.Size([48]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit2.se.conv2.weight - torch.Size([1152, 48, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit2.se.conv2.bias - torch.Size([1152]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit2.conv3.conv.weight - torch.Size([192, 1152, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit2.conv3.bn.weight - torch.Size([192]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit2.conv3.bn.bias - torch.Size([192]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit3.conv1.conv.weight - torch.Size([1152, 192, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit3.conv1.bn.weight - torch.Size([1152]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit3.conv1.bn.bias - torch.Size([1152]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit3.conv2.conv.weight - torch.Size([1152, 1, 5, 5]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit3.conv2.bn.weight - torch.Size([1152]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit3.conv2.bn.bias - torch.Size([1152]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit3.se.conv1.weight - torch.Size([48, 1152, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit3.se.conv1.bias - torch.Size([48]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit3.se.conv2.weight - torch.Size([1152, 48, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit3.se.conv2.bias - torch.Size([1152]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit3.conv3.conv.weight - torch.Size([192, 1152, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit3.conv3.bn.weight - torch.Size([192]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit3.conv3.bn.bias - torch.Size([192]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit4.conv1.conv.weight - torch.Size([1152, 192, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit4.conv1.bn.weight - torch.Size([1152]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit4.conv1.bn.bias - torch.Size([1152]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit4.conv2.conv.weight - torch.Size([1152, 1, 5, 5]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit4.conv2.bn.weight - torch.Size([1152]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit4.conv2.bn.bias - torch.Size([1152]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit4.se.conv1.weight - torch.Size([48, 1152, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit4.se.conv1.bias - torch.Size([48]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit4.se.conv2.weight - torch.Size([1152, 48, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit4.se.conv2.bias - torch.Size([1152]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit4.conv3.conv.weight - torch.Size([192, 1152, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit4.conv3.bn.weight - torch.Size([192]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit4.conv3.bn.bias - torch.Size([192]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit5.conv1.conv.weight - torch.Size([1152, 192, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit5.conv1.bn.weight - torch.Size([1152]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit5.conv1.bn.bias - torch.Size([1152]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit5.conv2.conv.weight - torch.Size([1152, 1, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit5.conv2.bn.weight - torch.Size([1152]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit5.conv2.bn.bias - torch.Size([1152]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit5.se.conv1.weight - torch.Size([48, 1152, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit5.se.conv1.bias - torch.Size([48]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit5.se.conv2.weight - torch.Size([1152, 48, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit5.se.conv2.bias - torch.Size([1152]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit5.conv3.conv.weight - torch.Size([320, 1152, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit5.conv3.bn.weight - torch.Size([320]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.stage5.unit5.conv3.bn.bias - torch.Size([320]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.final_block.conv.weight - torch.Size([1280, 320, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.final_block.bn.weight - torch.Size([1280]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "backbone.features.final_block.bn.bias - torch.Size([1280]): \n",
      "The value is the same before and after calling `init_weights` of ImageClassifier  \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "head.fc.weight - torch.Size([1000, 1280]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "01/03 15:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "head.fc.bias - torch.Size([1000]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n"
     ]
    }
   ],
   "source": [
    "engine.model = \"efficientnet_b0_light\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1)` was configured so validation will run after every batch.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type                      | Params\n",
      "----------------------------------------------------------\n",
      "0 | model       | MMPretrainCompatibleModel | 5.3 M \n",
      "1 | val_metric  | MulticlassAccuracy        | 0     \n",
      "2 | test_metric | MulticlassAccuracy        | 0     \n",
      "----------------------------------------------------------\n",
      "5.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.3 M     Total params\n",
      "21.154    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/repo/otx-fork/venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|| 1/1 [00:00<00:00,  9.39it/s, v_num=8, train/loss=0.0176, val/accuracy=0.560]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|| 1/1 [00:00<00:00,  5.71it/s, v_num=8, train/loss=0.0176, val/accuracy=0.560]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train/loss': tensor(0.0176), 'val/accuracy': tensor(0.5600)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "R4. Advanced-level Python API users provide a Dataset, and Model (nn.Module) as input, and OTX provides the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models.resnet import ResNet50_Weights, resnet50\n",
    "\n",
    "\n",
    "class ResNet50WithLossComputation(nn.Module):\n",
    "    def __init__(self, num_classes: int) -> None:\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        net = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "        net.fc = nn.Linear(\n",
    "            in_features=net.fc.in_features, out_features=self.num_classes\n",
    "        )\n",
    "        self.net = net\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, images: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "        logits = self.net(images)\n",
    "\n",
    "        if self.training:\n",
    "            return self.criterion(logits, labels)\n",
    "\n",
    "        return self.softmax(logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "import torch\n",
    "from lightning.pytorch.cli import ReduceLROnPlateau\n",
    "from otx.core.data.entity.base import OTXBatchLossEntity\n",
    "from otx.core.data.entity.classification import (\n",
    "    MulticlassClsBatchDataEntity,\n",
    "    MulticlassClsBatchPredEntity,\n",
    ")\n",
    "from otx.core.model.entity.classification import OTXClassificationModel\n",
    "from otx.core.model.module.classification import OTXClassificationLitModule\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class OTXResNet50(OTXClassificationModel):\n",
    "    def __init__(self, num_classes: int) -> None:\n",
    "        self.num_classes = num_classes\n",
    "        super().__init__()\n",
    "        self.register_buffer(\n",
    "            \"mean\",\n",
    "            torch.FloatTensor([123.675, 116.28, 103.53]).view(-1, 1, 1),\n",
    "            False,\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"std\",\n",
    "            torch.FloatTensor([58.395, 57.12, 57.375]).view(-1, 1, 1),\n",
    "            False,\n",
    "        )\n",
    "\n",
    "    def _create_model(self) -> nn.Module:\n",
    "        # ResNet50_Weights.IMAGENET1K_V2 is a really powerful pretrained model equipped with the modern training scheme:\n",
    "        # ImageNet-1K acc@1: 80.858, acc@5\": 95.434.\n",
    "        return ResNet50WithLossComputation(num_classes=self.num_classes)\n",
    "\n",
    "    def _customize_inputs(self, inputs: MulticlassClsBatchDataEntity) -> dict[str, Any]:\n",
    "        images = torch.stack(inputs.images, dim=0).to(dtype=torch.float32)\n",
    "        images = (images - self.mean) / self.std\n",
    "        return {\n",
    "            \"images\": images,\n",
    "            \"labels\": torch.cat(inputs.labels, dim=0),\n",
    "        }\n",
    "\n",
    "    def _customize_outputs(\n",
    "        self, outputs: Any, inputs: MulticlassClsBatchDataEntity\n",
    "    ) -> MulticlassClsBatchPredEntity | OTXBatchLossEntity:\n",
    "        if self.training:\n",
    "            return {\"loss\": outputs}\n",
    "\n",
    "        # To list, batch-wise\n",
    "        scores = torch.unbind(outputs, 0)\n",
    "\n",
    "        return MulticlassClsBatchPredEntity(\n",
    "            batch_size=inputs.batch_size,\n",
    "            images=inputs.images,\n",
    "            imgs_info=inputs.imgs_info,\n",
    "            scores=scores,\n",
    "            labels=inputs.labels,\n",
    "        )\n",
    "\n",
    "lightning_module = OTXClassificationLitModule(\n",
    "    otx_model=OTXResNet50(num_classes=2),\n",
    "    torch_compile=False,\n",
    "    optimizer=lambda p: torch.optim.SGD(p, lr=0.0049, momentum=0.9, weight_decay=0.0001),\n",
    "    scheduler=lambda o: ReduceLROnPlateau(o, patience=1, factor=0.5, monitor=\"train/loss\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from otx.engine import Engine\n",
    "\n",
    "engine = Engine(\n",
    "    data_root=data_root,\n",
    "    work_dir=\"./otx-workspace\",\n",
    "    device=\"gpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1)` was configured so validation will run after every batch.\n",
      "/home/harimkan/workspace/repo/otx-fork/venv/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:43: attribute 'optimizer' removed from hparams because it cannot be pickled\n",
      "/home/harimkan/workspace/repo/otx-fork/venv/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:43: attribute 'scheduler' removed from hparams because it cannot be pickled\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type               | Params\n",
      "---------------------------------------------------\n",
      "0 | model       | OTXResNet50        | 23.5 M\n",
      "1 | val_metric  | MulticlassAccuracy | 0     \n",
      "2 | test_metric | MulticlassAccuracy | 0     \n",
      "---------------------------------------------------\n",
      "23.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|| 1/1 [00:00<00:00,  7.99it/s, v_num=9, train/loss=0.360, val/accuracy=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|| 1/1 [00:00<00:00,  2.82it/s, v_num=9, train/loss=0.360, val/accuracy=1.000]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train/loss': tensor(0.3597), 'val/accuracy': tensor(1.)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.train(\n",
    "    model=lightning_module,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User provide datamodule & model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from otx.core.config.data import DataModuleConfig, SubsetConfig\n",
    "from otx.core.data.module import OTXDataModule\n",
    "\n",
    "task = \"MULTI_CLASS_CLS\"\n",
    "\n",
    "train_transform = [\n",
    "    {\"type\": \"LoadImageFromFile\"},\n",
    "    {\"type\": \"RandomResizedCrop\", \"scale\": 224, \"backend\": \"cv2\"},\n",
    "    {\"type\": \"PackInputs\"},\n",
    "]\n",
    "val_transform = [\n",
    "    {\"type\": \"LoadImageFromFile\"},\n",
    "    {\"type\": \"ResizeEdge\", \"scale\": 256, \"edge\": \"short\", \"backend\": \"cv2\"},\n",
    "    {\"type\": \"PackInputs\"},\n",
    "]\n",
    "\n",
    "datamodule = OTXDataModule(\n",
    "    task=task,\n",
    "    config=DataModuleConfig(\n",
    "        data_format=\"imagenet_with_subset_dirs\",\n",
    "        data_root=data_root,\n",
    "        train_subset=SubsetConfig(\n",
    "            batch_size=2,\n",
    "            subset_name=\"train\",\n",
    "            transform_lib_type=\"MMPRETRAIN\",\n",
    "            transforms=train_transform,\n",
    "        ),\n",
    "        val_subset=SubsetConfig(\n",
    "            batch_size=1,\n",
    "            subset_name=\"val\",\n",
    "            transform_lib_type=\"MMPRETRAIN\",\n",
    "            transforms=val_transform,\n",
    "        ),\n",
    "        test_subset=SubsetConfig(\n",
    "            batch_size=1,\n",
    "            subset_name=\"test\",\n",
    "            transform_lib_type=\"MMPRETRAIN\",\n",
    "            transforms=val_transform,\n",
    "        ),\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/repo/otx-fork/venv/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:639: Checkpoint directory ./otx-workspace/lightning_logs/version_9/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type               | Params\n",
      "---------------------------------------------------\n",
      "0 | model       | OTXResNet50        | 23.5 M\n",
      "1 | val_metric  | MulticlassAccuracy | 0     \n",
      "2 | test_metric | MulticlassAccuracy | 0     \n",
      "---------------------------------------------------\n",
      "23.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/repo/otx-fork/venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.train(\n",
    "    model=lightning_module,\n",
    "    datamodule=datamodule,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R5. Advanced-level Python API users can use custom training using all the trainer parameters available in lightning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/repo/otx-fork/venv/lib/python3.10/site-packages/lightning/fabric/connector.py:565: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1)` was configured so validation will run after every batch.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type               | Params\n",
      "---------------------------------------------------\n",
      "0 | model       | OTXResNet50        | 23.5 M\n",
      "1 | val_metric  | MulticlassAccuracy | 0     \n",
      "2 | test_metric | MulticlassAccuracy | 0     \n",
      "---------------------------------------------------\n",
      "23.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/repo/otx-fork/src/otx/core/data/mem_cache.py:229: UserWarning: Before calling MemCacheHandlerSingleton.get(), you should call MemCacheHandlerSingleton.create() first.\n",
      "  warnings.warn(message=msg, stacklevel=1)\n",
      "/home/harimkan/workspace/repo/otx-fork/src/otx/core/data/mem_cache.py:229: UserWarning: Before calling MemCacheHandlerSingleton.get(), you should call MemCacheHandlerSingleton.create() first.\n",
      "  warnings.warn(message=msg, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/13 [00:00<?, ?it/s]                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/repo/otx-fork/src/otx/core/data/mem_cache.py:229: UserWarning: Before calling MemCacheHandlerSingleton.get(), you should call MemCacheHandlerSingleton.create() first.\n",
      "  warnings.warn(message=msg, stacklevel=1)\n",
      "/home/harimkan/workspace/repo/otx-fork/src/otx/core/data/mem_cache.py:229: UserWarning: Before calling MemCacheHandlerSingleton.get(), you should call MemCacheHandlerSingleton.create() first.\n",
      "  warnings.warn(message=msg, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|| 13/13 [00:02<00:00,  5.26it/s, v_num=10, train/loss=0.284, val/accuracy=1.000] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|| 13/13 [00:02<00:00,  4.81it/s, v_num=10, train/loss=0.284, val/accuracy=1.000]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train/loss': tensor(0.2844), 'val/accuracy': tensor(1.)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.train(\n",
    "    model=lightning_module,\n",
    "    datamodule=datamodule,\n",
    "    max_epochs=3,\n",
    "    precision=\"16\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
