{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTX API Usage for Entry-API User\n",
    "\n",
    "### Requirements\n",
    "R01. Entry-level Python API users provide a Dataset (dataset root path) as input, and OTX detect the appropriate Task and select Model to provide a workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"../../tests/assets/classification_dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "tests/assets/classification_dataset\n",
    "├── test\n",
    "│   ├── 0\n",
    "│   └── 1\n",
    "├── train\n",
    "│   ├── 0\n",
    "│   └── 1\n",
    "└── val\n",
    "    ├── 0\n",
    "    └── 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto-Configuration\n",
    "Using the Auto-Configuration feature, OTX provides the user with a default model, data pipeline per task for that dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/repo/otx-fork/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING:root:Replace num_classes with 2\n",
      "WARNING:root:Set Default Model: {'class_path': 'otx.core.model.entity.classification.MMPretrainMulticlassClsModel', 'init_args': {'config': {'backbone': {'version': 'b0', 'pretrained': True, 'type': 'OTXEfficientNet'}, 'head': {'act_cfg': {'type': 'HSwish'}, 'dropout_rate': 0.2, 'in_channels': 1280, 'init_cfg': {'bias': 0.0, 'layer': 'Linear', 'mean': 0.0, 'std': 0.01, 'type': 'Normal'}, 'loss': {'loss_weight': 1.0, 'type': 'CrossEntropyLoss'}, 'mid_channels': [1280], 'num_classes': 2, 'topk': [1, 5], 'type': 'StackedLinearClsHead'}, 'neck': {'type': 'GlobalAveragePooling'}, 'data_preprocessor': {'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': False, 'type': 'ClsDataPreprocessor'}, 'type': 'ImageClassifier'}}}\n",
      "WARNING:root:Set Default Optimizer: {'class_path': 'torch.optim.SGD', 'init_args': {'lr': 0.001, 'momentum': 0.9, 'weight_decay': 0.0001}}\n",
      "WARNING:root:Set Default Scheduler: {'class_path': 'lightning.pytorch.cli.ReduceLROnPlateau', 'init_args': {'mode': 'min', 'factor': 0.5, 'patience': 1, 'monitor': 'train/loss'}}\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1)` was configured so validation will run after every batch.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init weight - https://github.com/osmr/imgclsmob/releases/download/v0.0.364/efficientnet_b0-0752-0e386130.pth.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type                         | Params\n",
      "-------------------------------------------------------------\n",
      "0 | model       | MMPretrainMulticlassClsModel | 5.6 M \n",
      "1 | val_metric  | MulticlassAccuracy           | 0     \n",
      "2 | test_metric | MulticlassAccuracy           | 0     \n",
      "-------------------------------------------------------------\n",
      "5.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.6 M     Total params\n",
      "22.599    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/repo/otx-fork/venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 10.77it/s, v_num=4, train/loss=0.653, val/accuracy=0.560]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s, v_num=4, train/loss=0.653, val/accuracy=0.560]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train/loss': tensor(0.6533), 'val/accuracy': tensor(0.5600)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from otx.engine import Engine\n",
    "\n",
    "engine = Engine(data_root=data_root)\n",
    "engine.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at ./otx-workspace/lightning_logs/version_4/checkpoints/epoch=9-step=10.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at ./otx-workspace/lightning_logs/version_4/checkpoints/epoch=9-step=10.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 61.79it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test/accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5600000023841858     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test/accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5600000023841858    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test/accuracy': tensor(0.5600)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R2. Entry-level Python API users can see a list of available models provided by OTX and use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from otx.engine import list_models\n",
    "\n",
    "list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "                                                             List model of OTX                                                                               \n",
    "┏━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
    "┃ Task                  ┃ Model Name               ┃ Config Path                                                                      ┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
    "│ MULTI_CLASS_CLS       │ efficientnet_v2_light    │ src/otx/configs/_base_/model/MULTI_CLASS_CLS/efficientnet_v2_light.yaml          │\n",
    "│ MULTI_CLASS_CLS       │ efficientnet_b0_light    │ src/otx/configs/_base_/model/MULTI_CLASS_CLS/efficientnet_b0_light.yaml          │\n",
    "│ MULTI_CLASS_CLS       │ otx_mobilenet_v3_large   │ src/otx/configs/_base_/model/MULTI_CLASS_CLS/otx_mobilenet_v3_large.yaml         │\n",
    "│ MULTI_CLASS_CLS       │ otx_deit_tiny            │ src/otx/configs/_base_/model/MULTI_CLASS_CLS/otx_deit_tiny.yaml                  │\n",
    "│ MULTI_CLASS_CLS       │ otx_efficientnet_v2      │ src/otx/configs/_base_/model/MULTI_CLASS_CLS/otx_efficientnet_v2.yaml            │\n",
    "│ MULTI_CLASS_CLS       │ mobilenet_v3_large_light │ src/otx/configs/_base_/model/MULTI_CLASS_CLS/mobilenet_v3_large_light.yaml       │\n",
    "│ MULTI_CLASS_CLS       │ otx_efficientnet_b0      │ src/otx/configs/_base_/model/MULTI_CLASS_CLS/otx_efficientnet_b0.yaml            │\n",
    "│ MULTI_CLASS_CLS       │ otx_dino_v2              │ src/otx/configs/_base_/model/MULTI_CLASS_CLS/otx_dino_v2.yaml                    │\n",
    "│ MULTI_CLASS_CLS       │ otx_dino_v2_linear_probe │ src/otx/configs/_base_/model/MULTI_CLASS_CLS/otx_dino_v2_linear_probe.yaml       │\n",
    "│ MULTI_LABEL_CLS       │ efficientnet_v2_light    │ src/otx/configs/_base_/model/MULTI_LABEL_CLS/efficientnet_v2_light.yaml          │\n",
    "│ MULTI_LABEL_CLS       │ efficientnet_b0_light    │ src/otx/configs/_base_/model/MULTI_LABEL_CLS/efficientnet_b0_light.yaml          │\n",
    "│ MULTI_LABEL_CLS       │ otx_deit_tiny            │ src/otx/configs/_base_/model/MULTI_LABEL_CLS/otx_deit_tiny.yaml                  │\n",
    "│ MULTI_LABEL_CLS       │ mobilenet_v3_large_light │ src/otx/configs/_base_/model/MULTI_LABEL_CLS/mobilenet_v3_large_light.yaml       │\n",
    "│ DETECTION             │ yolox_tiny               │ src/otx/configs/_base_/model/DETECTION/yolox_tiny.yaml                           │\n",
    "│ DETECTION             │ atss_mobilenetv2         │ src/otx/configs/_base_/model/DETECTION/atss_mobilenetv2.yaml                     │\n",
    "│ DETECTION             │ atss_resnext101          │ src/otx/configs/_base_/model/DETECTION/atss_resnext101.yaml                      │\n",
    "│ DETECTION             │ atss_r50_fpn             │ src/otx/configs/_base_/model/DETECTION/atss_r50_fpn.yaml                         │\n",
    "│ DETECTION             │ yolox_s                  │ src/otx/configs/_base_/model/DETECTION/yolox_s.yaml                              │\n",
    "│ DETECTION             │ rtmdet_tiny              │ src/otx/configs/_base_/model/DETECTION/rtmdet_tiny.yaml                          │\n",
    "│ DETECTION             │ yolox_x                  │ src/otx/configs/_base_/model/DETECTION/yolox_x.yaml                              │\n",
    "│ DETECTION             │ ssd_mobilenetv2          │ src/otx/configs/_base_/model/DETECTION/ssd_mobilenetv2.yaml                      │\n",
    "│ DETECTION             │ yolox_l                  │ src/otx/configs/_base_/model/DETECTION/yolox_l.yaml                              │\n",
    "│ INSTANCE_SEGMENTATION │ maskrcnn_r50             │ src/otx/configs/_base_/model/INSTANCE_SEGMENTATION/maskrcnn_r50.yaml             │\n",
    "│ INSTANCE_SEGMENTATION │ maskrcnn_swint           │ src/otx/configs/_base_/model/INSTANCE_SEGMENTATION/maskrcnn_swint.yaml           │\n",
    "│ INSTANCE_SEGMENTATION │ maskrcnn_efficientnetb2b │ src/otx/configs/_base_/model/INSTANCE_SEGMENTATION/maskrcnn_efficientnetb2b.yaml │\n",
    "│ SEMANTIC_SEGMENTATION │ segnext_t                │ src/otx/configs/_base_/model/SEMANTIC_SEGMENTATION/segnext_t.yaml                │\n",
    "│ SEMANTIC_SEGMENTATION │ segnext_b                │ src/otx/configs/_base_/model/SEMANTIC_SEGMENTATION/segnext_b.yaml                │\n",
    "│ SEMANTIC_SEGMENTATION │ segnext_s                │ src/otx/configs/_base_/model/SEMANTIC_SEGMENTATION/segnext_s.yaml                │\n",
    "│ SEMANTIC_SEGMENTATION │ dino_v2                  │ src/otx/configs/_base_/model/SEMANTIC_SEGMENTATION/dino_v2.yaml                  │\n",
    "│ SEMANTIC_SEGMENTATION │ litehrnet_18             │ src/otx/configs/_base_/model/SEMANTIC_SEGMENTATION/litehrnet_18.yaml             │\n",
    "│ SEMANTIC_SEGMENTATION │ litehrnet_s              │ src/otx/configs/_base_/model/SEMANTIC_SEGMENTATION/litehrnet_s.yaml              │\n",
    "│ SEMANTIC_SEGMENTATION │ litehrnet_x              │ src/otx/configs/_base_/model/SEMANTIC_SEGMENTATION/litehrnet_x.yaml              │\n",
    "│ ACTION_CLASSIFICATION │ x3d                      │ src/otx/configs/_base_/model/ACTION_CLASSIFICATION/x3d.yaml                      │\n",
    "│ ACTION_DETECTION      │ x3d_fastrcnn             │ src/otx/configs/_base_/model/ACTION_DETECTION/x3d_fastrcnn.yaml                  │\n",
    "└───────────────────────┴──────────────────────────┴──────────────────────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Replace num_classes with 2\n",
      "WARNING:root:Set Default Model: {'class_path': 'otx.core.model.entity.classification.MMPretrainMulticlassClsModel', 'init_args': {'config': {'backbone': {'type': 'OTXMobileNetV3'}, 'head': {'act_cfg': {'type': 'HSwish'}, 'dropout_rate': 0.2, 'in_channels': 960, 'init_cfg': {'bias': 0.0, 'layer': 'Linear', 'mean': 0.0, 'std': 0.01, 'type': 'Normal'}, 'loss': {'loss_weight': 1.0, 'type': 'CrossEntropyLoss'}, 'mid_channels': [1280], 'num_classes': 2, 'topk': [1, 5], 'type': 'StackedLinearClsHead'}, 'neck': {'type': 'GlobalAveragePooling'}, 'data_preprocessor': {'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': False, 'type': 'ClsDataPreprocessor'}, 'type': 'ImageClassifier'}}}\n",
      "WARNING:root:Set Default Optimizer: {'class_path': 'torch.optim.SGD', 'init_args': {'lr': 0.001, 'momentum': 0.9, 'weight_decay': 0.0001}}\n",
      "WARNING:root:Set Default Scheduler: {'class_path': 'lightning.pytorch.cli.ReduceLROnPlateau', 'init_args': {'mode': 'min', 'factor': 0.5, 'patience': 1, 'monitor': 'train/loss'}}\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1)` was configured so validation will run after every batch.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type                         | Params\n",
      "-------------------------------------------------------------\n",
      "0 | model       | MMPretrainMulticlassClsModel | 4.2 M \n",
      "1 | val_metric  | MulticlassAccuracy           | 0     \n",
      "2 | test_metric | MulticlassAccuracy           | 0     \n",
      "-------------------------------------------------------------\n",
      "4.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.2 M     Total params\n",
      "16.818    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: https://github.com/d-li14/mobilenetv3.pytorch/blob/master/pretrained/mobilenetv3-large-1cd25616.pth?raw=true\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: classifier.0.weight, classifier.0.bias, classifier.3.weight, classifier.3.bias\n",
      "\n",
      "init weight - https://github.com/d-li14/mobilenetv3.pytorch/blob/master/pretrained/mobilenetv3-large-1cd25616.pth?raw=true\n",
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/repo/otx-fork/venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 14.35it/s, v_num=5, train/loss=0.690, val/accuracy=0.720]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s, v_num=5, train/loss=0.690, val/accuracy=0.720]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train/loss': tensor(0.6901), 'val/accuracy': tensor(0.7200)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from otx.engine import Engine\n",
    "\n",
    "Engine(data_root=data_root, model=\"otx_mobilenet_v3_large\").train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Config file\n",
    "If Configuration has all the configurations for Model, data, and engine, Engine can set this up ahead of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/repo/otx-fork/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init weight - https://github.com/osmr/imgclsmob/releases/download/v0.0.364/efficientnet_b0-0752-0e386130.pth.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1)` was configured so validation will run after every batch.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type                         | Params\n",
      "-------------------------------------------------------------\n",
      "0 | model       | MMPretrainMulticlassClsModel | 6.9 M \n",
      "1 | val_metric  | MulticlassAccuracy           | 0     \n",
      "2 | test_metric | MulticlassAccuracy           | 0     \n",
      "-------------------------------------------------------------\n",
      "6.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.9 M     Total params\n",
      "27.713    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/repo/otx-fork/venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 10.58it/s, v_num=6, train/loss=5.630, val/accuracy=0.680]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.64it/s, v_num=6, train/loss=5.630, val/accuracy=0.680]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train/loss': tensor(5.6322), 'val/accuracy': tensor(0.6800)}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from otx.engine import Engine\n",
    "\n",
    "engine = Engine.from_config(config=\"./test_config.yaml\")\n",
    "engine.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at ./otx-workspace/lightning_logs/version_6/checkpoints/epoch=9-step=10.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at ./otx-workspace/lightning_logs/version_6/checkpoints/epoch=9-step=10.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 60.70it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test/accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6800000071525574     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test/accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6800000071525574    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test/accuracy': tensor(0.6800)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
