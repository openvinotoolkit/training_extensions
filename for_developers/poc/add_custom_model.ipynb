{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to add custom model\n",
    "\n",
    "This is a simple Jupyter notebook example to show how the developer can add a new model for the OTX task (Multi class classification at this time) and execute model training.\n",
    "First let me start with importing everything we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/repo/otx-fork/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Any\n",
    "\n",
    "import torch\n",
    "from lightning.pytorch.cli import ReduceLROnPlateau\n",
    "from otx.core.data.entity.base import OTXBatchLossEntity\n",
    "from otx.core.data.entity.classification import (\n",
    "    MulticlassClsBatchDataEntity,\n",
    "    MulticlassClsBatchPredEntity,\n",
    ")\n",
    "from otx.core.model.entity.classification import OTXClassificationModel\n",
    "from otx.core.model.module.classification import OTXClassificationLitModule\n",
    "from torch import nn\n",
    "from torchvision.models.resnet import ResNet50_Weights, resnet50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have everything we need. Before we start, please keep in mind that this is not our end image. The training from Python API design is not determined yet and this is very first place.\n",
    "\n",
    "The first thing is that we need to develop the actual PyTorch Model which should be created in `OTXModel._create_model()` function.\n",
    "As you know, `OTXModel` is required to produce the task losses in the training.\n",
    "On the other hand, it should produce the model predictions from the image in the evaluation.\n",
    "Therefore, this `nn.Module` should be able to compute the task losses.\n",
    "This is important thing you have to notice.\n",
    "Let's see the code now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50WithLossComputation(nn.Module):\n",
    "    def __init__(self, num_classes: int) -> None:\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        net = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "        net.fc = nn.Linear(\n",
    "            in_features=net.fc.in_features, out_features=self.num_classes\n",
    "        )\n",
    "        self.net = net\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, images: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "        logits = self.net(images)\n",
    "\n",
    "        if self.training:\n",
    "            return self.criterion(logits, labels)\n",
    "\n",
    "        return self.softmax(logits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing is that we need to develop the one derived from `OTXModel`.\n",
    "However, in this example, we want to add the multi class classification model.\n",
    "We should implement the class derived from `OTXClassificationModel`.\n",
    "For another OTX task, such as `OTXTaskType.DETECTION`, we might be able to make a custom model by deriving from `OTXDetectionModel`.\n",
    "\n",
    "Since every `OTXModel` is an abstract class, it is designed to require a developer to implement three abstract functions:\n",
    "\n",
    "1) `_create_model()`\n",
    "2) `_customize_inputs()`\n",
    "3) `_customize_outputs()`\n",
    "\n",
    "You can see that the following example is exactly implementing those three functions.\n",
    "Let's see together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OTXResNet50(OTXClassificationModel):\n",
    "    def __init__(self, num_classes: int) -> None:\n",
    "        self.num_classes = num_classes\n",
    "        super().__init__()\n",
    "        self.register_buffer(\n",
    "            \"mean\",\n",
    "            torch.FloatTensor([123.675, 116.28, 103.53]).view(-1, 1, 1),\n",
    "            False,\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"std\",\n",
    "            torch.FloatTensor([58.395, 57.12, 57.375]).view(-1, 1, 1),\n",
    "            False,\n",
    "        )\n",
    "\n",
    "    def _create_model(self) -> nn.Module:\n",
    "        # ResNet50_Weights.IMAGENET1K_V2 is a really powerful pretrained model equipped with the modern training scheme:\n",
    "        # ImageNet-1K acc@1: 80.858, acc@5\": 95.434.\n",
    "        return ResNet50WithLossComputation(num_classes=self.num_classes)\n",
    "\n",
    "    def _customize_inputs(self, inputs: MulticlassClsBatchDataEntity) -> dict[str, Any]:\n",
    "        images = torch.stack(inputs.images, dim=0).to(dtype=torch.float32)\n",
    "        images = (images - self.mean) / self.std\n",
    "        return {\n",
    "            \"images\": images,\n",
    "            \"labels\": torch.cat(inputs.labels, dim=0),\n",
    "        }\n",
    "\n",
    "    def _customize_outputs(\n",
    "        self, outputs: Any, inputs: MulticlassClsBatchDataEntity\n",
    "    ) -> MulticlassClsBatchPredEntity | OTXBatchLossEntity:\n",
    "        if self.training:\n",
    "            return {\"loss\": outputs}\n",
    "\n",
    "        # To list, batch-wise\n",
    "        scores = torch.unbind(outputs, 0)\n",
    "\n",
    "        return MulticlassClsBatchPredEntity(\n",
    "            batch_size=inputs.batch_size,\n",
    "            images=inputs.images,\n",
    "            imgs_info=inputs.imgs_info,\n",
    "            scores=scores,\n",
    "            labels=inputs.labels,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to prepare a datamodule. Of course, we can also declare it via a config file and use it, but for the current example we will write it without a config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from otx.core.data.module import OTXDataModule\n",
    "from otx.core.config.data import DataModuleConfig, SubsetConfig\n",
    "\n",
    "task = \"MULTI_CLASS_CLS\"\n",
    "data_dir = \"../../tests/assets/classification_dataset\"\n",
    "\n",
    "train_transform = [\n",
    "    {\"type\": \"LoadImageFromFile\"},\n",
    "    {\"type\": \"RandomResizedCrop\", \"scale\": 224, \"backend\": \"cv2\"},\n",
    "    {\"type\": \"PackInputs\"},\n",
    "]\n",
    "val_transform = [\n",
    "    {\"type\": \"LoadImageFromFile\"},\n",
    "    {\"type\": \"ResizeEdge\", \"scale\": 256, \"edge\": \"short\", \"backend\": \"cv2\"},\n",
    "    {\"type\": \"PackInputs\"},\n",
    "]\n",
    "\n",
    "datamodule = OTXDataModule(\n",
    "    task=task,\n",
    "    config=DataModuleConfig(\n",
    "        data_format=\"imagenet_with_subset_dirs\",\n",
    "        data_root=data_dir,\n",
    "        train_subset=SubsetConfig(\n",
    "            batch_size=2,\n",
    "            subset_name=\"train\",\n",
    "            transform_lib_type=\"MMPRETRAIN\",\n",
    "            transforms=train_transform,\n",
    "        ),\n",
    "        val_subset=SubsetConfig(\n",
    "            batch_size=1,\n",
    "            subset_name=\"val\",\n",
    "            transform_lib_type=\"MMPRETRAIN\",\n",
    "            transforms=val_transform,\n",
    "        ),\n",
    "        test_subset=SubsetConfig(\n",
    "            batch_size=1,\n",
    "            subset_name=\"test\",\n",
    "            transform_lib_type=\"MMPRETRAIN\",\n",
    "            transforms=val_transform,\n",
    "        ),\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can train through a class in OTX called Engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/repo/otx-fork/venv/lib/python3.10/site-packages/lightning/fabric/connector.py:565: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1)` was configured so validation will run after every batch.\n",
      "/home/harimkan/workspace/repo/otx-fork/venv/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:43: attribute 'optimizer' removed from hparams because it cannot be pickled\n",
      "/home/harimkan/workspace/repo/otx-fork/venv/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:43: attribute 'scheduler' removed from hparams because it cannot be pickled\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: ./otx-workspace/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type               | Params\n",
      "---------------------------------------------------\n",
      "0 | model       | OTXResNet50        | 23.5 M\n",
      "1 | val_metric  | MulticlassAccuracy | 0     \n",
      "2 | test_metric | MulticlassAccuracy | 0     \n",
      "---------------------------------------------------\n",
      "23.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harimkan/workspace/repo/otx-fork/venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 13/13 [00:02<00:00,  5.33it/s, v_num=0, train/loss=0.311, val/accuracy=1.000] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 13/13 [00:02<00:00,  4.88it/s, v_num=0, train/loss=0.311, val/accuracy=1.000]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train/loss': tensor(0.3110), 'val/accuracy': tensor(1.)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from otx.core.engine.engine import Engine\n",
    "\n",
    "num_classes = 2\n",
    "lightning_module = OTXClassificationLitModule(\n",
    "    otx_model=OTXResNet50(num_classes=num_classes),\n",
    "    torch_compile=False,\n",
    "    optimizer=lambda p: torch.optim.SGD(p, lr=0.0049, momentum=0.9, weight_decay=0.0001),\n",
    "    scheduler=lambda o: ReduceLROnPlateau(o, patience=1, factor=0.5, monitor=\"train/loss\"),\n",
    ")\n",
    "\n",
    "from otx.core.engine.engine import Engine\n",
    "\n",
    "engine = Engine(\n",
    "    task=task,\n",
    "    work_dir=\"./otx-workspace\",\n",
    "    device=\"gpu\",\n",
    ")\n",
    "\n",
    "engine.train(\n",
    "    model=lightning_module,\n",
    "    datamodule=datamodule,\n",
    "    max_epochs=3,\n",
    "    precision=\"16\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saying again. This is not the end image of the OTX training API. We will continue to strive to improve it so that users can use it conveniently. And, I believe that it is not difficult since we already have a solid core design and it is just an entrypoint.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "otx-v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
